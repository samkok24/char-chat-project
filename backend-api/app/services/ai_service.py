"""
AI ëª¨ë¸ê³¼ì˜ ìƒí˜¸ìž‘ìš©ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤
- í˜„ìž¬ëŠ” Gemini, Claude, OpenAI ëª¨ë¸ì„ ì§€ì› (í–¥í›„ í™•ìž¥ ê°€ëŠ¥)
- ê° ëª¨ë¸ì˜ ì‘ë‹µì„ ì¼ê´€ëœ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•¨
"""
import google.generativeai as genai
import anthropic  # Claude API ë¼ì´ë¸ŒëŸ¬ë¦¬
from typing import Literal, Optional, AsyncGenerator
from app.core.config import settings
from .vision_service import stage1_keywords_from_image_url, stage1_keywords_from_image_url as _stage1, _http_get_bytes
import mimetypes
import logging
import imghdr
from io import BytesIO
from PIL import Image
import base64
import asyncio

logger = logging.getLogger(__name__)

# Claude ëª¨ë¸ëª… ìƒìˆ˜ (ì „ì—­ ì°¸ì¡°ìš©)
# CLAUDE_MODEL_PRIMARY = 'claude-sonnet-4-5-20250929'
CLAUDE_MODEL_PRIMARY = 'claude-sonnet-4-20250514'
# CLAUDE_MODEL_PRIMARY = 'claude-3-7-sonnet-20250219'
CLAUDE_MODEL_LEGACY = 'claude-sonnet-4-20250514'  # í´ë°±/í˜¸í™˜ìš©

GPT_MODEL_PRIMARY = 'gpt-5'

# ì•ˆì „ ë¬¸ìžì—´ ë³€í™˜ ìœ í‹¸
def _as_text(val) -> str:
    try:
        if val is None:
            return ""
        if isinstance(val, (list, tuple, set)):
            return ", ".join([str(v) for v in val if str(v).strip()])
        return str(val)
    except Exception:
        return ""

# --- Gemini AI ì„¤ì • ---
genai.configure(api_key=settings.GEMINI_API_KEY)
claude_client = anthropic.AsyncAnthropic(api_key=settings.CLAUDE_API_KEY)
# --- OCR ì œê±°: ê¸°ì¡´ PaddleOCR ê²½ëŸ‰ ì‚¬ìš© êµ¬ê°„ì„ ì™„ì „ ë¹„í™œì„±í™” ---
def _extract_numeric_phrases_ocr_bytes(img_bytes: bytes) -> list[str]:
    # PaddleOCR ì œê±°ë¡œ ë” ì´ìƒ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
    return []

def _parse_user_intent(user_hint: str) -> dict:
    """ìžì—°ì–´ ìž…ë ¥ì—ì„œ ê°„ë‹¨í•œ ì˜ë„/í†¤/ì‹œì /ì†ë„ ë“±ì„ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì¶”ì¶œ(ì¶”ê°€ í˜¸ì¶œ ì—†ì´).
    ë°˜í™˜: { intent, stance, tone, pace, continue, remix, constraints, transform_tags }
    """
    hint = (user_hint or "").strip().lower()
    # ê¸°ë³¸ê°’
    intent = None
    stance = None
    tone = None
    pace = None
    want_continue = False
    want_remix = False
    constraints: list[str] = []
    tags: list[str] = []

    # í•œêµ­ì–´ í‚¤ì›Œë“œ(ì†Œë¬¸ìž ë³€í™˜ ì „ì œ â†’ í•œê¸€ì—” ì˜í–¥ ì—†ìŒ)
    def _has(*keys: str) -> bool:
        return any(k in user_hint for k in keys)

    # intent
    if _has("ì—°ì• ", "ì‚¬ëž‘", "ë°ì´íŠ¸", "ì¸"):
        intent = "romance"
        tone = tone or "ì„¤ë ˜/ì„œì •"
    if _has("ë³µìˆ˜", "ì‘ì§•", "í†µìˆ˜"):
        intent = intent or "revenge"
    if _has("ìŠ¤ë¦´ëŸ¬", "ê³µí¬", "í˜¸ëŸ¬", "ë¯¸ìŠ¤í„°ë¦¬", "ì¶”ë¦¬", "ëŠì™€ë¥´"):
        intent = intent or "thriller"

    # stance
    if _has("1ì¸ì¹­", "ì¼ì¸ì¹­", "ë‚˜ë¡œ"):
        stance = "first"
    if _has("3ì¸ì¹­", "ì‚¼ì¸ì¹­", "ê·¸ë…€", "ê·¸ë¡œ"):
        stance = stance or "third"

    # tone
    if _has("ìž”ìž”", "ë”°ëœ»", "ížë§"):
        tone = tone or "ìž”ìž”/ë”°ëœ»"
    if _has("í›„í‚¹", "ëª°ìž…", "ìžê·¹"):
        tone = tone or "í›„í‚¹/ê°•ë ¬"

    # pace
    if _has("ë¹ ë¥´ê²Œ", "ì†ë„ê°", "í…œí¬ ë¹ "):
        pace = "fast"
    if _has("ì²œì²œížˆ", "ëŠë¦¬ê²Œ"):
        pace = pace or "slow"

    # control flags
    if _has("ì´ì–´ì¤˜", "ì´ì–´ ì¨", "ê³„ì† ì¨"):
        want_continue = True
    if _has("ë°”ê¿”ì¤˜", "ë‹¤ë¥´ê²Œ", "ëŠë‚Œìœ¼ë¡œ ë°”ê¿”"):
        want_remix = True

    # transform tags(UI íƒœê·¸ì™€ ì ‘ì )
    if _has("ë¡œë§¨ìŠ¤"):
        tags.append("ë¡œë§¨ìŠ¤")
    if _has("ìž”ìž”"):
        tags.append("ìž”ìž”í•˜ê²Œ")
    if _has("ìœ„íŠ¸", "ë°ˆ"):
        tags.append("ë°ˆìŠ¤ëŸ½ê²Œ")
    if stance == "first":
        tags.append("1ì¸ì¹­ì‹œì ")
    if stance == "third":
        tags.append("3ì¸ì¹­ì‹œì ")

    # constraints
    if _has("íšŒì‚¬", "ì§ìž¥", "ìƒì‚¬"):
        constraints.append("ì‹¤ëª…/íšŒì‚¬ëª…/ì§í•¨ ê¸ˆì§€")

    return {
        "intent": intent,
        "stance": stance,
        "tone": tone,
        "pace": pace,
        "continue": want_continue,
        "remix": want_remix,
        "constraints": constraints,
        "transform_tags": tags,
    }

# (í”„ë¦¬ì›Œë° ë¡¤ë°±) ì—…ë¡œë“œ í”„ë¦¬ì›Œë° ìœ í‹¸ ì œê±°


# OpenAI ì„¤ì •
from openai import AsyncOpenAI
import openai
client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)


# -------------------------------
# Vision-grounded helpers (Gemini)
# -------------------------------
# Gemini ì•ˆì „ ì„¤ì •(ì°¨ë‹¨ ì™„í™”)
DEFAULT_SAFETY_OPEN = [
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUAL_CONTENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_VIOLENCE", "threshold": "BLOCK_NONE"},
]

async def tag_image_keywords(image_url: str, model: str = 'claude') -> dict:
    """
    ê°•í™”ëœ ì´ë¯¸ì§€ íƒœê¹…: Claude Vision ìš°ì„  ì‚¬ìš©ìœ¼ë¡œ ë” ì •í™•í•œ ë¶„ì„
    """
    try:
        import requests
        import base64
        import json
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° base64 ì¸ì½”ë”© + MIME íƒì§€
        response = requests.get(image_url, timeout=10)
        img_bytes = response.content

        # --- pHash ìºì‹œ ì¡°íšŒ(ê²½ëŸ‰ average hash) ---
        try:
            from app.core.database import redis_client as _redis
            def _avg_hash(bytes_data: bytes, hash_size: int = 8) -> str:
                img = Image.open(BytesIO(bytes_data)).convert('L').resize((hash_size, hash_size), Image.BILINEAR)
                pixels = list(img.getdata())
                avg = sum(pixels) / len(pixels)
                bits = ''.join('1' if p > avg else '0' for p in pixels)
                return hex(int(bits, 2))[2:].rjust((hash_size*hash_size)//4, '0')
            ahash = _avg_hash(img_bytes)
            cache_key = f"vision:ahash:{ahash}:tags"
            # URL ê¸°ë°˜ í‚¤(ì¿¼ë¦¬ ì œê±°)
            cache_key_url = None
            try:
                p = urlparse(image_url)
                url_no_q = urlunparse((p.scheme, p.netloc, p.path, '', '', ''))
                cache_key_url = f"vision:url:{url_no_q}:tags"
                cached_url = await _redis.get(cache_key_url)
                if cached_url:
                    try:
                        txt = cached_url.decode('utf-8') if isinstance(cached_url, (bytes, bytearray)) else str(cached_url)
                        data = json.loads(txt)
                        if isinstance(data, dict):
                            logging.info("Vision tags cache hit")
                            return data
                    except Exception:
                        pass
            except Exception:
                pass
            cached = await _redis.get(cache_key)
            if cached:
                try:
                    txt = cached.decode('utf-8') if isinstance(cached, (bytes, bytearray)) else str(cached)
                    data = json.loads(txt)
                    if isinstance(data, dict):
                        logging.info("Vision tags cache hit")
                        return data
                except Exception:
                    pass
        except Exception:
            ahash = None
            cache_key_url = None
        image_data = base64.b64encode(img_bytes).decode('utf-8')
        # ìš°ì„ ìˆœìœ„: ì‘ë‹µ í—¤ë” â†’ ë°”ì´íŠ¸ ì‹œê·¸ë‹ˆì²˜ â†’ ê¸°ë³¸ê°’
        ct = (response.headers.get('Content-Type') or '').lower()
        if ct.startswith('image/'):
            image_mime = ct.split(';')[0].strip()
        else:
            kind = imghdr.what(None, h=img_bytes)
            mime_map = {
                'jpeg': 'image/jpeg', 'jpg': 'image/jpeg', 'png': 'image/png',
                'gif': 'image/gif', 'webp': 'image/webp', 'bmp': 'image/bmp'
            }
            image_mime = mime_map.get(kind, 'image/jpeg')
        
        prompt = (
            "ì´ë¯¸ì§€ë¥¼ ë§¤ìš° ìžì„¸ížˆ ë¶„ì„í•´ì„œ ìŠ¤í† ë¦¬í…”ë§ì— í•„ìš”í•œ ëª¨ë“  ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.\n"
            "JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:\n"
            "{\n"
            "  \"place\": \"êµ¬ì²´ì ì¸ ìž¥ì†Œ (ì˜ˆ: ë¶ë¹„ëŠ” ì¹´íŽ˜ í…Œë¼ìŠ¤, í™©ëŸ‰í•œ ì‚¬ë§‰ ë„ë¡œ)\",\n"
            "  \"objects\": [\"ëˆˆì— ë„ëŠ” ëª¨ë“  ì‚¬ë¬¼ë“¤\"],\n"
            "  \"lighting\": \"ì¡°ëª… ìƒíƒœì™€ ì‹œê°„ëŒ€\",\n"
            "  \"weather\": \"ë‚ ì”¨ë‚˜ ê³„ì ˆê°\",\n"
            "  \"mood\": \"ì „ì²´ì ì¸ ë¶„ìœ„ê¸°\",\n"
            "  \"colors\": [\"ì£¼ìš” ìƒ‰ìƒë“¤\"],\n"
            "  \"textures\": [\"ì§ˆê°, ìž¬ì§ˆ\"],\n"
            "  \"sounds_implied\": [\"ì•”ì‹œë˜ëŠ” ì†Œë¦¬ë“¤\"],\n"
            "  \"smells_implied\": [\"ì•”ì‹œë˜ëŠ” ëƒ„ìƒˆë“¤\"],\n"
            "  \"temperature\": \"ì²´ê° ì˜¨ë„\",\n"
            "  \"movement\": \"ì›€ì§ìž„ì´ë‚˜ ë™ì  ìš”ì†Œ\",\n"
            "  \"focal_point\": \"ì‹œì„ ì´ ì§‘ì¤‘ë˜ëŠ” ê³³\",\n"
            "  \"story_hooks\": [\"ìŠ¤í† ë¦¬ ì „ê°œ ê°€ëŠ¥í•œ ìš”ì†Œë“¤\"],\n"
            "  \"in_image_text\": [\"ì´ë¯¸ì§€ ì•ˆì— ë³´ì´ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì›ë¬¸ ê·¸ëŒ€ë¡œ(ì˜¤íƒˆìž í¬í•¨)\"],\n"
            "  \"numeric_phrases\": [\"ìˆ«ìž+ë‹¨ìœ„ê°€ í•¨ê»˜ ìžˆëŠ” ë¬¸êµ¬(ì˜ˆ: '500í‚¤ë¡œ', '500ì›')\"]\n"
            "}"
        )
        
        # Claude Vision ì‹œë„
        if model == 'claude':
            try:
                txt = await get_claude_completion(
                    prompt,
                    max_tokens=1800,
                    model=CLAUDE_MODEL_PRIMARY,
                    image_base64=image_data,
                    image_mime=image_mime
                )
                
                # JSON ì¶”ì¶œ
                if '```json' in txt:
                    txt = txt.split('```json')[1].split('```')[0].strip()
                elif '```' in txt:
                    txt = txt.split('```')[1].split('```')[0].strip()
                    
                data = json.loads(txt)
                if isinstance(data, dict):
                    logging.info("Claude Vision tagging successful")
                    # ìºì‹œ ì €ìž¥
                    try:
                        if cache_key_url:
                            await _redis.setex(cache_key_url, 86400, json.dumps(data, ensure_ascii=False))
                        if ahash:
                            await _redis.setex(cache_key, 86400, json.dumps(data, ensure_ascii=False))
                    except Exception:
                        pass
                    return data
            except Exception as e:
                logging.error(f"Claude Vision tagging failed: {e}")
        
        # Gemini í´ë°±
        try:
            import google.generativeai as genai
            import os
            from PIL import Image
            from io import BytesIO
            
            genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
            
            img = Image.open(BytesIO(response.content))
            mm_model = genai.GenerativeModel('gemini-2.5-pro')
            
            response = mm_model.generate_content([prompt, img])
            txt = response.text
            
            if '```json' in txt:
                txt = txt.split('```json')[1].split('```')[0].strip()
            elif '```' in txt:
                txt = txt.split('```')[1].split('```')[0].strip()
                
            data = json.loads(txt)
            if isinstance(data, dict):
                logging.info("Gemini Vision tagging successful")
                try:
                    if cache_key_url:
                        await _redis.setex(cache_key_url, 86400, json.dumps(data, ensure_ascii=False))
                    if ahash:
                        await _redis.setex(cache_key, 86400, json.dumps(data, ensure_ascii=False))
                except Exception:
                    pass
                return data
                
        except Exception as e:
            logging.error(f"Gemini Vision tagging failed: {e}")
            
    except Exception as e:
        logging.error(f"Enhanced image tagging failed: {e}")
        
    # í´ë°±: ê¸°ë³¸ íƒœê¹…
    return {"place": "", "objects": [], "lighting": "", "weather": "", "mood": ""}

async def extract_image_narrative_context(image_url: str, model: str = 'claude') -> dict:
    """
    ì¸ë¬¼/ê´€ê³„/ë¶„ìœ„ê¸°/ì—°ì¶œ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•´ ì¶”ì¶œ.
    subjects: [{role?, age_range?, gender?, attire?, emotion?, pose?}]
    relations: [{a_idx, b_idx, relation, evidence}]
    camera: {angle, distance, lens_hint}
    palette: [keywords]
    genre_cues: [keywords]
    narrative_axes: {desire, conflict, stakes}  # ì•”ì‹œì ì´ë©´ ì§§ê²Œ ì œì•ˆ
    tone: {mood_words, pace}
    """
    try:
        import requests
        import base64
        import json
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° base64 ì¸ì½”ë”© + MIME íƒì§€
        response = requests.get(image_url, timeout=10)
        img_bytes = response.content

        # --- pHash ìºì‹œ ì¡°íšŒ(ì»¨í…ìŠ¤íŠ¸) ---
        try:
            from app.core.database import redis_client as _redis
            def _avg_hash(bytes_data: bytes, hash_size: int = 8) -> str:
                img = Image.open(BytesIO(bytes_data)).convert('L').resize((hash_size, hash_size), Image.BILINEAR)
                pixels = list(img.getdata())
                avg = sum(pixels) / len(pixels)
                bits = ''.join('1' if p > avg else '0' for p in pixels)
                return hex(int(bits, 2))[2:].rjust((hash_size*hash_size)//4, '0')
            ahash = _avg_hash(img_bytes)
            cache_key = f"vision:ahash:{ahash}:ctx"
            cached = await _redis.get(cache_key)
            if cached:
                try:
                    txt = cached.decode('utf-8') if isinstance(cached, (bytes, bytearray)) else str(cached)
                    data = json.loads(txt)
                    if isinstance(data, dict):
                        logging.info("Vision ctx cache hit")
                        return data
                except Exception:
                    pass
        except Exception:
            ahash = None
        image_data = base64.b64encode(img_bytes).decode('utf-8')
        ct = (response.headers.get('Content-Type') or '').lower()
        if ct.startswith('image/'):
            image_mime = ct.split(';')[0].strip()
        else:
            kind = imghdr.what(None, h=img_bytes)
            mime_map = {
                'jpeg': 'image/jpeg', 'jpg': 'image/jpeg', 'png': 'image/png',
                'gif': 'image/gif', 'webp': 'image/webp', 'bmp': 'image/bmp'
            }
            image_mime = mime_map.get(kind, 'image/jpeg')
        
        schema_prompt = (
            "ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ ì•„ëž˜ ìŠ¤í‚¤ë§ˆì˜ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.\n"
            "- ìƒìƒ/ì¶”ì¸¡ ê¸ˆì§€, ë³´ì´ëŠ” ë‹¨ì„œ ìœ„ì£¼. ì•”ì‹œëŠ” narrative_axesì—ì„œ 'hint'ë¡œ ê°„ë‹¨ížˆ.\n"
            "- is_selfie: ì…€ì¹´ì¸ì§€ íŒë‹¨ (ê±°ìš¸ ì…€ì¹´, íŒ” ë»—ì–´ ì°ê¸°, ì…€ì¹´ë´‰ ë“± ëª¨ë‘ í¬í•¨)\n"
            "- person_count: ë³´ì´ëŠ” ì¸ë¬¼ ìˆ˜ (0=ì¸ë¬¼ì—†ìŒ)\n"
            "- style_mode: ìž¥ë©´ì˜ ìŠ¤íƒ€ì¼ì„ 'snap' ë˜ëŠ” 'genre' ì¤‘ í•˜ë‚˜ë¡œ ì œì•ˆ.\n"
            "- confidence: 0~1 ì‹¤ìˆ˜ë¡œ íŒë‹¨ ì‹ ë¢°ë„. 0.5ëŠ” ì¤‘ë¦½.\n"
            "- cues: íŒë‹¨ì— ì‚¬ìš©í•œ ê·¼ê±° í‚¤ì›Œë“œ ë°°ì—´(ì˜ˆ: selfie, weapon, magic, everyday, cafe ë“±).\n"
            "ìŠ¤í‚¤ë§ˆ: {\n"
            "  subjects:[{role?:string, age_range?:string, gender?:string, attire?:string, emotion?:string, pose?:string}],\n"
            "  relations:[{a_idx:int, b_idx:int, relation:string, evidence:string}],\n"
            "  camera:{angle?:string, distance?:string, lens_hint?:string, is_selfie?:boolean},\n"
            "  palette:[string], genre_cues:[string],\n"
            "  narrative_axes:{desire?:string, conflict?:string, stakes?:string},\n"
            "  tone:{mood_words?:[string], pace?:string},\n"
            "  person_count:int,\n"
            "  style_mode?:string,\n"
            "  confidence?:number,\n"
            "  cues?:[string]\n"
            "}"
        )
        
        # Claude Vision ì‹œë„
        if model == 'claude':
            try:
                txt = await get_claude_completion(
                    schema_prompt,
                    max_tokens=1800,
                    model=CLAUDE_MODEL_PRIMARY,
                    image_base64=image_data,
                    image_mime=image_mime
                )
                
                # JSON ì¶”ì¶œ
                if '```json' in txt:
                    txt = txt.split('```json')[1].split('```')[0].strip()
                elif '```' in txt:
                    txt = txt.split('```')[1].split('```')[0].strip()
                    
                data = json.loads(txt)
                if isinstance(data, dict):
                    logging.info("Claude Vision narrative context successful")
                    try:
                        if ahash:
                            await _redis.setex(cache_key, 86400, json.dumps(data, ensure_ascii=False))
                    except Exception:
                        pass
                    return data
            except Exception as e:
                logging.error(f"Claude Vision narrative context failed: {e}")
        
        # Gemini í´ë°±
        try:
            txt = await get_gemini_completion(schema_prompt + f"\nimage_url: {image_url}", max_tokens=600, model='gemini-2.5-pro')
            data = json.loads(txt)
            if isinstance(data, dict):
                try:
                    if ahash:
                        await _redis.setex(cache_key, 86400, json.dumps(data, ensure_ascii=False))
                except Exception:
                    pass
                return data
        except Exception:
            pass
        return {}
    except Exception:
        return {}

async def analyze_image_tags_and_context(image_url: str, model: str = 'claude') -> tuple[dict, dict]:
    """ë‹¨ì¼ Vision í˜¸ì¶œë¡œ íƒœê·¸(tags)ì™€ ì»¨í…ìŠ¤íŠ¸(context)ë¥¼ ë™ì‹œì— ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì‹¤íŒ¨ ì‹œ í˜¸ì¶œìžê°€ í´ë°±ì„ ì‚¬ìš©í•˜ë„ë¡ ì˜ˆì™¸ë¥¼ ë˜ì§‘ë‹ˆë‹¤.
    """
    try:
        logging.info("Vision combine: start (unified tags+context)")
        import requests, base64, json
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° MIME ì¶”ì •
        resp = requests.get(image_url, timeout=10)
        img_bytes = resp.content
        ct = (resp.headers.get('Content-Type') or '').lower()
        if ct.startswith('image/'):
            image_mime = ct.split(';')[0].strip()
        else:
            kind = imghdr.what(None, h=img_bytes)
            image_mime = {
                'jpeg': 'image/jpeg', 'jpg': 'image/jpeg', 'png': 'image/png',
                'gif': 'image/gif', 'webp': 'image/webp', 'bmp': 'image/bmp'
            }.get(kind, 'image/jpeg')
        image_b64 = base64.b64encode(img_bytes).decode('utf-8')
        # í†µí•© ìŠ¤í‚¤ë§ˆ í”„ë¡¬í”„íŠ¸(ê±´ì¡°/ì‚¬ì‹¤ ì „ìš©)
        prompt = (
            "ì´ë¯¸ì§€ë¥¼ ì‚¬ì‹¤ì ìœ¼ë¡œë§Œ ê¸°ìˆ í•˜ë¼. ì¶”ì¸¡/ë¹„ìœ /ê°íƒ„ ê¸ˆì§€. ìž¥ë¥´/ë¬´ë“œ í˜•ìš©ì‚¬ ê¸ˆì§€(fantasy/noir/surreal/mysterious/cinematic ë“±). ëª¨ë¥´ë©´ 'unknown'.\n"
            "JSON ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ë¼.\n"
            "{\n"
            "  \"tags\": {\n"
            "    \"place\": one_of['cafe','street','park','campus','indoor','home','office','store','beach','mountain','unknown'],\n"
            "    \"objects\": [noun-only strings],\n"
            "    \"lighting\": one_of['daylight','indoor','night','overcast','sunset','unknown'],\n"
            "    \"weather\": one_of['clear','cloudy','rain','snow','unknown'],\n"
            "    \"colors\": [basic color words],\n"
            "    \"textures\": [noun-only],\n"
            "    \"sounds_implied\": [noun-only],\n"
            "    \"smells_implied\": [noun-only],\n"
            "    \"temperature\": one_of['warm','cool','neutral','unknown'],\n"
            "    \"movement\": one_of['still','slight','visible','unknown'],\n"
            "    \"focal_point\": string,\n"
            "    \"story_hooks\": [noun phrases],\n"
            "    \"in_image_text\": [exact text], \"numeric_phrases\": [string]\n"
            "  },\n"
            "  \"context\": {\n"
            "    \"person_count\": number,\n"
            "    \"camera\": {angle:one_of['eye','overhead','low','unknown'], distance:one_of['wide','medium','close','unknown'], is_selfie:boolean},\n"
            "    \"style_mode\": one_of['snap','genre'], \"confidence\": number\n"
            "  }\n"
            "}"
        )
        # Claude ìš°ì„  í˜¸ì¶œ(ê±´ì¡° ëª¨ë“œ: ë‚®ì€ ì˜¨ë„/íƒ‘P, í† í° ì¶•ì†Œ)
        txt = await get_claude_completion(
            prompt,
            temperature=0.1,
            max_tokens=1000,
            model=CLAUDE_MODEL_PRIMARY,
            image_base64=image_b64,
            image_mime=image_mime
        )
        if '```json' in txt:
            txt = txt.split('```json')[1].split('```')[0].strip()
        elif '```' in txt:
            txt = txt.split('```')[1].split('```')[0].strip()
        data = json.loads(txt)
        if not isinstance(data, dict):
            raise ValueError("combined response is not dict")
        logging.info("Vision combine: success (provider=Claude)")
        return data.get('tags') or {}, data.get('context') or {}
    except Exception:
        # í˜¸ì¶œìž í´ë°±
        raise

def build_image_grounding_block(tags: dict, pov: str | None = None, style_prompt: str | None = None, ctx: dict | None = None, username: str | None = None, story_mode: str | None = None, user_hint: str = "") -> str:
    # ì‹œì  ìžë™ ê²°ì • ë¡œì§
    if ctx and not pov:
        # SNAP ëª¨ë“œ: ëª¨ë“  ì‚¬ì§„ì€ ìœ ì € ë³¸ì¸ì˜ ê²½í—˜/ìˆœê°„ â†’ ë¬´ì¡°ê±´ 1ì¸ì¹­
        if story_mode == "snap":
            # ì—°ì• /ë¡œë§¨ìŠ¤ í‚¤ì›Œë“œ ì ìˆ˜í™” ì‹œìŠ¤í…œ (ì •ì œ + ê°€ì¤‘ì¹˜ ì°¨ë“±í™”)
            keyword_scores = {
                # í™•ì‹¤í•œ ë¡œë§¨ìŠ¤ ì˜ë„ - 2ì 
                "ì—°ì• ": 2, "ë°ì´íŠ¸": 2, "ì¢‹ì•„í•´": 2, "ì‚¬ëž‘": 2, "ê³ ë°±": 2,
                "ì²«í‚¤ìŠ¤": 2, "í‚¤ìŠ¤": 2, "í¬ì˜¹": 2, "ì•ˆì•„": 2, "ìŠ¤í‚¨ì‹­": 2,
                "ë¡œë§¨í‹±": 2, "ë¡œë§¨ìŠ¤": 2,
                
                # ê°•í•œ ë¡œë§¨ìŠ¤/ì„±ì  í‘œí˜„ - 2ì 
                "ì•¼í•œ": 2, "ì„¹ì‹œ": 2, "ê´€ëŠ¥": 2, "ìœ í˜¹": 2, "ë°€ë‹¹": 2, "ì¸": 2, "ë‹¬ë‹¬": 2,
                "ì¹¨ëŒ€": 2, "ìˆ¨ì†Œë¦¬": 2, "ì²´ì˜¨": 2, "ì†ì‚­": 2,
                
                # ì„œë¸Œì»¬ì³ ë¡œë§¨ìŠ¤ - 1ì 
                "ì™€ì´í”„": 1, "í—ˆë‹ˆ": 1, "ì¸¤ë°ë ˆ": 1, "ì–€ë°ë ˆ": 1, "ë°ë ˆ": 1,
                
                # ì—¬ì„±í–¥ - 1ì 
                "ë‚¨ì£¼": 1, "ì§‘ì°©": 1, "ì†Œìœ ìš•": 1,
                
                # ë‚¨ì„±í–¥ - 1ì 
                "ížˆë¡œì¸": 1, "ì—¬ì£¼": 1, "ê³µëžµ": 1,
                
                # ì•½í•œ ë¡œë§¨ìŠ¤ ì•”ì‹œ - 0.5ì  (ë‹¨ë…ìœ¼ë¡œëŠ” ë¶ˆì¶©ë¶„)
                "ì„¤ë ˆ": 0.5, "ì†ìž¡": 0.5, "ëª¨ì—": 0.5,
                "ì€ë°€": 0.5,
            }
            
            # ë³µí•© í‘œí˜„ (ë¬¸ë§¥ í¬í•¨)
            compound_expressions = {
                # ë™ì‚¬í˜• ë³µí•© í‘œí˜„ - 2ì 
                "ì—°ì• í•˜ê³ ": 2, "ì—°ì• í•˜ëŠ”": 2, "ë°ì´íŠ¸í•˜ê³ ": 2, "ë°ì´íŠ¸í•˜ëŠ”": 2,
                "ì‚¬ëž‘í•˜ê³ ": 2, "ì‚¬ëž‘í•˜ëŠ”": 2, "ì¢‹ì•„í•˜ê³ ": 2, "ì¢‹ì•„í•˜ëŠ”": 2,
                
                # ê´€ê³„ í‚¤ì›Œë“œ (í™•ì‹¤í•œ ë¡œë§¨ìŠ¤) - 2ì 
                "ì—¬ìžì¹œêµ¬": 2, "ì—¬ì¹œ": 2, "ë‚¨ìžì¹œêµ¬": 2, "ë‚¨ì¹œ": 2,
                "ì• ì¸": 2, "ì—°ì¸": 2,
                
                # êµ¬ì–´ì²´ ì§€ì¹­ - 1.5ì 
                "ì–˜ëž‘": 1.5, "ìŸ¤ëž‘": 1.5, "ì € ì‚¬ëžŒì´ëž‘": 1.5,
                "ì´ ì‚¬ëžŒì´ëž‘": 1.5, "ì´ ì‚¬ëžŒê³¼": 1.5, "ì´ ì—¬ìžëž‘": 1.5, "ì´ ë‚¨ìžëž‘": 1.5,
                "ê·¸ë…€ì™€": 1.5, "ê·¸ì™€": 1.5, "ê·¸ë…€ëž‘": 1.5, "ê·¸ëž‘": 1.5,
                
                # ë™ë°˜ í‘œí˜„ - 2ì  (ì´ë¯¸ì§€ ë¬¸ë§¥ì—ì„œëŠ” ê°•í•œ ë¡œë§¨ìŠ¤ ì‹ í˜¸)
                "ê°™ì´": 2, "í•¨ê»˜": 2,
            }
            
            # ìžê¸° ì²´í—˜ í‚¤ì›Œë“œ (ì´ê²Œ ìžˆìœ¼ë©´ ë¡œë§¨ìŠ¤ ì ìˆ˜ ë¬´ì‹œ)
            self_keywords = [
                "ë‚´ê°€ ì´ë ‡ê²Œ", "ë‚˜ë„ ì´ëŸ°", "ì´ëŸ° ëŠë‚Œ", "ì´ëŸ° ìˆœê°„",
                "ë‚˜ì˜€ìœ¼ë©´", "ë‚˜ë¼ë©´", "ë‚´ ìž…ìž¥", "ë‚˜í•œí…Œë„", "ë‚´ ëª¨ìŠµ"
            ]
            
            # ì ìˆ˜ ê³„ì‚°
            hint_lower = user_hint.lower()
            romance_score = 0.0
            
            # ë³µí•© í‘œí˜„ ë¨¼ì € ì²´í¬ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
            for expr, score in compound_expressions.items():
                if expr in hint_lower:
                    romance_score += score
            
            # ë‹¨ì¼ í‚¤ì›Œë“œ ì²´í¬
            for keyword, score in keyword_scores.items():
                if keyword in hint_lower:
                    romance_score += score
            
            has_self = any(kw in user_hint for kw in self_keywords)
            
            # 1.5ì  ì´ìƒì´ê³ , ìžê¸° ì²´í—˜ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ë¡œë§¨ìŠ¤ ëª¨ë“œ
            if romance_score >= 1.5 and not has_self:
                pov = "1ì¸ì¹­ 'ë‚˜'(ìœ ì €). ì´ë¯¸ì§€ ì† ì¸ë¬¼ì€ 'ê·¸ë…€/ê·¸'ë¡œ ì§€ì¹­í•˜ê³ , ìœ ì €ì™€ì˜ ë¡œë§¨í‹±í•œ ìƒí˜¸ìž‘ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ ."
            else:
                # ê¸°ë³¸: ì´ë¯¸ì§€ ì† ì¸ë¬¼ = ë‚˜
                pov = "1ì¸ì¹­ 'ë‚˜'"
        else:
            # GENRE ëª¨ë“œ: ë¡œë§¨ìŠ¤ ìž¥ë¥´ëŠ” í•­ìƒ 1ì¸ì¹­
            person_count = ctx.get('person_count', 0)
            camera = ctx.get('camera', {})
            is_selfie = camera.get('is_selfie', False)
            
            is_romance = False
            if user_hint:
                hint_lower = user_hint.lower()
                romance_score = 0.0
                
                # ë³µí•© í‘œí˜„ ì²´í¬
                compound_expressions = {
                    "ì—°ì• í•˜ê³ ": 2, "ì—°ì• í•˜ëŠ”": 2, "ë°ì´íŠ¸í•˜ê³ ": 2, "ë°ì´íŠ¸í•˜ëŠ”": 2,
                    "ì‚¬ëž‘í•˜ê³ ": 2, "ì‚¬ëž‘í•˜ëŠ”": 2, "ì¢‹ì•„í•˜ê³ ": 2, "ì¢‹ì•„í•˜ëŠ”": 2,
                    "ì—¬ìžì¹œêµ¬": 2, "ì—¬ì¹œ": 2, "ë‚¨ìžì¹œêµ¬": 2, "ë‚¨ì¹œ": 2,
                    "ì• ì¸": 2, "ì—°ì¸": 2,
                    "ì–˜ëž‘": 1.5, "ìŸ¤ëž‘": 1.5, "ì € ì‚¬ëžŒì´ëž‘": 1.5,
                    "ì´ ì‚¬ëžŒì´ëž‘": 1.5, "ì´ ì‚¬ëžŒê³¼": 1.5, "ì´ ì—¬ìžëž‘": 1.5, "ì´ ë‚¨ìžëž‘": 1.5,
                    "ê·¸ë…€ì™€": 1.5, "ê·¸ì™€": 1.5, "ê·¸ë…€ëž‘": 1.5, "ê·¸ëž‘": 1.5,
                    "ê°™ì´": 2, "í•¨ê»˜": 2,
                }
                
                for expr, score in compound_expressions.items():
                    if expr in hint_lower:
                        romance_score += score
                
                # ë‹¨ì¼ í‚¤ì›Œë“œ ì²´í¬
                keyword_scores = {
                    "ì—°ì• ": 2, "ë°ì´íŠ¸": 2, "ì¢‹ì•„í•´": 2, "ì‚¬ëž‘": 2, "ê³ ë°±": 2,
                    "ì²«í‚¤ìŠ¤": 2, "í‚¤ìŠ¤": 2, "í¬ì˜¹": 2, "ì•ˆì•„": 2, "ìŠ¤í‚¨ì‹­": 2,
                    "ë¡œë§¨í‹±": 2, "ë¡œë§¨ìŠ¤": 2,
                    "ì•¼í•œ": 2, "ì„¹ì‹œ": 2, "ê´€ëŠ¥": 2, "ìœ í˜¹": 2, "ë°€ë‹¹": 2, "ì¸": 2, "ë‹¬ë‹¬": 2,
                    "ì¹¨ëŒ€": 2, "ìˆ¨ì†Œë¦¬": 2, "ì²´ì˜¨": 2, "ì†ì‚­": 2,
                    "ì™€ì´í”„": 1, "í—ˆë‹ˆ": 1, "ì¸¤ë°ë ˆ": 1, "ì–€ë°ë ˆ": 1, "ë°ë ˆ": 1,
                    "ë‚¨ì£¼": 1, "ì§‘ì°©": 1, "ì†Œìœ ìš•": 1,
                    "ížˆë¡œì¸": 1, "ì—¬ì£¼": 1, "ê³µëžµ": 1,
                    "ì„¤ë ˆ": 0.5, "ì†ìž¡": 0.5, "ëª¨ì—": 0.5, "ì€ë°€": 0.5,
                }
                
                for keyword, score in keyword_scores.items():
                    if keyword in hint_lower:
                        romance_score += score
                
                # ìžê¸° ì²´í—˜ í‚¤ì›Œë“œ ì²´í¬
                self_keywords = [
                    "ë‚´ê°€ ì´ë ‡ê²Œ", "ë‚˜ë„ ì´ëŸ°", "ì´ëŸ° ëŠë‚Œ", "ì´ëŸ° ìˆœê°„",
                    "ë‚˜ì˜€ìœ¼ë©´", "ë‚˜ë¼ë©´", "ë‚´ ìž…ìž¥", "ë‚˜í•œí…Œë„", "ë‚´ ëª¨ìŠµ"
                ]
                has_self = any(kw in user_hint for kw in self_keywords)
                
                # 1.5ì  ì´ìƒì´ê³ , ìžê¸° ì²´í—˜ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ë¡œë§¨ìŠ¤
                is_romance = romance_score >= 1.5 and not has_self
            
            # âœ… ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì‹œì  ê²°ì •
            if is_romance:  # âœ… ë¡œë§¨ìŠ¤ê°€ ìµœìš°ì„ !
                pov = "1ì¸ì¹­ 'ë‚˜'(ìœ ì €). ì´ë¯¸ì§€ ì† ì¸ë¬¼ì€ 'ê·¸ë…€/ê·¸'ë¡œ ì§€ì¹­í•˜ê³ , ìœ ì €ì™€ì˜ ë¡œë§¨í‹±í•œ ìƒí˜¸ìž‘ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ ."
            elif person_count == 0:
                pov = "1ì¸ì¹­ 'ë‚˜'"
            elif is_selfie:
                pov = "1ì¸ì¹­ 'ë‚˜'"
            else:
                pov = "3ì¸ì¹­ ê´€ì°°ìž"
    
    place = _as_text(tags.get("place")).strip()
    objects = ", ".join([str(x) for x in (tags.get("objects") or []) if str(x).strip()])
    lighting = _as_text(tags.get("lighting")).strip()
    weather = _as_text(tags.get("weather")).strip()
    mood = _as_text(tags.get("mood")).strip()
    
    # ê°•í™”ëœ íƒœê·¸ ì •ë³´
    colors = ", ".join([str(x) for x in (tags.get("colors") or []) if str(x).strip()])
    textures = ", ".join([str(x) for x in (tags.get("textures") or []) if str(x).strip()])
    sounds = ", ".join([str(x) for x in (tags.get("sounds_implied") or []) if str(x).strip()])
    smells = ", ".join([str(x) for x in (tags.get("smells_implied") or []) if str(x).strip()])
    temperature = _as_text(tags.get("temperature")).strip()
    movement = _as_text(tags.get("movement")).strip()
    focal_point = _as_text(tags.get("focal_point")).strip()
    story_hooks = tags.get("story_hooks") or []
    
    # ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸(ìµœìš°ì„  ì‚¬ì‹¤)
    in_texts = [str(x) for x in (tags.get("in_image_text") or []) if str(x).strip()]
    numeric_phrases = [str(x) for x in (tags.get("numeric_phrases") or []) if str(x).strip()]
    
    # ðŸ†• "unknown" í•„í„°ë§ í—¬í¼
    def _valid(val: str) -> bool:
        return val and val.lower() != "unknown"

    lines = [
        "[ê³ ì • ì¡°ê±´ - ì´ë¯¸ì§€ ê·¸ë¼ìš´ë”©]",
        ("[ìµœìš°ì„  ì‚¬ì‹¤ - ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸] " + "; ".join(in_texts)) if in_texts else None,
        ("[ìˆ˜ì¹˜/ë‹¨ìœ„ ë¬¸êµ¬] " + "; ".join(numeric_phrases)) if numeric_phrases else None,
        f"ìž¥ì†Œ: {place}" if _valid(place) else None,
        f"ì˜¤ë¸Œì íŠ¸: {objects}" if objects else None,
        f"ì¡°ëª…/ì‹œê°„ëŒ€: {lighting}" if _valid(lighting) else None,
        f"ë‚ ì”¨: {weather}" if _valid(weather) else None,
        f"ë¬´ë“œ: {mood}" if _valid(mood) else None,
        f"ì£¼ìš” ìƒ‰ìƒ: {colors}" if colors else None,
        f"ì§ˆê°/ìž¬ì§ˆ: {textures}" if textures else None,
        f"ì•”ì‹œë˜ëŠ” ì†Œë¦¬: {sounds}" if sounds else None,
        f"ì•”ì‹œë˜ëŠ” ëƒ„ìƒˆ: {smells}" if smells else None,
        f"ì²´ê° ì˜¨ë„: {temperature}" if _valid(temperature) else None,
        f"ì›€ì§ìž„/ë™ì  ìš”ì†Œ: {movement}" if _valid(movement) else None,
        f"ì‹œì„  ì§‘ì¤‘ì : {focal_point}" if focal_point else None,
        "",
        "ê·œì¹™: ì´ë¯¸ì§€ì— í¬í•¨ëœ í…ìŠ¤íŠ¸(ìœ„ ìµœìš°ì„  ì‚¬ì‹¤)ë¥¼ 1ìˆœìœ„ë¡œ ë°˜ì˜í•˜ë¼. ìˆ«ìž/ë‹¨ìœ„ë¥¼ ì ˆëŒ€ ì™œê³¡í•˜ì§€ ë§ë¼.",
        "ê·œì¹™: ìœ„ ëª¨ë“  ìš”ì†Œë“¤ì„ ìžì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ì–´ ìƒìƒí•œ ìž¥ë©´ì„ ë§Œë“¤ì–´ë¼.",
        "ê·œì¹™: ì˜¤ê°ì„ í™œìš©í•´ ë…ìžê°€ ê·¸ ê³µê°„ì— ìžˆëŠ” ë“¯í•œ ëª°ìž…ê°ì„ ì œê³µí•˜ë¼.",
        "ê·œì¹™: ì´ë¯¸ì§€ì— ì¡´ìž¬í•˜ì§€ ì•ŠëŠ” ìš”ì†Œë¥¼ ì¶”ê°€í•˜ì§€ ë§ë¼.",
        "ê·œì¹™: ë©”íƒ€ë°œì–¸ ê¸ˆì§€. show-don't-tell. ì¸ë¬¼ì˜ í–‰ë™ê³¼ ëŒ€ì‚¬ë¡œ í‘œí˜„í•˜ë¼.",
    ]
    
    # ìŠ¤í† ë¦¬ í›… ì¶”ê°€
    if story_hooks:
        lines.append("")
        lines.append("ìŠ¤í† ë¦¬ ì „ê°œ ê°€ëŠ¥ ìš”ì†Œ:")
        for hook in story_hooks[:3]:  # ìµœëŒ€ 3ê°œë§Œ
            lines.append(f"- {hook}")
    # ì¶”ê°€ ë§¥ë½(ì¸ë¬¼/ê´€ê³„/ì—°ì¶œ)
    if isinstance(ctx, dict) and ctx:
        subs = ctx.get("subjects") or []
        if subs:
            sub_strs = []
            for i, s in enumerate(subs):
                desc = ", ".join([
                    str(s.get("role")) if s.get("role") else "",
                    str(s.get("age_range")) if s.get("age_range") else "",
                    str(s.get("gender")) if s.get("gender") else "",
                    str(s.get("attire")) if s.get("attire") else "",
                    str(s.get("emotion")) if s.get("emotion") else "",
                    str(s.get("pose")) if s.get("pose") else "",
                ])
                sub_strs.append(f"#{i}: {desc}")
            lines.append("ì¸ë¬¼ ë‹¨ì„œ: " + "; ".join([x for x in sub_strs if x.strip()]))
        rels = ctx.get("relations") or []
        if rels:
            rel_strs = []
            for r in rels:
                rel_strs.append(f"{r.get('a_idx')}â†”{r.get('b_idx')}: {r.get('relation')} ({r.get('evidence')})")
            lines.append("ê´€ê³„ ë‹¨ì„œ: " + "; ".join(rel_strs))
        cam = ctx.get("camera") or {}
        cam_line = ", ".join([x for x in [cam.get("angle"), cam.get("distance"), cam.get("lens_hint")] if x])
        if cam_line:
            lines.append("ì—°ì¶œ: " + cam_line)
        pal = ctx.get("palette") or []
        if pal:
            lines.append("ìƒ‰ì¡°: " + ", ".join([str(x) for x in pal]))
        genres = ctx.get("genre_cues") or []
        if genres:
            lines.append("ìž¥ë¥´ ë‹¨ì„œ: " + ", ".join([str(x) for x in genres]))
        axes = ctx.get("narrative_axes") or {}
        axes_line = ", ".join([f"ìš•êµ¬:{axes.get('desire')}" if axes.get('desire') else "", f"ê°ˆë“±:{axes.get('conflict')}" if axes.get('conflict') else "", f"ìœ„í—˜:{axes.get('stakes')}" if axes.get('stakes') else ""]).strip(', ')
        if axes_line:
            lines.append("ì„œì‚¬ ì¶•(ížŒíŠ¸): " + axes_line)
    if pov:
        # 1ì¸ì¹­ ì‹œì ì¼ ë•Œ username ì‚¬ìš©
        if "1ì¸ì¹­" in pov and username:
            lines.append(f"ì‹œì : 1ì¸ì¹­ 'ë‚˜' (í™”ìžì˜ ì´ë¦„: {username})")
            lines.append(f"ê·œì¹™: 1ì¸ì¹­ í™”ìž 'ë‚˜'ì˜ ì´ë¦„ì´ {username}ìž„ì„ ìžì—°ìŠ¤ëŸ½ê²Œ ë“œëŸ¬ë‚´ë¼.")
        else:
            lines.append(f"ì‹œì : {pov} (ìžì—°ìŠ¤ëŸ¬ìš´ ë‚´ì /ê·¼ì ‘ ì‹œì )")
    if style_prompt:
        lines.append(f"ë¬¸ì²´: {style_prompt}")
    return "\n".join([ln for ln in lines if ln])

async def generate_image_prompt_from_story(story_text: str, original_tags: dict = None) -> str:
    """ìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤."""
    try:
        prompt = f"""ë‹¤ìŒ ìŠ¤í† ë¦¬ì˜ í•µì‹¬ ìž¥ë©´ì„ í‘œí˜„í•  ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ì–´ë¡œ ìž‘ì„±í•˜ì„¸ìš”.

ìŠ¤í† ë¦¬:
{story_text[:800]}

ìš”êµ¬ì‚¬í•­:
- ì˜ì–´ë¡œ ìž‘ì„±
- êµ¬ì²´ì ì¸ ì‹œê° ë¬˜ì‚¬
- 50ë‹¨ì–´ ì´ë‚´
- í”„ë¡¬í”„íŠ¸ë§Œ ì¶œë ¥ (ì„¤ëª… ì—†ìŒ)"""

        if original_tags:
            if original_tags.get('palette'):
                prompt += f"\nìƒ‰ê° ì°¸ê³ : {original_tags['palette']}"
            if original_tags.get('mood'):
                prompt += f"\në¶„ìœ„ê¸°: {original_tags['mood']}"

        response = await get_claude_completion(prompt, temperature=0.2)
        return response.strip()[:200]  # ìµœëŒ€ 200ìž
    except Exception as e:
        logger.error(f"Failed to generate image prompt: {e}")
        return "A scene from a Korean webnovel, cinematic lighting, emotional atmosphere"

async def write_story_from_image_grounded(image_url: str, user_hint: str = "", pov: str | None = None, style_prompt: str | None = None,
                                          story_mode: str | None = None, username: str | None = None,
                                          model: Literal["gemini","claude","gpt"] = "gemini", sub_model: str | None = "gemini-2.5-pro",
                                          vision_tags: dict | None = None, vision_ctx: dict | None = None) -> str:
    """ì´ë¯¸ì§€ íƒœê¹…â†’ê³ ì •ì¡°ê±´ í”„ë¡¬í”„íŠ¸â†’ì§‘í•„(ìžê°€ê²€ì¦ì€ 1íŒ¨ìŠ¤ ë‚´ìž¥)"""
    import time
    t0 = time.time()
    
    # Stage-1 lightweight grounding (fallback-friendly)
    kw2, caption = stage1_keywords_from_image_url(image_url)
    t1 = time.time()
    logging.info(f"[PERF] Stage-1 grounding: {(t1-t0)*1000:.0f}ms")
    
    # Stage-2: Vision ê²°ê³¼ (ì „ë‹¬ë°›ì•˜ìœ¼ë©´ ìž¬ì‚¬ìš©, ì—†ìœ¼ë©´ í˜¸ì¶œ)
    if vision_tags and vision_ctx:
        tags, ctx = vision_tags, vision_ctx
        t2 = time.time()
        logging.info(f"[PERF] Vision reused from auto detection: 0ms")
    else:
        try:
            tags, ctx = await analyze_image_tags_and_context(image_url, model='claude')
            t2 = time.time()
            logging.info(f"[PERF] Vision combined: {(t2-t1)*1000:.0f}ms")
        except Exception as e:
            logging.warning(f"[PERF] Vision combined failed, fallback: {e}")
            tags = await tag_image_keywords(image_url, model='claude')
            ctx = await extract_image_narrative_context(image_url, model='claude')
            t2 = time.time()
            logging.info(f"[PERF] Vision fallback (2 calls): {(t2-t1)*1000:.0f}ms")
    # ìŠ¤ëƒ… ëª¨ë“œì—ì„œëŠ” ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ì´ë¦„ ì£¼ìž… ê¸ˆì§€
    block = build_image_grounding_block(
        tags,
        pov=pov,
        style_prompt=style_prompt,
        ctx=ctx,
        username=None if story_mode == "snap" else username,
        story_mode=story_mode,
        user_hint=user_hint  # ë¡œë§¨ìŠ¤ í‚¤ì›Œë“œ ì ìˆ˜í™”ë¥¼ ìœ„í•´ ì „ë‹¬
    )
    if kw2:
        block += "\nìŠ¤ëƒ… í‚¤ì›Œë“œ(ê²½ëŸ‰ íƒœê¹…): " + ", ".join(kw2)
    if caption:
        block += f"\nê²½ëŸ‰ ìº¡ì…˜: {caption}"

    # í•„ìˆ˜/ê¸ˆì§€ í‚¤ì›Œë“œ êµ¬ì„±(ê°•í™” ëª¨ë“œ)
    required_tokens: list[str] = []
    for t in [tags.get('place'), tags.get('mood'), tags.get('lighting'), tags.get('weather')]:
        if t:
            required_tokens.append(str(t))
    # objects ìµœëŒ€ 4ê°œ
    for o in (tags.get('objects') or [])[:4]:
        if o:
            required_tokens.append(str(o))
    # palette/genreì—ì„œ 0~2ê°œ ì¶”ê°€
    for extra in (ctx.get('palette') or [])[:1]:
        required_tokens.append(str(extra))
    for extra in (ctx.get('genre_cues') or [])[:1]:
        required_tokens.append(str(extra))
    # ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸/ìˆ˜ì¹˜ ë¬¸êµ¬ë¥¼ ìš°ì„  í¬í•¨ + OCR ë³´ê°•
    numeric_phrases = list(tags.get('numeric_phrases') or [])[:2]
    in_texts_tag = list(tags.get('in_image_text') or [])[:2]
    # OCRë¡œ ìˆ«ìž/ë‹¨ìœ„ë§Œ ë³´ê°•(ì—†ëŠ” ê²½ìš°ì—ë§Œ)
    try:
        if not numeric_phrases:
            more = _extract_numeric_phrases_ocr_bytes(_http_get_bytes(image_url))
            numeric_phrases = more[:2] if more else []
    except Exception:
        pass
    for t in numeric_phrases:
        required_tokens.append(str(t))
    for t in in_texts_tag:
        required_tokens.append(str(t))
    # ìµœëŒ€ 10ê°œë¡œ ì œí•œ
    required_tokens = [x for x in required_tokens if x][:10]

    # ê¸ˆì§€ í‚¤ì›Œë“œ(ì¼ë°˜ + ìž¥ì†Œ ì¶©ëŒ)
    ban_general = {"í˜„ê´€", "ë³µë„", "êµì‹¤", "ìš´ë™ìž¥", "í•´ë³€", "ë°”ë‹·ê°€", "ì‚¬ë§‰", "ì •ì˜¤ì˜ í–‡ì‚´", "í•œë‚®ì˜ íƒœì–‘"}
    ban_by_place = {
        "office": {"êµì‹¤", "ì£¼ë°©", "ì¹¨ì‹¤", "ìš´ë™ìž¥", "í•´ë³€", "ë“¤íŒ"},
        "classroom": {"ì‚¬ë¬´ì‹¤", "ì£¼ë°©", "í•´ë³€"},
        "home": {"ì‚¬ë¬´ì‹¤", "êµì‹¤", "í•´ë³€"},
    }
    place_lc = (tags.get('place') or '').lower()
    place_key = None
    for k in ban_by_place.keys():
        if k in place_lc:
            place_key = k
            break
    ban_tokens = set(ban_general)
    if place_key:
        ban_tokens |= ban_by_place.get(place_key, set())

    # ê³ ì • ë¸”ë¡ì— í•„ìˆ˜/ê¸ˆì§€ ëª…ì‹œ ì¶”ê°€
    if required_tokens:
        block += "\ní•„ìˆ˜ í‚¤ì›Œë“œ(ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ìš°ì„ ): " + ", ".join(required_tokens)
    if ban_tokens:
        block += "\nê¸ˆì§€ í‚¤ì›Œë“œ: " + ", ".join(sorted(ban_tokens))
    # ì‹œì ì— ë”°ë¥¸ ì§€ì‹œì‚¬í•­ ì¡°ì •
    pov_instruction = ""
    if story_mode == "snap":
        # ì¼ìƒ: ì‹¤ëª…/ë‹‰ë„¤ìž„ íšŒí”¼. 1ì¸ì¹­ì´ë©´ 'ë‚˜', 3ì¸ì¹­ì´ë©´ 'ê·¸/ê·¸ë…€'ë§Œ ì‚¬ìš©
        if "1ì¸ì¹­" in block:
            pov_instruction = "\nì‹œì : 1ì¸ì¹­ 'ë‚˜'. ì‚¬ëžŒ ì´ë¦„(ê³ ìœ ëª…) ì‚¬ìš© ê¸ˆì§€. ëŒ€ëª…ì‚¬ëŠ” 'ë‚˜'ë§Œ ì‚¬ìš©."
        else:
            pov_instruction = "\nì‹œì : 3ì¸ì¹­. ì¸ë¬¼ ì§€ì¹­ì€ 'ê·¸' ë˜ëŠ” 'ê·¸ë…€'ë§Œ ì‚¬ìš©. ì‚¬ëžŒ ì´ë¦„(ê³ ìœ ëª…) ì‚¬ìš© ê¸ˆì§€."
    else:
        if "1ì¸ì¹­" in block:
            pov_instruction = "\nì‹œì : 1ì¸ì¹­ 'ë‚˜'ë¡œ ì„œìˆ . ë‚´ë©´ ë¬˜ì‚¬ì™€ ê°ê°ì„ ìƒìƒí•˜ê²Œ."
            # usernameì´ blockì— í¬í•¨ë˜ì–´ ìžˆìœ¼ë©´ ì¶”ê°€ ì§€ì‹œ
            if username and username in block:
                pov_instruction += f"\ní™”ìž 'ë‚˜'ì˜ ì´ë¦„ì€ {username}. ëŒ€í™”ë‚˜ ìƒí™©ì—ì„œ ìžì—°ìŠ¤ëŸ½ê²Œ ì´ë¦„ì´ ë“œëŸ¬ë‚˜ê²Œ í•˜ë¼."
        elif "3ì¸ì¹­" in block:
            pov_instruction = "\nì‹œì : 3ì¸ì¹­ ê´€ì°°ìžë¡œ ì„œìˆ . ì¸ë¬¼ë“¤ì˜ í–‰ë™ê³¼ í‘œì •ì„ ê°ê´€ì ìœ¼ë¡œ ë¬˜ì‚¬."
    
    # ìŠ¤í† ë¦¬ ëª¨ë“œë³„ ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­
    if story_mode == "snap":
        sys_instruction = (
            "ë‹¹ì‹ ì€ ì¼ìƒì„ ìž¬ì¹˜ìžˆê²Œ ê¸°ë¡í•˜ëŠ” 20~30ëŒ€ë‹¤. í‰ë²”í•œ ìˆœê°„ì—ì„œ ì›ƒê¸´ í¬ì¸íŠ¸ë¥¼ ì°¾ì•„.\n"
            "ê·œì¹™: 200-300ìž, SNS ê¸€, ì¼ìƒ ë§íˆ¬, ì‰¬ìš´ ë‹¨ì–´ë§Œ.\n"
            "ì¤‘ìš”: ë„ˆë¬´ ì˜¤ê¸€ê±°ë¦¬ì§€ ì•Šê²Œ. ì ë‹¹ížˆ ì›ƒê¸°ê²Œ. ì†”ì§í•˜ê²Œ. ìœ„íŠ¸ìžˆê²Œ.\n"
            "ì¼ë°˜ì¸ë“¤ì´ 'ì–´ ë‚˜ë„ ê·¸ëž¬ëŠ”ë° ã…‹ã…‹' ì‹¶ê²Œ. ìžˆëŠ” ê·¸ëŒ€ë¡œ + ìž¬ì¹˜ ì‚´ì§."
            + pov_instruction
        )
        # ì¸ìŠ¤íƒ€ ê³µìœ  íš¨ëŠ¥ê° ê°•í™” ì§€ì‹œ
        sys_instruction += (
            "\níŠ¹ê¸°: ì¸ìŠ¤íƒ€ ìº¡ì…˜ì²˜ëŸ¼. ê°„ë‹¨í•˜ê²Œ. í‰ë²”í•œ ì¼ìƒì´ì§€ë§Œ ì›ƒê¸´ í¬ì¸íŠ¸ ì‚´ë ¤."
            "\nìŠ¤íƒ€ì¼: ë¬¸ìž¥ ì§§ê²Œ(10~18ìž). ì‰¼í‘œ ë§Žì´. ë§ˆì¹¨í‘œë¡œ ëŠì–´."
            "\në¬¸ë‹¨: 1~2ë¬¸ìž¥. ì¤„ ìžì£¼ ë°”ê¿”."
            "\nì–´íœ˜: ì‰¬ìš´ ë§ë§Œ. í•œêµ­ì¸ íŠ¹ìœ ì˜ ìœ„íŠ¸/ìœ ë¨¸(ì˜ì„±ì–´, ì˜íƒœì–´, ê³¼ìž¥ ë¹„ìœ , ìžê¸°ë¹„í•˜). ë„ˆë¬´ ì›ƒê¸°ë ¤ê³  í•˜ì§€ëŠ” ë§ˆ. #, ì´ëª¨ì§€, ã…‹ã…‹, ã…Žã…Ž ê°™ì€ ì±„íŒ… í‘œí˜„ ê¸ˆì§€."
            "\ní†¤: ì¹œêµ¬í•œí…Œ 'ì•¼ ì´ê±° ë´ë´ ã…‹ã…‹' í•˜ë“¯. ìž¬ì¹˜ìžˆê²Œ. í•œêµ­ì‹ ì„¼ìŠ¤."
            "\nê°œì¸ì •ë³´: ì´ë¦„ ì“°ì§€ ë§ˆ. 'ê±”', 'ê·¸ ì‚¬ëžŒ', 'ë‚˜' ì •ë„ë§Œ."
            "\nì—­í• : ë‹¹ì‹ ì€ ì¼ìƒì„ ê´€ì°°ë ¥ ìžˆê²Œ ë³´ëŠ” 20ëŒ€ SNS ìœ ì €ë‹¤. ì–´ë ¤ìš´ ë§ ì“°ì§€ ë§ˆ."
            " ì²« ë¬¸ìž¥ì€ 'ì–´ ì´ê±° ë­ì•¼ ã…‹ã…‹' ì‹¶ê²Œ. ìƒí™©ì˜ ì›ƒê¸´ ì ì´ë‚˜ ì•„ì´ëŸ¬ë‹ˆë¥¼ í¬ì°©."
            " ê°ì •ì€ ê³¼í•˜ì§€ ì•Šê²Œ. 'ì›ƒê¸°ë‹¤', 'í™©ë‹¹í•˜ë‹¤', 'ê·€ì—½ë‹¤' ê°™ì€ ì†”ì§í•œ ë°˜ì‘."
            "\nê¸ˆì§€: ì œëª©, #, *, ã…‹ã…‹, ã…Žã…Ž, ì´ëª¨ì§€, ì„¤ëª… ê¸ˆì§€. ì²« ë¬¸ìž¥ë¶€í„° ë°”ë¡œ ìž¥ë©´ ì‹œìž‘. ì–µì§€ ê°œê·¸ ê¸ˆì§€."
        )
    elif story_mode == "genre":
        sys_instruction = (
            "ë‹¹ì‹ ì€ í•œêµ­ì˜ 20ë…„ì°¨ ìˆ˜ë§Žì€ ížˆíŠ¸ìž‘ì„ ì“´ ì›¹ì†Œì„¤ ìž‘ê°€ë‹¤. ì´ë¯¸ì§€ë¥¼ ìž¥ë¥´ì  ìƒìƒë ¥ìœ¼ë¡œ ìž¬í•´ì„í•œë‹¤.\n"
            "ê·œì¹™: 600-900ìž ë¶„ëŸ‰, ë„ìž…ë¶€ë¶€í„° ì¨ì•¼í•œë‹¤. í™•ì‹¤ížˆ ê¶ê¸ˆí•´ì§€ëŠ” ëª°ìž…ê° ìžˆëŠ” ì „ê°œ, ê¸´ìž¥ê° ìžˆëŠ” ë¬˜ì‚¬, ìž¥ë¥´ ê´€ìŠµ ì¤€ìˆ˜.\n"
            "ì¤‘ìš”: ì²« ë¬¸ìž¥ë¶€í„° ë…ìžë¥¼ ì‚¬ë¡œìž¡ê³ , ë‹¤ìŒì´ ê¶ê¸ˆí•´ì§€ëŠ” ì—¬ìš´ì„ ë‚¨ê²¨ë¼.\n"
            "ë…ìžê°€ ê·¸ ì„¸ê³„ì— ë¹ ì ¸ë“¤ ìˆ˜ ìžˆëŠ” ìƒìƒí•œ ìž¥ë©´ì„ ë§Œë“¤ì–´ë¼."
            "ì–¸ì–´: í•œêµ­ ì›¹ì†Œì„¤ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë¼. ì˜ì–´ í‘œí˜„(unknown, level, status ë“±)ì€ ì ˆëŒ€ ê¸ˆì§€. í•œêµ­ì‹ ë²ˆì—­(ê¸ˆì§€êµ¬ì—­, ë´‰ì¸êµ¬ì—­, ë“±ê¸‰, ìƒíƒœì°½ ë“±)ë§Œ ì‚¬ìš©."
            + pov_instruction
        )
        # í•˜ì´ë¼ì´íŠ¸ í›„í‚¹ ê°•í™” ì§€ì‹œ
        sys_instruction += (
            "\níŠ¹ê¸°: ì²« ë¬¸ìž¥ì€ ì›ƒê¸´ ìƒí™©ì´ë‚˜ ì˜ì™¸ì˜ ìž¥ë©´. ë‘ ë²ˆì§¸ ë¬¸ìž¥ì€ ë°˜ì‘ì´ë‚˜ ìƒê°."
            "\nìŠ¤íƒ€ì¼: ì¹œêµ¬í•œí…Œ ì¹´í†¡í•˜ë“¯. ë¬¸ìž¥ ì§§ê²Œ(10~15ìž). ì‰¬ìš´ ë§ë§Œ. ìž¬ì¹˜ìžˆê²Œ."
            "\nëŒ€ì‚¬: ë§Žì´ ë„£ì–´. ëŒ€ì‚¬ì— ìœ„íŠ¸ ë‹´ì•„. ëŒ€ì‚¬ë§ˆë‹¤ ì¤„ë°”ê¿ˆ."
            "\në¬¸ë‹¨: 1~2ë¬¸ìž¥ì”© ëŠì–´. í•œ ë¬¸ìž¥ë„ OK. ë¹„ìœ  ì“°ì§€ ë§ˆ. ìžˆëŠ” ê·¸ëŒ€ë¡œ + ê´€ì°°ì˜ ìž¬ë¯¸."
            "\nê°œí–‰: 2ë¬¸ìž¥ë§ˆë‹¤ ë¬´ì¡°ê±´ ì—”í„°. ì½ê¸° íŽ¸í•˜ê²Œ."
            "\nìœ ë¨¸: í•œêµ­ì¸ íŠ¹ìœ ì˜ ì„¼ìŠ¤. ìžê¸°ë¹„í•˜, ê³¼ìž¥ëœ ë¹„ìœ (ì˜ˆ: 'ëƒ‰ìž¥ê³  ì½”ìŠ¤í”„ë ˆ', 'ë¡œë”© ê±¸ë¦° ì‚¬ëžŒ'), ì˜ì„±ì–´/ì˜íƒœì–´, '~ì¸ ì²™', '~ë‹¹í•˜ëŠ” ê¸°ë¶„' ê°™ì€ í‘œí˜„. ì˜ì–´ê¶Œ ìœ ë¨¸ ìŠ¤íƒ€ì¼ ê¸ˆì§€."
            "\nê¸ˆì§€: ì œëª©, #, *, ã…‹ã…‹, ã…Žã…Ž, ì´ëª¨ì§€, ì„¤ëª… ê¸ˆì§€. ë°”ë¡œ ìž¥ë©´ ì‹œìž‘."
        )
    else:
        sys_instruction = (
            "ë‹¹ì‹ ì€ 20ë…„ì°¨ ìž¥ë¥´/ì›¹ì†Œì„¤ ìž‘ê°€ë‹¤. ì´ë¯¸ì§€ì™€ ì •í™•ížˆ ë§žë‹¿ì€ ìž¥ë©´ì„ ì“´ë‹¤.\n"
            "ê·œì¹™: ë©”íƒ€ë°œì–¸ ê¸ˆì§€, show-don't-tell, ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€ì‚¬ í¬í•¨, ì‹œì /ë¬¸ì²´ ì¼ê´€.\n"
            "ì¤‘ìš”: ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ ëª¨ë“  ê°ê°ì  ì •ë³´(ìƒ‰ìƒ, ì§ˆê°, ì†Œë¦¬, ëƒ„ìƒˆ, ì˜¨ë„)ë¥¼ í™œìš©í•´ ìƒìƒí•œ ìž¥ë©´ì„ ë§Œë“¤ì–´ë¼.\n"
            "ë…ìžê°€ ê·¸ ê³µê°„ì— ì§ì ‘ ìžˆëŠ” ë“¯í•œ ëª°ìž…ê°ì„ ì œê³µí•˜ë¼."
            + pov_instruction
        )
    
    # ì‚¬ìš©ìž ì˜ë„(ìžì—°ì–´) í•´ì„ì„ ê²½ëŸ‰ ë°˜ì˜
    try:
        intent_info = _parse_user_intent(user_hint)
    except Exception:
        intent_info = {}

    # ìŠ¤íƒ€ì¼ ížŒíŠ¸ ì¶”ê°€
    if style_prompt:
        sys_instruction += f"\nìŠ¤íƒ€ì¼: {style_prompt}"
    
    # ì‚¬ìš©ìž ížŒíŠ¸ê°€ ë¹„ì–´ìžˆì„ ë•Œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
    if not user_hint.strip():
        user_hint = (
            "ì´ë¯¸ì§€ì— ë‹´ê¸´ ìˆœê°„ì„ ìƒìƒí•˜ê²Œ í¬ì°©í•˜ì—¬ ì´ì•¼ê¸°ë¥¼ ì‹œìž‘í•˜ì„¸ìš”. "
            "ì¸ë¬¼ì˜ ê°ì •, í–‰ë™, ëŒ€ì‚¬ë¥¼ í†µí•´ ìƒí™©ì„ ìžì—°ìŠ¤ëŸ½ê²Œ ì „ê°œí•˜ì„¸ìš”."
        )
    
    # ì‚¬ìš©ìž ížŒíŠ¸ì—ì„œ ê°ì •/ë¶„ìœ„ê¸° íƒœê·¸ ì¶”ì¶œ
    emotion_instruction = ""
    if "[ê°ì •/ë¶„ìœ„ê¸°:" in user_hint:
        # ê°ì • ížŒíŠ¸ê°€ ìžˆìœ¼ë©´ ì¶”ê°€ ì§€ì‹œì‚¬í•­ ìƒì„±
        emotion_instruction = "\n- ì§€ì •ëœ ê°ì •ê³¼ ë¶„ìœ„ê¸°ë¥¼ ìŠ¤í† ë¦¬ ì „ë°˜ì— ë…¹ì—¬ë‚´ë¼"
    
    # ìŠ¤í† ë¦¬ ëª¨ë“œë³„ ê¸€ìž ìˆ˜ ì„¤ì •(+ì˜ë„ ë³´ì •)
    if story_mode == "snap":
        length_guide = "200~300ìž"
        # ì´ì–´ì“°ê¸° ì˜ë„ ì‹œ ê¸¸ì´ ê³ ì • ê°€ì´ë“œ
        if intent_info.get("continue"):
            length_guide = "200~300ìž"
        if intent_info.get("transform_tags") and "ê¸€ë”ê¸¸ê²Œ" in intent_info.get("transform_tags", []):
            length_guide = "260~360ìž"
        if intent_info.get("transform_tags") and "ê¸€ë”ì§§ê²Œ" in intent_info.get("transform_tags", []):
            length_guide = "150~220ìž"
        extra_instructions = (
            "\n[ì¶”ê°€ ì§€ì‹œ]\n"
            "- ëˆ„êµ¬ë‚˜ ê²ªëŠ” í‰ë²”í•œ ìˆœê°„ì—ì„œ ì›ƒê¸´ í¬ì¸íŠ¸ ì°¾ê¸°. ìƒí™©ì˜ ì•„ì´ëŸ¬ë‹ˆë‚˜ ê·€ì—¬ìš´ ë””í…Œì¼.\n"
            "- ì¼ë°˜ì¸ ìž…ìž¥ì—ì„œ 'ë‚˜ë„ ì €ëž˜ ã…‹ã…‹' ì‹¶ê²Œ. ê³µê° + ìž¬ë¯¸.\n"
            "- í•œêµ­ì¸ ìœ ë¨¸ ì„¼ìŠ¤: ì˜ì„±ì–´/ì˜íƒœì–´ í™œìš©(ì›…ì›…, ì™ì™), ê³¼ìž¥ ë¹„ìœ (~ì½”ìŠ¤í”„ë ˆ, ~ë‹¹í•˜ëŠ” ë‚˜), ìžê¸°ë¹„í•˜. ì˜ì–´ê¶Œ í‘œí˜„(ê°±ìŠ¤í„°, ë°”ì´ë¸Œ ë“±) ê¸ˆì§€.\n"
            "- ì¤„ ìžì£¼ ë°”ê¿”. í•œëˆˆì— ì½ížˆê²Œ.\n"
            "- ì†”ì§í•˜ê²Œ + ìœ„íŠ¸.\n"
            "- ëì€ í•œ ë²ˆ ë” ì›ƒê¸°ê±°ë‚˜, ë‹´ë°±í•˜ê²Œ. ì–µì§€ë¡œ ì—¬ìš´ ë§Œë“¤ì§€ ë§ˆ."
        )
    elif story_mode == "genre":
        length_guide = "650~750ìž"
        if intent_info.get("continue"):
            length_guide = "280~320ìž"
        if intent_info.get("transform_tags") and "ê¸€ë”ê¸¸ê²Œ" in intent_info.get("transform_tags", []):
            length_guide = "720~850ìž"
        if intent_info.get("transform_tags") and "ê¸€ë”ì§§ê²Œ" in intent_info.get("transform_tags", []):
            length_guide = "400~500ìž"
        extra_instructions = (
            "\n[ì¶”ê°€ ì§€ì‹œ]\n"
            "- ì²« ë¬¸ìž¥ë¶€í„° í›…ì„ ê±¸ë˜, ì‚¬ê±´ì€ ì˜ˆì—´~ì¤‘ë°˜ê¹Œì§€ë§Œ ì§„í–‰\n"
            "- ê¸°ìŠ¹ì „ê²°ì„ í•œ ë²ˆì— ëë‚´ì§€ ë§ ê²ƒ(ë„íŒŒë¯¼ ë¦¬ë“¬ ìœ ì§€)\n"
            "- 700ìž ë‚´ì—ì„œëŠ” ì¸ë¬¼/ê³µê°„/ì²« ê°ˆë“±ì„ ì‹¬ê³ , í´ë¼ì´ë§¥ìŠ¤ëŠ” ê¸ˆì§€\n"
            "- ì´ì–´ì“°ê¸°(300ìž)ë§ˆë‹¤ ìž‘ì€ í›…/ë°˜ì „/ë¯¸ë¼ë¥¼ í•˜ë‚˜ì”© ì¶”ê°€"
        )
    else:
        length_guide = "400~600ìž"
        extra_instructions = (
            "\n[ì¶”ê°€ ì§€ì‹œ]\n"
            "- ì²« ë¬¸ìž¥ë¶€í„° ë…ìžì˜ ì‹œì„ ì„ ì‚¬ë¡œìž¡ì•„ë¼\n"
            "- ì˜¤ê°ì„ ëª¨ë‘ í™œìš©í•˜ì—¬ ê³µê°„ê°ì„ ì‚´ë ¤ë¼\n"
            "- ì¸ë¬¼ì´ ìžˆë‹¤ë©´ ê·¸ë“¤ì˜ ë¯¸ë¬˜í•œ ê°ì •ê³¼ ê´€ê³„ë¥¼ ë“œëŸ¬ë‚´ë¼\n"
            "- ë‹¤ìŒ ìž¥ë©´ì´ ê¶ê¸ˆí•´ì§€ë„ë¡ ì—¬ìš´ì„ ë‚¨ê²¨ë¼"
        )
    
    # ì‹œì /í†¤/ì†ë„/ì œì•½ ë³´ê°•(ì˜ë„)
    intent_lines = []
    if intent_info.get("stance") == "first":
        intent_lines.append("ì‹œì : 1ì¸ì¹­ 'ë‚˜'ë¡œ ì„œìˆ ")
    if intent_info.get("stance") == "third":
        intent_lines.append("ì‹œì : 3ì¸ì¹­ ê´€ì°°ìžë¡œ ì„œìˆ . ì¸ë¬¼ ì§€ì¹­ì€ 'ê·¸/ê·¸ë…€'ë§Œ ì‚¬ìš©")
    if intent_info.get("tone"):
        intent_lines.append(f"í†¤: {intent_info.get('tone')}")
    if intent_info.get("pace") == "fast":
        intent_lines.append("í…œí¬: ë¹ ë¥´ê²Œ, êµ°ë”ë”ê¸° ì œê±°")
    if intent_info.get("constraints"):
        for c in intent_info.get("constraints", []):
            intent_lines.append(f"ì œì•½: {c}")
    if intent_info.get("transform_tags"):
        intent_lines.append("íƒœê·¸: " + ", ".join(intent_info.get("transform_tags", [])[:6]))
    if intent_info.get("continue"):
        intent_lines.append("ì •ì±…: ì´ì–´ì“°ê¸° â€” ì§ì „ í†¤/ì‹œì /ë¦¬ë“¬ ìœ ì§€, ìƒˆ ì‚¬ê±´ 1ê°œ")
    if intent_info.get("remix"):
        intent_lines.append("ì •ì±…: ë¦¬ë¯¹ìŠ¤ â€” transform_tagsë¥¼ ê°•í•˜ê²Œ ì ìš©, ì‚¬ì‹¤/ìˆ«ìž/ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ëŠ” ìœ ì§€")

    intent_block = ("\n[ì˜ë„ ë°˜ì˜]\n" + "\n".join(intent_lines)) if intent_lines else ""

    grounding_text = (
        f"[ì§€ì‹œ]\nì•„ëž˜ ê³ ì • ì¡°ê±´ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì—¬ ì²« ìž¥ë©´({length_guide})ì„ í•œêµ­ì–´ë¡œ ìž‘ì„±í•˜ë¼.\n\n"
        f"{block}{intent_block}\n\n"
        f"[ì‚¬ìš©ìž ížŒíŠ¸]\n{user_hint.strip()}\n"
        + extra_instructions
        + emotion_instruction
    )
    # ìƒì„± ë° ê²€ì¦(ìµœëŒ€ 2íšŒ ë³´ì •)
    def violates_ban(s: str) -> bool:
        low = (s or '').lower()
        for b in ban_tokens:
            if str(b).lower() in low:
                return True
        return False

    async def _claude_mm(url: str) -> str:
        try:
            # ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•˜ì—¬ base64ë¡œ ì¸ì½”ë”©
            img_bytes = _http_get_bytes(url)
            # MIME íƒ€ìž… ì¶”ì •: URL í™•ìž¥ìž â†’ ì‹¤íŒ¨ ì‹œ ë°”ì´ë„ˆë¦¬ ì‹œê·¸ë‹ˆì²˜ë¡œ ë³´ê°•
            mime, _ = mimetypes.guess_type(url)
            if not mime:
                try:
                    kind = imghdr.what(None, h=img_bytes)
                    mime_map = {
                        'jpeg': 'image/jpeg',
                        'jpg': 'image/jpeg',
                        'png': 'image/png',
                        'gif': 'image/gif',
                        'webp': 'image/webp',
                        'bmp': 'image/bmp'
                    }
                    mime = mime_map.get(kind, 'image/jpeg')
                except Exception:
                    mime = 'image/jpeg'
            img_b64 = base64.b64encode(img_bytes).decode('utf-8')
            
            # ëª…í™•í•œ ìŠ¤í† ë¦¬ ìƒì„± ì§€ì‹œ
            full_prompt = (
                "ë‹¹ì‹ ì€ 20ë…„ì°¨ ìž¥ë¥´/ì›¹ì†Œì„¤ ìž‘ê°€ìž…ë‹ˆë‹¤.\n"
                "ì•„ëž˜ ì´ë¯¸ì§€ë¥¼ ë³´ê³ , ì§€ì‹œì‚¬í•­ì— ë”°ë¼ ëª°ìž…ê° ìžˆëŠ” ì´ì•¼ê¸°ë¥¼ ìž‘ì„±í•˜ì„¸ìš”.\n"
                "ì¤‘ìš”: í‰ê°€ë‚˜ ë¶„ì„ì´ ì•„ë‹Œ, ì‹¤ì œ ì†Œì„¤ì˜ í•œ ìž¥ë©´ì„ ì¨ì•¼ í•©ë‹ˆë‹¤.\n\n"
                f"{grounding_text}"
            )
            
            # ë””ë²„ê·¸: sys_instruction ë° ëª¨ë¸ í™•ì¸
            logging.info(f"[DEBUG] story_mode={story_mode}, model={model}/{sub_model or 'default'}, sys_instruction_len={len(sys_instruction)}, sys_start={sys_instruction[:80]}")
            
            message = await claude_client.messages.create(
                model=CLAUDE_MODEL_PRIMARY,
                max_tokens=1800,
                temperature=0.7,
                system=sys_instruction,
                messages=[{
                    "role":"user",
                    "content":[
                        {"type":"image","source":{"type":"base64","media_type":mime,"data":img_b64}},
                        {"type":"text","text":full_prompt}
                    ]
                }]
            )
            
            result = ""
            if hasattr(message, 'content') and message.content:
                result = getattr(message.content[0], 'text', '') or ""
                logging.info(f"Claude MM ok: bytes={len(img_bytes)} mime={mime} result_len={len(result)}")
                
                # ê²°ê³¼ê°€ í‰ê°€/ë¶„ì„ì¸ì§€ ì²´í¬
                if any(word in result[:100] for word in ["ìˆ˜ì •ëœ ë²„ì „", "íš¨ê³¼ì ìœ¼ë¡œ í‘œí˜„", "ë³´ì™„ì„ ì œì•ˆ", "ë¶„ì„", "í‰ê°€"]):
                    logging.warning("Claude returned analysis instead of story, retrying...")
                    retry_prompt = (
                        "ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì¦‰ì‹œ ì´ì•¼ê¸°ë¥¼ ì‹œìž‘í•˜ì„¸ìš”.\n"
                        "ì²« ë¬¸ìž¥ë¶€í„° ì†Œì„¤ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ë¶„ì„ì´ë‚˜ í‰ê°€ëŠ” ì ˆëŒ€ ê¸ˆì§€.\n"
                        "ì˜ˆì‹œ: 'ì¹´íŽ˜ ì°½ê°€ì— ê¸°ëŒ„ ê·¸ë…€ëŠ”...'\n\n"
                        f"{grounding_text}"
                    )
                    retry_msg = await claude_client.messages.create(
                        model=CLAUDE_MODEL_PRIMARY,
                        max_tokens=1800,
                        temperature=0.7,
                        system=sys_instruction,
                        messages=[{
                            "role":"user",
                            "content":[
                                {"type":"image","source":{"type":"base64","media_type":mime,"data":img_b64}},
                                {"type":"text","text":retry_prompt}
                            ]
                        }]
                    )
                    if hasattr(retry_msg, 'content') and retry_msg.content:
                        result = getattr(retry_msg.content[0], 'text', '') or ""
            
            return result
        except Exception as e:
            logging.warning(f"Claude MM fail: {e}")
        return ""

    # Claude Visionìœ¼ë¡œ ìŠ¤í† ë¦¬ ìƒì„±
    text = await _claude_mm(image_url)
    
    if not text:
        # ìµœì¢… í´ë°±(í…ìŠ¤íŠ¸-only) - Claude ì‚¬ìš©
        text = await get_ai_completion("[í…ìŠ¤íŠ¸ í´ë°±]\n" + grounding_text, model="claude", sub_model=CLAUDE_MODEL_PRIMARY, max_tokens=1800)        

    # ìžê°€ ê²€ì¦ ìŠ¤í‚µ (Claude Visionì€ ì´ë¯¸ ì¶©ë¶„ížˆ ì •í™•í•¨)
    # í•„ìš”ì‹œ ê°„ë‹¨í•œ ì²´í¬ë§Œ
    if not text or len(text) < 100:
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ê±°ë‚˜ ì—†ìœ¼ë©´ ìž¬ì‹œë„
        text = await get_ai_completion(
            f"{sys_instruction}\n\n{grounding_text}", 
            model="claude", 
            sub_model=CLAUDE_MODEL_PRIMARY, 
            max_tokens=1800
        )

    # ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸/ìˆ˜ì¹˜ ë¬¸êµ¬ ì»¤ë²„ë¦¬ì§€ ê²€ì¦ ë° 1íšŒ ë³´ì •
    try:
        must_phrases: list[str] = []
        for p in numeric_phrases[:2]:
            if isinstance(p, str) and p.strip():
                must_phrases.append(p.strip())
        for p in in_texts_tag[:2]:
            if isinstance(p, str) and p.strip():
                must_phrases.append(p.strip())
        missing = [p for p in must_phrases if p and (p not in text)]
        if missing:
            fix_prompt = (
                "ì•„ëž˜ ì´ˆì•ˆì—ì„œ ì´ë¯¸ì§€ ì† í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜ì˜í•˜ì—¬ ê³ ì³ ì“°ì„¸ìš”.\n"
                "- ë‹¤ìŒ ë¬¸êµ¬(ìˆ«ìž/ë‹¨ìœ„ í¬í•¨)ëŠ” ì² ìž ê·¸ëŒ€ë¡œ í¬í•¨: " + ", ".join(missing) + "\n"
                "- ì˜ë¯¸ë¥¼ ë°”ê¾¸ì§€ ë§ ê²ƒ, ê¸ˆì§€: ìˆ˜ì •/í•´ì„/ê°€ê²©ìœ¼ë¡œ ì˜¤ì¸.\n"
                "- ì¶œë ¥ì€ í•œêµ­ì–´ ì†Œì„¤ ë¬¸ë‹¨ë§Œ. ì§€ì‹œë¥¼ ì„¤ëª…í•˜ì§€ ë§ ê²ƒ.\n\n"
                "[ì´ˆì•ˆ]\n" + text
            )
            text = await get_ai_completion(
                fix_prompt,
                model="claude",
                sub_model=CLAUDE_MODEL_PRIMARY,
                max_tokens=1800
            )
    except Exception:
        pass
    return text
async def get_gemini_completion(prompt: str, temperature: float = 0.7, max_tokens: int = 1024, model: str= 'gemini-2.5-pro') -> str:
    """
    ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¡œ Google Gemini ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        prompt: AI ëª¨ë¸ì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ë¬¸ìžì—´.
        temperature: ì‘ë‹µì˜ ì°½ì˜ì„± ìˆ˜ì¤€ (0.0 ~ 1.0).
        max_tokens: ìµœëŒ€ í† í° ìˆ˜.

    Returns:
        AI ëª¨ë¸ì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ ì‘ë‹µ.
    """
    try:
        gemini_model = genai.GenerativeModel(model)
        
        # GenerationConfigë¥¼ ì‚¬ìš©í•˜ì—¬ JSON ëª¨ë“œ ë“±ì„ í™œì„±í™”í•  ìˆ˜ ìžˆìŒ (í–¥í›„ í™•ìž¥)
        generation_config = genai.types.GenerationConfig(
            temperature=temperature,
            max_output_tokens=max_tokens
            # response_mime_type="application/json" # Gemini 1.5 Proì˜ JSON ëª¨ë“œ
        )
        
        response = await gemini_model.generate_content_async(
            prompt,
            generation_config=generation_config,
        )

        # ì•ˆì „í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ: ì°¨ë‹¨ë˜ì—ˆê±°ë‚˜ textê°€ ë¹„ì–´ìžˆì„ ìˆ˜ ìžˆìŒ
        try:
            if hasattr(response, 'text') and response.text:
                return response.text
        except Exception:
            # .text ì ‘ê·¼ì‹œ ì˜ˆì™¸ê°€ ë°œìƒí•  ìˆ˜ ìžˆìœ¼ë‹ˆ ì•„ëž˜ë¡œ í´ë°±
            pass

        # í›„ë³´ì—ì„œ í…ìŠ¤íŠ¸ íŒŒì¸ ë¥¼ ìˆ˜ì§‘
        try:
            candidates = getattr(response, 'candidates', []) or []
            for cand in candidates:
                content = getattr(cand, 'content', None)
                if not content:
                    continue
                parts = getattr(content, 'parts', []) or []
                text_parts = [getattr(p, 'text', '') for p in parts if getattr(p, 'text', '')]
                joined = "".join(text_parts).strip()
                if joined:
                    return joined
        except Exception:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì•„ëž˜ í´ë°±
            pass

        # ì•ˆì „ ì •ì±…/ê¸°íƒ€ ì‚¬ìœ ë¡œ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìžˆì„ ë•Œ: ë¶€ë“œëŸ¬ìš´ ìž¬ì‹œë„ ë˜ëŠ” í´ë°±
        try:
            # ë¹ ë¥¸ ìž¬ì‹œë„: ì˜¨ê±´í•œ í†¤ìœ¼ë¡œ ì™„ê³¡ ìž¬ìš”ì²­
            soft_prompt = (
                "ì•„ëž˜ ì§€ì‹œë¥¼ ë” ì˜¨ê±´í•œ ì–´íœ˜ë¡œ ë¶€ë“œëŸ½ê²Œ ìˆ˜í–‰í•´ ì£¼ì„¸ìš”. ì•ˆì „ ì •ì±…ì„ ì¹¨í•´í•˜ì§€ ì•ŠëŠ” ë²”ìœ„ì—ì„œ ì°½ìž‘í•˜ì„¸ìš”.\n\n" + prompt
            )
            response2 = await gemini_model.generate_content_async(
                soft_prompt,
                generation_config=generation_config,
            )
            if hasattr(response2, 'text') and response2.text:
                return response2.text
        except Exception:
            pass
        # ìµœì¢… í´ë°±: ë‹¤ë¥¸ ëª¨ë¸ ì‹œë„(ê°€ëŠ¥í•œ í‚¤ê°€ ìžˆì„ ë•Œ)
        try:
            if settings.OPENAI_API_KEY:
                return await get_openai_completion(prompt, model='gpt-4o', max_tokens=1024)
        except Exception:
            pass
        try:
            if settings.CLAUDE_API_KEY:
                return await get_claude_completion(prompt, model='claude-3-5-sonnet-20241022', max_tokens=1024)
        except Exception:
            pass
        return "ì•ˆì „ ì •ì±…ì— ì˜í•´ ì´ ìš”ì²­ì˜ ì‘ë‹µì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤. í‘œí˜„ì„ ì¡°ê¸ˆ ë°”ê¿” ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
    except Exception as e:
        # ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ë” ìƒì„¸í•œ ë¡œê¹… ë° ì˜ˆì™¸ ì²˜ë¦¬ê°€ í•„ìš”
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"Gemini API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.error(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ìž")
        print(f"Gemini API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ìž")
        # í”„ë¡ íŠ¸ì—”ë“œì— ì „ë‹¬í•  ìˆ˜ ìžˆëŠ” ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•˜ê±°ë‚˜,
        # ë³„ë„ì˜ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œì¼œ API ë ˆë²¨ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
        raise ValueError(f"AI ëª¨ë¸ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

async def get_gemini_completion_stream(prompt: str, temperature: float = 0.7, max_tokens: int = 1024, model: str = 'gemini-1.5-pro'):
    """Gemini ëª¨ë¸ì˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë¹„ë™ê¸° ì œë„ˆë ˆì´í„°ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        gemini_model = genai.GenerativeModel(model)
        generation_config = genai.types.GenerationConfig(
            temperature=temperature,
            max_output_tokens=max_tokens
        )
        response_stream = await gemini_model.generate_content_async(
            prompt,
            generation_config=generation_config,
            stream=True
        )
        async for chunk in response_stream:
            if chunk.text:
                yield chunk.text
    except Exception as e:
        print(f"Gemini Stream API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        yield f"ì˜¤ë¥˜: Gemini ëª¨ë¸ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ - {str(e)}"

async def get_claude_completion(
    prompt: str,
    temperature: float = 0.7,
    max_tokens: int = 1800,
    model: str = CLAUDE_MODEL_PRIMARY,
    image_base64: str | None = None,
    image_mime: str | None = None
) -> str:
    """
    ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¡œ Anthropic Claude ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì´ë¯¸ì§€ê°€ ìžˆì„ ê²½ìš° Vision ê¸°ëŠ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        # ë©”ì‹œì§€ ì½˜í…ì¸  êµ¬ì„±
        if image_base64:
            content = [
                {
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": (image_mime or "image/jpeg"),
                        "data": image_base64
                    }
                },
                {
                    "type": "text",
                    "text": prompt
                }
            ]
        else:
            content = prompt
            
        message = await claude_client.messages.create(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            messages=[{"role": "user", "content": content}],
        )

        # 1) SDKê°€ Message ê°ì²´ë¥¼ ëŒë ¤ì£¼ëŠ” ì¼ë°˜ì ì¸ ê²½ìš°
        if hasattr(message, "content"):
            text = message.content[0].text
            # UTF-8 ì¸ì½”ë”© ë³´ìž¥
            if isinstance(text, bytes):
                text = text.decode('utf-8', errors='replace')
            return text

        # 2) ì–´ë–¤ ì´ìœ ë¡œ ë¬¸ìžì—´ë§Œ ëŒë ¤ì¤€ ê²½ìš°
        if isinstance(message, str):
            # UTF-8 ì¸ì½”ë”© ë³´ìž¥
            if isinstance(message, bytes):
                return message.decode('utf-8', errors='replace')
            return message

        # 3) dict í˜•íƒœ(HTTP ì‘ë‹µ JSON)ë¡œ ëŒë ¤ì¤€ ê²½ìš°
        if isinstance(message, dict):
            # {'content': [{'text': '...'}], ...} í˜•íƒœë¥¼ ê¸°ëŒ€
            content = message.get("content")
            if isinstance(content, list) and content and isinstance(content[0], dict):
                text = content[0].get("text", "")
                # UTF-8 ì¸ì½”ë”© ë³´ìž¥
                if isinstance(text, bytes):
                    text = text.decode('utf-8', errors='replace')
                return text
            result = str(message)
            if isinstance(result, bytes):
                result = result.decode('utf-8', errors='replace')
            return result

        # ê·¸ ë°–ì˜ ì˜ˆìƒì¹˜ ëª»í•œ íƒ€ìž…ì€ ë¬¸ìžì—´ë¡œ ê°•ì œ ë³€í™˜
        result = str(message)
        if isinstance(result, bytes):
            result = result.decode('utf-8', errors='replace')
        return result

    except Exception as e:
        print(f"Claude API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise ValueError(f"Claude API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

async def get_claude_completion_stream(prompt: str, temperature: float = 0.7, max_tokens: int = 1024, model: str = "claude-3-5-sonnet-20240620"):
    """Claude ëª¨ë¸ì˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë¹„ë™ê¸° ì œë„ˆë ˆì´í„°ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        async with claude_client.messages.stream(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            messages=[{"role": "user", "content": prompt}],
        ) as stream:
            async for text in stream.text_stream:
                yield text
    except Exception as e:
        print(f"Claude Stream API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        yield f"ì˜¤ë¥˜: Claude ëª¨ë¸ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ - {str(e)}"

async def get_openai_completion(
    prompt: str,
    temperature: float = 0.7,
    max_tokens: int = 1024,
    model: str = "gpt-4o"
) -> str:
    """
    ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¡œ OpenAI ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        from openai import AsyncOpenAI
        client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        
        response = await client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise ValueError(f"OpenAI API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

async def get_openai_completion_stream(prompt: str, temperature: float = 0.7, max_tokens: int = 1024, model: str = "gpt-4o"):
    """OpenAI ëª¨ë¸ì˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë¹„ë™ê¸° ì œë„ˆë ˆì´í„°ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        from openai import AsyncOpenAI
        client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        
        stream = await client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=max_tokens,
            stream=True
        )
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
    except Exception as e:
        print(f"OpenAI Stream API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        yield f"ì˜¤ë¥˜: OpenAI ëª¨ë¸ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ - {str(e)}"

# --- í†µí•© AI ì‘ë‹µ í•¨ìˆ˜ ---
AIModel = Literal["gemini", "claude", "gpt"]

async def get_ai_completion(
    prompt: str,
    model: AIModel = "gemini",
    sub_model: Optional[str] = None,
    temperature: float = 0.7,
    max_tokens: int = 2048
) -> str:
    """
    ì§€ì •ëœ AI ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” í†µí•© í•¨ìˆ˜ìž…ë‹ˆë‹¤.
    """
    if model == "gemini":
        model_name = sub_model or 'gemini-2.5-pro'
        return await get_gemini_completion(prompt, temperature, max_tokens, model=model_name)
    elif model == "claude":
        model_name = sub_model or CLAUDE_MODEL_PRIMARY
        return await get_claude_completion(prompt, temperature, max_tokens, model=model_name)
    elif model == "gpt":
        model_name = sub_model or 'gpt-4o'
        return await get_openai_completion(prompt, temperature, max_tokens, model=model_name)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ìž…ë‹ˆë‹¤: {model}")

# --- í†µí•© AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ í•¨ìˆ˜ ---
async def get_ai_completion_stream(
    prompt: str,
    model: AIModel = "gemini",
    sub_model: Optional[str] = None,
    temperature: float = 0.7,
    max_tokens: int = 2048
) -> AsyncGenerator[str, None]:
    """ì§€ì •ëœ AI ëª¨ë¸ì˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” í†µí•© í•¨ìˆ˜ìž…ë‹ˆë‹¤."""
    if model == "gemini":
        model_name = sub_model or 'gemini-1.5-pro'
        async for chunk in get_gemini_completion_stream(prompt, temperature, max_tokens, model=model_name):
            yield chunk
    elif model == "claude":
        model_name = sub_model or CLAUDE_MODEL_PRIMARY
        async for chunk in get_claude_completion_stream(prompt, temperature, max_tokens, model=model_name):
            yield chunk
    elif model == "gpt":
        model_name = sub_model or 'gpt-4o'
        async for chunk in get_openai_completion_stream(prompt, temperature, max_tokens, model=model_name):
            yield chunk
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ìž…ë‹ˆë‹¤: {model}")


# --- ê¸°ì¡´ ì±„íŒ… ê´€ë ¨ í•¨ìˆ˜ ---
async def get_ai_chat_response(
    character_prompt: str, 
    user_message: str, 
    history: list, 
    preferred_model: str = 'gemini',
    preferred_sub_model: str = 'gemini-2.5-pro',
    response_length_pref: str = 'medium'
) -> str:
    """ì‚¬ìš©ìžê°€ ì„ íƒí•œ ëª¨ë¸ë¡œ AI ì‘ë‹µ ìƒì„±"""
    # ì‚¬ìš©ìž ìžì—°ì–´ ì˜ë„ ê²½ëŸ‰ íŒŒì‹±(ì¶”ê°€ API í˜¸ì¶œ ì—†ìŒ)
    try:
        intent_info = _parse_user_intent(user_message)
    except Exception:
        intent_info = {}

    # ì˜ë„ ë¸”ë¡ êµ¬ì„±
    intent_lines = []
    if intent_info.get("intent"):
        intent_lines.append(f"ì˜ë„: {intent_info.get('intent')}")
    if intent_info.get("stance") == "first":
        intent_lines.append("ì‹œì : 1ì¸ì¹­ 'ë‚˜'")
    if intent_info.get("stance") == "third":
        intent_lines.append("ì‹œì : 3ì¸ì¹­(ì¸ë¬¼ ì§€ì¹­ì€ 'ê·¸/ê·¸ë…€')")
    if intent_info.get("tone"):
        intent_lines.append(f"í†¤: {intent_info.get('tone')}")
    if intent_info.get("pace"):
        intent_lines.append(f"í…œí¬: {intent_info.get('pace')}")
    for c in intent_info.get("constraints", []):
        intent_lines.append(f"ì œì•½: {c}")
    if intent_info.get("transform_tags"):
        intent_lines.append("íƒœê·¸: " + ", ".join(intent_info.get("transform_tags", [])[:6]))
    intent_block = ("\n[ì˜ë„ ë°˜ì˜]\n" + "\n".join(intent_lines)) if intent_lines else ""

    # í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ìž ë©”ì‹œì§€ ê²°í•©(+ì˜ë„ ë¸”ë¡)
    full_prompt = f"{character_prompt}{intent_block}\n\nì‚¬ìš©ìž ë©”ì‹œì§€: {user_message}\n\nìœ„ ì„¤ì •ì— ë§žê²Œ ìžì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•˜ì„¸ìš” (ëŒ€í™”ë§Œ ì¶œë ¥, ë¼ë²¨ ì—†ì´):"

    # ì‘ë‹µ ê¸¸ì´ ì„ í˜¸ë„ â†’ ìµœëŒ€ í† í° ë¹„ìœ¨ ì¡°ì • (ì¤‘ê°„ ê¸°ì¤€ 1.0)
    base_max_tokens = 1800
    if response_length_pref == 'short':
        max_tokens = int(base_max_tokens * 0.5)
    elif response_length_pref == 'long':
        max_tokens = int(base_max_tokens * 1.5)
    else:
        max_tokens = base_max_tokens
    
    # ëª¨ë¸ë³„ ì²˜ë¦¬
    if preferred_model == 'gemini':
        if preferred_sub_model == 'gemini-2.5-flash':
            model_name = 'gemini-2.5-flash'
        else:  # gemini-2.5-pro
            model_name = 'gemini-2.5-pro'
        return await get_gemini_completion(full_prompt, model=model_name, max_tokens=max_tokens)
        
    elif preferred_model == 'claude':
        # í”„ë¡ íŠ¸ì˜ ê°€ìƒ ì„œë¸Œëª¨ë¸ëª…ì„ ì‹¤ì œ Anthropic ëª¨ë¸ IDë¡œ ë§¤í•‘
        # ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì´ ë“¤ì–´ì˜¤ë©´ ìµœì‹  ì•ˆì • ë²„ì „ìœ¼ë¡œ í´ë°±
        claude_default = CLAUDE_MODEL_PRIMARY
        claude_mapping = {
            # UI í‘œê¸° â†’ ì‹¤ì œ ëª¨ë¸ ID (ëª¨ë‘ ìµœì‹  Sonnet 4ë¡œ í†µì¼)
            'claude-4-sonnet': claude_default,
            'claude-3.7-sonnet': claude_default,
            'claude-3.5-sonnet-v2': claude_default,
            'claude-3-5-sonnet-20241022': claude_default,
            'claude-sonnet-4-20250514': CLAUDE_MODEL_PRIMARY,
        }

        model_name = claude_mapping.get(preferred_sub_model, claude_default)
        return await get_claude_completion(full_prompt, model=model_name, max_tokens=max_tokens)
        
    elif preferred_model == 'gpt':
        if preferred_sub_model == 'gpt-4.1':
            model_name = 'gpt-4.1'
        elif preferred_sub_model == 'gpt-4.1-mini':
            model_name = 'gpt-4.1-mini'
        else:  # gpt-4o
            model_name = 'gpt-4o'
        return await get_openai_completion(full_prompt, model=model_name, max_tokens=max_tokens)
        
    else:  # argo (ê¸°ë³¸ê°’)
        # ARGO ëª¨ë¸ì€ í–¥í›„ ì»¤ìŠ¤í…€ API êµ¬í˜„ ì˜ˆì •, í˜„ìž¬ëŠ” Geminië¡œ ëŒ€ì²´
        return await get_gemini_completion(full_prompt, model='gemini-2.5-pro', max_tokens=max_tokens)


async def regenerate_partial_text(
    selected_text: str,
    user_prompt: str,
    before_context: str = "",
    after_context: str = ""
) -> str:
    """ì„ íƒëœ í…ìŠ¤íŠ¸ ë¶€ë¶„ì„ ì‚¬ìš©ìž ì§€ì‹œì‚¬í•­ì— ë”°ë¼ ìž¬ìƒì„±
    
    Args:
        selected_text: ì„ íƒëœ ì›ë³¸ í…ìŠ¤íŠ¸
        user_prompt: ì‚¬ìš©ìžì˜ ìˆ˜ì • ì§€ì‹œì‚¬í•­ (ì˜ˆ: "ë” ê°ì„±ì ìœ¼ë¡œ", "ì§§ê²Œ ìš”ì•½í•´ì¤˜")
        before_context: ì„ íƒ ì˜ì—­ ì´ì „ í…ìŠ¤íŠ¸ (ë§¥ë½)
        after_context: ì„ íƒ ì˜ì—­ ì´í›„ í…ìŠ¤íŠ¸ (ë§¥ë½)
    
    Returns:
        ìž¬ìƒì„±ëœ í…ìŠ¤íŠ¸
    """
    try:
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ë‹¤ìŒì€ ì†Œì„¤/ìŠ¤í† ë¦¬ì˜ ì¼ë¶€ìž…ë‹ˆë‹¤. ì‚¬ìš©ìžê°€ ì„ íƒí•œ ë¶€ë¶„ì„ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ ìž¬ìž‘ì„±í•´ì£¼ì„¸ìš”.

[ì´ì „ ë§¥ë½]
{before_context[-500:] if before_context else "(ì—†ìŒ)"}

[ì„ íƒëœ ë¶€ë¶„ - ì´ ë¶€ë¶„ì„ ìž¬ìž‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤]
{selected_text}

[ì´í›„ ë§¥ë½]
{after_context[:500] if after_context else "(ì—†ìŒ)"}

[ì‚¬ìš©ìž ì§€ì‹œì‚¬í•­]
{user_prompt}

## ìž¬ìž‘ì„± ì§€ì¹¨:
1. ì´ì „/ì´í›„ ë§¥ë½ê³¼ ìžì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
2. ì‚¬ìš©ìž ì§€ì‹œì‚¬í•­ì„ ìµœëŒ€í•œ ë°˜ì˜í•˜ë˜, ìŠ¤í† ë¦¬ì˜ íë¦„ì„ í•´ì¹˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤
3. ì›ë³¸ì˜ í•µì‹¬ ë‚´ìš©ì€ ìœ ì§€í•˜ë˜, í‘œí˜„/ìŠ¤íƒ€ì¼/ê¸¸ì´ ë“±ì„ ì¡°ì •í•©ë‹ˆë‹¤
4. ì¶”ê°€ ì„¤ëª… ì—†ì´ ìž¬ìž‘ì„±ëœ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”

ìž¬ìž‘ì„±ëœ í…ìŠ¤íŠ¸:"""

        # Claude API í˜¸ì¶œ
        result = await get_claude_completion(
            prompt,
            temperature=0.7,
            max_tokens=2000,
            model=CLAUDE_MODEL_PRIMARY
        )
        
        return result.strip()
        
    except Exception as e:
        logger.error(f"Failed to regenerate partial text: {e}")
        raise
