# -*- coding: utf-8 -*-
"""AI스토리다이빙.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TGXNUFR3KWjqriEK2xCG9PmsRzNoFeJJ
"""

pip install -q gradio openai requests anthropic google-generativeai google-cloud-aiplatform Pillow torch torchvision torchaudio diffusers transformers accelerate

# -*- coding: utf-8 -*-
"""webnovel_chat_app_v8.py
AI의 사용자 대사 임의 생성 방지 강화 및 사용자 선택지 채팅 표시.
장면 시작 시 AI가 더 능동적으로 상황을 제시하거나 다른 캐릭터의 대사를 통해 사용자 행동 유도.

주요 변경 사항
─────────────────────────────────────────
1. call_gpt 및 generate_ai_reaction_to_scene_choice_llm 시스템 프롬프트 강화: AI가 사용자 대사를 생성하지 않도록 명확히 지시.
2. handle_send_click_wrapper 수정: 사용자의 역할/장면/상황 선택을 채팅창에 사용자 메시지로 표시 후 AI 응답이 이어지도록 변경.
3. Config 클래스의 IMAGE_MODEL을 "imagen-3.0-fast-generate-001"로 업데이트.
4. generate_ai_reaction_to_scene_choice_llm 프롬프트 수정: 장면 시작 시 AI가 더 능동적으로 사용자 행동을 유도하도록 변경.
5. SCENE_START_PREFIX 상수 제거 및 관련 로직 수정.
"""

from __future__ import annotations

import io
import json
import time
import re
import random
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Any
import vertexai
import gradio as gr
import openai
import requests
import torch
from google.colab import userdata # Colab 환경에서 실행 가정
from google.colab.userdata import NotebookAccessError # Colab 환경에서 실행 가정
from PIL import Image
from diffusers import DiffusionPipeline
import anthropic
import google.generativeai as genai
from google.generativeai import types # types 모듈 임포트 (필수)
from google.generativeai.types import HarmCategory, HarmBlockThreshold


# ───────────────────────────────────────
# 0) Constants
# ───────────────────────────────────────
MAX_EPISODES_TO_PARSE = 50
DEFAULT_MY_PROFILE_NAME = "투자자"
DEFAULT_MY_PROFILE_PLACEHOLDER = (
    f"이름: {DEFAULT_MY_PROFILE_NAME}\n"
    "성별: 남성\n"
    "나이: 20대 중반\n"
    "외모: 평범하지만 어딘가 관찰력이 좋아 보이는 눈매, 편안한 복장.\n"
    "성격: 호기심이 많고 신중하며, 때로는 과감한 결정을 내리기도 한다. 다른 사람의 이야기를 잘 들어주는 편.\n"
    "특징: 갑자기 이 세계에 떨어진 전직 벤처투자자. 원래 세계의 지식을 일부 가지고 있지만, 이 세계의 법칙에는 아직 미숙하다. 뛰어난 적응력과 위기 대처 능력을 지니고 있다."
    "말투: 현대적이고 표준적인 말투를 사용. 가끔 혼잣말이나 속마음을 표현하기도 한다."
)
DEFAULT_USER_BOX_PLACEHOLDER = "AI 캐릭터와 대화를 시작하거나, 파일 로드 후 초기 설정을 진행해주세요."
SITUATION_USER_BOX_PLACEHOLDER = "제시할 상황을 입력하고 '⚡ 상황 전송'을 누르세요..."
CHOICE_USER_BOX_PLACEHOLDER = "선택지 번호(예: 1) 또는 원하는 행동을 입력하세요..."
ROLE_CHOICE_USER_BOX_PLACEHOLDER = "'나'의 역할을 선택하세요 (예: 1번)"
SCENE_CHOICE_USER_BOX_PLACEHOLDER = "참여할 장면을 선택하세요 (예: 1번)"
EPISODE_CONFIRM_USER_BOX_PLACEHOLDER ="시작할 회차를 선택하고 아래 '확정' 버튼을 눌러주세요."
DEFAULT_SEND_BUTTON_TEXT = "전송 ➤"
SITUATION_SEND_BUTTON_TEXT = "⚡ 상황 전송"
CHOICE_SEND_BUTTON_TEXT = "✅ 선택/행동 전송"
ROLE_CHOICE_SEND_BUTTON_TEXT = "✅ 역할 선택"
SCENE_CHOICE_SEND_BUTTON_TEXT = "✅ 장면 선택"
USER_REQUEST_EVENT_BUTTON_TEXT = "✨ 다음 사건은?"
CONFIRM_EPISODE_BUTTON_TEXT = "🚀 시작 회차 확정"

USER_SITUATION_PREFIX = "[상황 제시] "
SYSTEM_SITUATION_PREFIX = "[시스템 상황] "
STORY_BRIEFING_PREFIX = "[스토리 브리핑]\n"
MY_ROLE_CHOICE_PREFIX = "\n\n[나의 역할 선택지 제시]\n"
SCENE_ENTRY_CHOICE_PREFIX = "[참여 장면 선택지 제시]\n"
# SCENE_START_PREFIX 제거

USER_CHOICE_ROLE_PREFIX = "[역할 선택]\n\n "
USER_CHOICE_SCENE_PREFIX = "[장면 선택]\n\n "
USER_CHOICE_ACTION_PREFIX = "[선택]\n\n "

RANDOM_SITUATION_PROBABILITY = 0.4
SYSTEM_NUDGE_THRESHOLD = 5


# ───────────────────────────────────────
# 1) Configuration
# ───────────────────────────────────────
class Config:
    OPENAI_API_KEY: str = ""; ANTHROPIC_API_KEY: str = ""; GEMINI_API_KEY: str = ""
    VERTEX_AI_PROJECT_ID: str = "gen-lang-client-0989848795"  # ◀◀◀ 여기에 Vertex AI 프로젝트 ID를 입력하세요!
    VERTEX_AI_LOCATION: str = "us-central1"  # ◀◀◀ Vertex AI 리소스 위치 (예: us-central1)
    try: OPENAI_API_KEY = userdata.get("OPENAI_API_KEY")
    except (NotebookAccessError, KeyError): print("Warning: OPENAI_API_KEY not found in Colab userdata.")
    try: ANTHROPIC_API_KEY = userdata.get("ANTHROPIC_API_KEY")
    except (NotebookAccessError, KeyError): print("Warning: ANTHROPIC_API_KEY not found in Colab userdata.")
    try: GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')
    except (NotebookAccessError, KeyError): print("Warning: GEMINI_API_KEY not found in Colab userdata.")

    # GPT_MODEL: str = "gpt-5-mini-2025-08-07"
    GPT_MODEL: str = "gpt-4.1-mini"
    # IMAGE_BACKEND: str = "google"; IMAGE_MODEL: str = "imagen-3.0-fast-generate-001"
    IMAGE_BACKEND: str = "google"; IMAGE_MODEL: str = "imagen-4.0-ultra-generate-001"
    SD_MODEL_ID: str = "stabilityai/stable-diffusion-xl-base-1.0"
    NEG_PROMPT: str = "Additional body parts, Flaw, Imperfection, Joined fingers, Unpleasant size, Identifying sign, Incorrect structure, Wrong proportion, Tacky, Poor quality, Poor clarity, Spot, Absent arms, fingers, hands, legs, Error, Damaged, Beyond the image, Badly drawn face, feet, hands, Text on paper, Repulsive, Unpleasant size, Shortened, Narrow eyes, Visual plan, Arrangement, Cut off, Unpleasant, Blurry, Unattractive, Awkward position, Imaginary framework, Watermark, text"

# ───────────────────────────────────────
# 2) API Client Initialization
# ───────────────────────────────────────
openai_client: Optional[openai.OpenAI] = None
if Config.OPENAI_API_KEY: openai_client = openai.OpenAI(api_key=Config.OPENAI_API_KEY)
else: print("Warning: OpenAI API client not initialized. OPENAI_API_KEY is missing.")

if Config.GEMINI_API_KEY: genai.configure(api_key=Config.GEMINI_API_KEY)
else: print("Warning: Google Gemini API not configured. GEMINI_API_KEY is missing.")

# ───────────────────────────────────────
# 2.1) Model Wrappers
# ───────────────────────────────────────
class LLMAgent:
    def __init__(self, model: str = Config.GPT_MODEL): self.model = model
    def chat(self, messages: List[Dict[str, str]], *, max_tokens: int = 300, temperature: float = 0.7, top_p: float = 0.9) -> str:
        if not openai_client: return "오류: OpenAI API 클라이언트가 초기화되지 않았습니다."
        try:
            resp = openai_client.chat.completions.create(model=self.model, messages=messages, max_tokens=max_tokens, temperature=temperature, top_p=top_p)
            content = resp.choices[0].message.content
            return content.strip() if content else ""
        except Exception as e: print(f"Error in LLMAgent.chat: {e}"); return f"LLM 호출 중 오류 발생: {e}"

class ImageGenerator:
    def __init__(self):
        self.backend = Config.IMAGE_BACKEND.lower()
        self.model_name = Config.IMAGE_MODEL # Vertex AI 모델 ID 또는 SD 모델 ID
        self.pipe = None # Stable Diffusion 파이프라인
        self.vertex_generation_model = None # Vertex AI 이미지 생성 모델 인스턴스

        if self.backend == "google":
            if not Config.VERTEX_AI_PROJECT_ID or Config.VERTEX_AI_PROJECT_ID == "YOUR_VERTEX_AI_PROJECT_ID":
                print("Warning: VERTEX_AI_PROJECT_ID is not set correctly in Config. Vertex AI Imagen backend will not work.")
                self.backend = None # 백엔드 비활성화
            else:
                try:
                    from google.colab import auth
                    import vertexai
                    from vertexai.preview.vision_models import ImageGenerationModel

                    auth.authenticate_user() # Colab 사용자 인증
                    print(f"Initializing Vertex AI for project: {Config.VERTEX_AI_PROJECT_ID}, location: {Config.VERTEX_AI_LOCATION}")
                    vertexai.init(project=Config.VERTEX_AI_PROJECT_ID, location=Config.VERTEX_AI_LOCATION)
                    # 모델은 generate 함수 호출 시 로드 (모델 ID가 동적으로 변경될 수 있으므로)
                    print("Vertex AI initialized successfully.")
                except ImportError:
                    print("ERROR: vertexai library not found. Please install google-cloud-aiplatform. Disabling Google image backend.")
                    self.backend = None
                except Exception as e:
                    print(f"Error initializing Vertex AI: {e}. Disabling Google image backend.")
                    self.backend = None

        elif self.backend == "sd":
            # ... (기존 Stable Diffusion 모델 로드 로직) ...
            sd_model_to_load = Config.SD_MODEL_ID
            try:
                self.pipe = DiffusionPipeline.from_pretrained(sd_model_to_load, torch_dtype=torch.float16, use_safetensors=True).to("cuda" if torch.cuda.is_available() else "cpu")
                print(f"Loaded SD model: {sd_model_to_load}.")
            except Exception as e:
                print(f"Error loading SD model {sd_model_to_load}: {e}. Trying fallback...")
                try:
                    sd_model_to_load = "runwayml/stable-diffusion-v1-5"
                    self.pipe = DiffusionPipeline.from_pretrained(sd_model_to_load, torch_dtype=torch.float16, use_safetensors=True).to("cuda" if torch.cuda.is_available() else "cpu")
                    print(f"Loaded fallback SD model: {sd_model_to_load}.")
                    Config.SD_MODEL_ID = sd_model_to_load
                except Exception as e2:
                    print(f"Error loading fallback SD model: {e2}")
                    self.pipe = None
        if not torch.cuda.is_available() and self.backend == "sd":
            print("Warning: CUDA not available for SD, Stable Diffusion will run on CPU if enabled.")


    def generate(self, prompt: str, *, w: int = 768, h: int = 768, steps: int = 25, scale: float = 7.0) -> Optional[Image.Image]:
        if self.backend == "google":
            if not Config.VERTEX_AI_PROJECT_ID or Config.VERTEX_AI_PROJECT_ID == "YOUR_VERTEX_AI_PROJECT_ID":
                gr.Warning("Vertex AI 프로젝트 ID가 설정되지 않았습니다.")
                return None
            try:
                from vertexai.preview.vision_models import ImageGenerationModel # 함수 내에서 import 하여 vertexai.init() 이후에 호출되도록 보장

                gr.Info(f"Vertex AI Imagen ({self.model_name}) 이미지 생성 중...")

                # 모델 인스턴스 로드 (매번 호출 시 로드하거나, __init__에서 한 번 로드 후 재사용)
                # 여기서는 매번 로드하여 Config 변경에 유연하게 대응
                if self.vertex_generation_model is None or self.vertex_generation_model._model_id != self.model_name: # 모델 ID 변경 시 새로 로드
                    self.vertex_generation_model = ImageGenerationModel.from_pretrained(self.model_name)

                aspect_ratio_setting = "1:1" # 기본값
                if w == 1024 and h == 1024: aspect_ratio_setting = "1:1"
                elif w == 1536 and h == 1024: aspect_ratio_setting = "3:2" # 지원하는지 확인 필요, 예시
                elif w == 1024 and h == 1536: aspect_ratio_setting = "2:3" # 지원하는지 확인 필요, 예시
                elif w == 1920 and h == 1080: aspect_ratio_setting = "16:9"
                elif w == 1080 and h == 1920: aspect_ratio_setting = "9:16"
                # API가 지원하는 정확한 aspect_ratio 값으로 설정해야 합니다.
                # 문서에는 "1:1", "9:16", "16:9", "4:3", "3:4" 등이 언급됩니다.
                # w, h 값에 따라 가장 유사한 지원 비율로 설정하거나, 사용자에게 지원 비율만 선택하게 하는 것이 좋습니다.

                # Vertex AI Imagen API는 width/height를 직접 받지 않고 aspect_ratio를 사용합니다.
                # 출력 이미지 크기는 모델 및 aspect_ratio에 따라 결정됩니다.
                # 요청 시 number_of_images로 생성할 이미지 수를 지정할 수 있습니다.
                response_obj = self.vertex_generation_model.generate_images( # 변수명을 response_obj로 변경하여 명확
                    prompt=prompt,
                    number_of_images=1,
                    aspect_ratio=aspect_ratio_setting,
                    negative_prompt=Config.NEG_PROMPT
                    # safety_filter_level="block_few", # "block_some", "block_most", "block_none_unsafe" (사용 가능 여부 확인)
                    # person_generation="allow_all" # "allow_adult", "disallow"
                    # 필요한 경우 다른 파라미터 추가 (예: seed, language)
                )

                # response_obj.images (이것이 실제 이미지 리스트)를 확인
                if response_obj and hasattr(response_obj, 'images') and response_obj.images and len(response_obj.images) > 0:
                    generated_image_instance = response_obj.images[0] # 첫 번째 이미지 객체
                    img_bytes = generated_image_instance._image_bytes # _image_bytes는 내부 속성일 수 있으나, 제공된 스니펫 기준
                    if img_bytes:
                        gr.Info("Vertex AI Imagen 이미지 생성 완료.")
                        return Image.open(io.BytesIO(img_bytes)).convert("RGB")
                    else:
                        gr.Error("Vertex AI Imagen에서 이미지 바이트를 가져오지 못했습니다.")
                        return None
                else:
                    gr.Error("Vertex AI Imagen에서 이미지를 생성하지 못했습니다 (반환된 이미지 없음).")
                    return None

            except ImportError:
                gr.Error("Vertex AI 라이브러리를 찾을 수 없습니다. `google-cloud-aiplatform`을 설치해주세요.")
                return Image.new('RGB', (w,h), color='lightpink') # 라이브러리 없음 오류 색상
            except Exception as e:
                error_message = str(e).lower()
                if "permission_denied" in error_message or "unauthenticated" in error_message or "serviceusage.services.use" in error_message:
                    gr.Error(f"Vertex AI 인증 오류 또는 권한 문제. Google Cloud 프로젝트 설정 및 인증을 확인하세요: {e}")
                else:
                    gr.Error(f"Vertex AI Imagen 이미지 생성 중 예외 발생: {e}")
                print(f"Vertex AI Imagen image gen exception: {e}")
                return Image.new('RGB', (w,h), color='lightgrey')

        elif self.backend == "sd":
            # ... (Stable Diffusion 로직은 동일) ...
            if not self.pipe:
                gr.Warning("SD 파이프라인 준비 안됨.")
                return None
            try:
                gr.Info(f"SD ({Config.SD_MODEL_ID}) 이미지 생성 중...")
                image = self.pipe(prompt, height=h, width=w, guidance_scale=scale, num_inference_steps=steps, negative_prompt=Config.NEG_PROMPT).images[0]
                gr.Info("SD 이미지 생성 완료.")
                return image
            except Exception as e:
                gr.Error(f"SD 이미지 생성 오류: {e}")
                print(f"SD image gen error: {e}")
                return Image.new('RGB', (w,h), color='lightgrey')

        gr.Warning(f"알 수 없는 이미지 백엔드: {self.backend}")
        return None


llm = LLMAgent()
img_gen = ImageGenerator()

# ───────────────────────────────────────
# Episode Parsing Logic
# ───────────────────────────────────────
def parse_episodes_from_text(text_content: str, max_episodes: int = MAX_EPISODES_TO_PARSE) -> List[Dict[str, str]]:
    if not text_content: return []
    episode_title_pattern = re.compile(r"^(.*?(\d+)화)$", re.MULTILINE)
    parsed_episodes = []; episode_counter = 0
    matches = list(episode_title_pattern.finditer(text_content))
    for i, match in enumerate(matches):
        if episode_counter >= max_episodes: break
        episode_title_full = match.group(1).strip(); episode_number_str = match.group(2)
        content_start = match.end(); content_end = matches[i+1].start() if (i + 1) < len(matches) else len(text_content)
        episode_content = text_content[content_start:content_end].strip(); display_title = f"{episode_number_str}화"
        if episode_content: parsed_episodes.append({"title": episode_title_full, "display_title": display_title, "content": episode_content}); episode_counter += 1
    if not parsed_episodes and text_content.strip():
        gr.Info("회차 구분 명확하지 않아 전체 내용을 1화로 처리합니다.")
        parsed_episodes.append({"title": "전체 내용 (1화)", "display_title": "1화", "content": text_content.strip()})
    return parsed_episodes

def get_cumulative_content(selected_display_title: str, parsed_episodes: List[Dict[str, str]]) -> str:
    if not selected_display_title or not parsed_episodes: return ""
    cumulative_text = []; selected_index = -1
    for i, episode in enumerate(parsed_episodes):
        if episode["display_title"] == selected_display_title: selected_index = i; break
    if selected_index != -1:
        for i in range(selected_index + 1): cumulative_text.append(parsed_episodes[i]["content"])
    return "\n\n".join(cumulative_text)

# ───────────────────────────────────────
# Helper & Callback Functions for Initial Setup & Situations
# ───────────────────────────────────────
def generate_story_briefing_llm(world_context: str) -> Optional[str]:
    if not openai_client or not world_context: return None
    prompt = (
        f"다음 웹소설 내용을 바탕으로, 현재까지의 주요 줄거리, 주인공(들)의 상황, 그리고 앞으로 해결해야 할 과제나 목표 등을 약 300-400자 내외의 한글로 요약해주세요.\n"
        f"이 이야기에 처음 참여하는 사람에게 맥락을 설명하는 것이 목적입니다. 이야기의 매력을 느낄 수 있도록 흥미롭게 브리핑해주세요.\n"
        f"각 문단은 2-3 문장으로 구성하고, 문단 사이에 한 줄의 공백(줄바꿈 두 번)을 추가하여 가독성을 높여주세요.\n"
        f"--- 원작 내용 (최대 {len(world_context)}자 중 일부) ---\n{world_context[:2500]}...\n--- (내용 끝) ---"
    )
    try:
        response_text = llm.chat([{"role": "user", "content": prompt}], max_tokens=450, temperature=0.5)
        return response_text if response_text else "스토리 브리핑 생성에 실패했습니다."
    except Exception as e: print(f"Error generating story briefing: {e}"); return "스토리 브리핑 생성 중 오류가 발생했습니다."



# def confirm_start_episode_and_setup(
#     selected_episode_display_title: str,    # 드롭다운에서 선택된 회차의 표시 이름 (예: "N화")
#     parsed_episodes_list: List[Dict[str,str]], # 전체 파싱된 에피소드 객체 리스트 (load_file_and_parse_episodes_revised에서 반환된 parsed_episodes_state 값)
#     current_my_profile_in_box: str,        # 프로필 입력창의 현재 내용
#     # full_story_context: str # 참고: 전체 원작 내용은 필요시 다른 상태 변수에서 가져와 LLM 프롬프트에 활용 가능
# ) -> Tuple[
#     str,                   # focused_episode_content_state 업데이트용
#     str,                   # current_timeline_info_state 업데이트용
#     gr.update,             # chatbot_display 업데이트용
#     List[Dict[str,str]],   # diaglist_state 업데이트용
#     float,                 # initial_setup_step 업데이트용
#     list,                  # role_choices_list_state 업데이트용
#     list,                  # scene_choices_list_state (초기화)
#     gr.update,             # user_box 업데이트용
#     gr.update,             # send_btn 업데이트용
#     gr.update,             # request_event_btn 업데이트용
#     gr.update,             # inject_situation_btn 업데이트용
#     gr.update              # confirm_start_episode_btn (비활성화)
# ]:
#     if not selected_episode_display_title or not parsed_episodes_list:
#         gr.Warning("시작할 회차를 선택해주세요 또는 파일이 올바르게 로드되지 않았습니다.")
#         # 오류 발생 시 반환할 기본값들 (UI 변경 없음 또는 최소화)
#         # 현재 상태를 유지하거나, 사용자에게 명확한 오류를 알리는 것이 중요.
#         # 여기서는 현재 상태를 최대한 유지하는 방향으로 간단히 처리.
#         # 실제로는 이 상황에 맞는 더 정교한 반환 값 설정이 필요할 수 있음.
#         return ("", "", gr.update(), [], 0.5, [], [], gr.update(interactive=True), gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=True))

#     initial_diaglist_for_chatbot = []

#     # 1. 선택된 N화까지의 누적 내용 생성
#     focused_content = get_cumulative_content(selected_episode_display_title, parsed_episodes_list)
#     current_timeline_info = f"{selected_episode_display_title} 시점을 기준으로 이야기가 시작됩니다."
#     gr.Info(current_timeline_info)

#     effective_profile = current_my_profile_in_box if current_my_profile_in_box.strip() else DEFAULT_MY_PROFILE_PLACEHOLDER

#     # 2. N화 기준 브리핑 생성
#     # generate_story_briefing_llm은 focused_content (N화까지 내용)만으로 브리핑 생성
#     briefing = generate_story_briefing_llm(focused_content)
#     briefing_text = briefing if briefing else "스토리 브리핑을 가져오지 못했습니다."

#     # 3. N화 기준 역할 선택지 생성
#     # generate_my_role_choices_llm도 focused_content와 effective_profile로 역할 생성.
#     # (AI가 전체 내용을 참고하여 N화 시점의 역할을 제안하게 하려면,
#     #  이 함수에 full_story_context도 전달하고 내부 프롬프트를 수정해야 함. 현재는 N화 기준.)
#     role_choice_data = generate_my_role_choices_llm(focused_content, effective_profile)

#     role_choices_list_for_state = []
#     new_setup_step = 0.5 # 기본값: 오류 시 현재 상태 유지 또는 특정 오류 상태
#     user_box_placeholder_update = gr.update(placeholder=EPISODE_CONFIRM_USER_BOX_PLACEHOLDER, interactive=False)
#     send_btn_text_update = gr.update(value=DEFAULT_SEND_BUTTON_TEXT, interactive=False)
#     req_event_btn_interactive_update = gr.update(interactive=False)
#     inject_sit_btn_interactive_update = gr.update(interactive=False)
#     confirm_start_episode_btn_interactive_update = gr.update(interactive=True) # 기본적으로는 다시 누를 수 있게

#     if role_choice_data and role_choice_data.get("full_text") and not role_choice_data.get("is_fallback"):
#         role_choices_text_for_display = role_choice_data['full_text']
#         role_choices_list_for_state = role_choice_data.get("choices_list", [])

#         combined_initial_message = f"{STORY_BRIEFING_PREFIX}{briefing_text}{MY_ROLE_CHOICE_PREFIX}{role_choices_text_for_display}"
#         initial_diaglist_for_chatbot.append({"role": "assistant", "content": combined_initial_message})

#         new_setup_step = 1.0 # 역할 선택 대기 상태로 변경
#         user_box_placeholder_update = gr.update(placeholder=ROLE_CHOICE_USER_BOX_PLACEHOLDER, interactive=True)
#         send_btn_text_update = gr.update(value=ROLE_CHOICE_SEND_BUTTON_TEXT, interactive=True)
#         confirm_start_episode_btn_interactive_update = gr.update(interactive=False) # 확정 후에는 비활성화
#     else:
#         fallback_text = role_choice_data.get("full_text") if role_choice_data else "역할 선택지 생성에 실패했습니다."
#         combined_initial_message = f"{STORY_BRIEFING_PREFIX}{briefing_text}\n\n{fallback_text}\nAI 캐릭터에게 말을 걸어 이야기를 시작하세요."
#         initial_diaglist_for_chatbot.append({"role": "assistant", "content": combined_initial_message})

#         # 역할 선택지 생성 실패 시, 바로 일반 대화 모드로 진입하거나 오류 안내
#         # 여기서는 일반 대화 모드로 보내고, 사용자가 직접 AI에게 말을 걸도록 유도
#         new_setup_step = 3.0
#         user_box_placeholder_update = gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER, interactive=True)
#         send_btn_text_update = gr.update(value=DEFAULT_SEND_BUTTON_TEXT, interactive=True)
#         req_event_btn_interactive_update = gr.update(interactive=True) # 일반 대화 모드이므로 버튼 활성화
#         inject_sit_btn_interactive_update = gr.update(interactive=True)
#         confirm_start_episode_btn_interactive_update = gr.update(interactive=False) # 확정 후에는 비활성화

#     return (
#         focused_content,                         # focused_episode_content_state
#         current_timeline_info,                   # current_timeline_info_state
#         gr.update(value=initial_diaglist_for_chatbot), # chatbot_display
#         initial_diaglist_for_chatbot,            # diaglist_state
#         new_setup_step,                          # initial_setup_step
#         role_choices_list_for_state,             # role_choices_list_state
#         [],                                      # scene_choices_list_state (초기화)
#         user_box_placeholder_update,             # user_box
#         send_btn_text_update,                    # send_btn
#         req_event_btn_interactive_update,        # request_event_btn
#         inject_sit_btn_interactive_update,       # inject_situation_btn
#         confirm_start_episode_btn_interactive_update # confirm_start_episode_btn
#     )

def confirm_start_episode_and_setup(
    selected_episode_display_title: str,
    parsed_episodes_list: List[Dict[str,str]],
    current_my_profile_in_box: str,
) -> Tuple[
    str, str, gr.update, List[Dict[str,str]], float, list, list,
    gr.update, gr.update, gr.update, gr.update, gr.update
]:
    if not selected_episode_display_title or not parsed_episodes_list:
        gr.Warning("시작할 회차를 선택해주세요 또는 파일이 올바르게 로드되지 않았습니다.")
        return ("", "", gr.update(), [], 0.5, [], [], gr.update(), gr.update(), gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=True))

    initial_diaglist_for_chatbot = []

    # 선택된 회차 정보 및 인덱스 찾기
    selected_episode_idx = -1
    for i, ep in enumerate(parsed_episodes_list):
        if ep["display_title"] == selected_episode_display_title:
            selected_episode_idx = i
            break

    if selected_episode_idx == -1:
        gr.Warning("선택한 회차를 찾을 수 없습니다.")
        return ("", "", gr.update(), [], 0.5, [], [], gr.update(), gr.update(), gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=True))

    # 선택된 회차의 전체 내용과 주변 회차 정보 가져오기
    current_episode_content = parsed_episodes_list[selected_episode_idx]["content"]
    prev_episode_content = parsed_episodes_list[selected_episode_idx-1]["content"] if selected_episode_idx > 0 else ""
    next_episode_content = parsed_episodes_list[selected_episode_idx+1]["content"] if selected_episode_idx < len(parsed_episodes_list)-1 else ""

    # N화까지의 누적 내용 생성
    focused_content = get_cumulative_content(selected_episode_display_title, parsed_episodes_list)

    raw_text_content = ""
    for ep in parsed_episodes_list:
        raw_text_content += ep["content"] + "\n\n"


    current_timeline_info = f"{selected_episode_display_title} 시점을 기준으로 이야기가 시작됩니다."
    gr.Info(current_timeline_info)

    effective_profile = current_my_profile_in_box if current_my_profile_in_box.strip() else DEFAULT_MY_PROFILE_PLACEHOLDER

    # N화 전용 브리핑 생성 - 프롬프트 구체화
    briefing_prompt = (
        f"다음 웹소설에 대한 간결한 브리핑을 작성해주세요. 브리핑은 두 부분으로 구성하되, 각 부분은 매우 간결하게 작성해주세요:\n\n"
        f"1. 작품 전체 소개 (300자 내외):\n"
        f"- '이 작품은 ~~~한 세계관입니다. 주인공 ~~~는 ~~~' 형식으로 시작\n"
        f"- 핵심 내용만 담아 몰입과 유저 참여 유도를 위해 흥미가 느껴지도록 작성\n\n"
        f"2. {selected_episode_display_title} 시점 요약 (200자 내외):\n"
        f"- '당신은 지금 이 작품의 {selected_episode_display_title}에 서 있습니다.' 문장으로 시작\n"
        f"- {selected_episode_display_title}에서 일어나는 핵심 사건만 간략히 설명\n\n"
        f"각 부분은 불필요한 설명 없이 핵심만 담아주세요.\n\n"
        f"--- 전체 작품 내용 (참고용) ---\n{raw_text_content[:1500]}...\n\n"
        f"--- {selected_episode_display_title} 내용 ---\n{current_episode_content[:500]}"
    )

    # 기존 함수 대신 직접 LLM 호출로 더 구체적인 브리핑 생성
    briefing = llm.chat([{"role": "user", "content": briefing_prompt}], max_tokens=450, temperature=0.5)
    briefing_text = briefing if briefing else "스토리 브리핑을 가져오지 못했습니다."

    # N화에 맞는 역할 선택지 생성 - 더 구체적인 프롬프트
    role_prompt_content = (
        f"당신은 창의적인 스토리 작가입니다. 웹소설 {selected_episode_display_title}의 내용과 참여자('나')의 프로필을 바탕으로, "
        f"'나'가 이 특정 회차에서 맡을 수 있는 흥미로운 역할 3가지를 제안해주세요.\n\n"
        f"【역할 설계 요구사항】\n"
        f"1. 각 역할은 {selected_episode_display_title}에 등장하는 인물, 장소, 사건과 직접적으로 연결되어야 합니다.\n"
        f"2. {selected_episode_display_title}의 플롯에 자연스럽게 참여할 수 있는 역할이어야 합니다.\n"
        f"3. 단순한 '아군/적군' 구분이 아닌, 구체적인 배경이나 동기를 가진 역할이어야 합니다.\n"
        f"4. 역할마다 이 회차의 특정 장면이나 등장인물과 관련된 구체적인 연결점을 반드시 포함하세요.\n\n"
        f"출력 형식은 다음과 같이 정확히 지켜주세요 (다른 설명 없이 역할 목록만):\n"
        f"1. [첫 번째 역할 - 구체적 설명과 {selected_episode_display_title}의 어떤 장면/인물과 연결되는지]\n\n"
        f"2. [두 번째 역할 - 구체적 설명과 {selected_episode_display_title}의 어떤 장면/인물과 연결되는지]\n\n"
        f"3. [세 번째 역할 - 구체적 설명과 {selected_episode_display_title}의 어떤 장면/인물과 연결되는지]"
    )

    role_prompt_messages = [
        {"role": "system", "content": role_prompt_content},
        {"role": "user", "content": (
            f"【{selected_episode_display_title} 내용】\n{current_episode_content[:2500]}\n\n"
            f"【이전 회차 맥락 참고】\n{prev_episode_content[:500] if prev_episode_content else '이전 회차 없음'}\n\n"
            f"【'나'(참여자)의 기본 프로필】\n{effective_profile}\n\n"
            f"{selected_episode_display_title} 시점에서 당신은?:"
        )}
    ]

    # 직접 LLM 호출로 더 구체적인 역할 선택지 생성
    role_response = llm.chat(role_prompt_messages, max_tokens=500, temperature=0.7)

    # 역할 선택지 파싱 로직
    role_choice_data = None
    if role_response:
        roles_temp = {}
        current_role_num = None
        current_role_text = []

        for line in role_response.splitlines():
            match = re.match(r"^\s*([1-9])\.\s*(.*)", line)
            if match:
                if current_role_num is not None and current_role_text:
                    roles_temp[current_role_num] = "\n".join(current_role_text).strip()
                current_role_num = int(match.group(1))
                current_role_text = [match.group(2).strip()]
            elif current_role_num is not None and line.strip():
                current_role_text.append(line.strip())

        if current_role_num is not None and current_role_text:
            roles_temp[current_role_num] = "\n".join(current_role_text).strip()

        parsed_choices = [roles_temp.get(i, "") for i in range(1, 4) if roles_temp.get(i, "")]
        if len(parsed_choices) >= 2:
            choices_for_display = "\n\n".join([f"{i+1}. {choice}" for i, choice in enumerate(parsed_choices)])
            role_choice_data = {"full_text": choices_for_display, "choices_list": parsed_choices}
        else:
            role_choice_data = {"full_text": "역할 선택지 생성에 실패했습니다.", "choices_list": [], "is_fallback": True}
    else:
        role_choice_data = {"full_text": "역할 선택지 생성에 실패했습니다.", "choices_list": [], "is_fallback": True}

    role_choices_list_for_state = []
    new_setup_step = 0.5
    user_box_placeholder_update = gr.update(placeholder=EPISODE_CONFIRM_USER_BOX_PLACEHOLDER, interactive=False)
    send_btn_text_update = gr.update(value=DEFAULT_SEND_BUTTON_TEXT, interactive=False)
    req_event_btn_interactive_update = gr.update(interactive=False)
    inject_sit_btn_interactive_update = gr.update(interactive=False)
    confirm_start_episode_btn_interactive_update = gr.update(interactive=True)

    if role_choice_data and role_choice_data.get("full_text") and not role_choice_data.get("is_fallback"):
        role_choices_text_for_display = role_choice_data['full_text']
        role_choices_list_for_state = role_choice_data.get("choices_list", [])

        # 시점과 선택된 회차를 확실히 강조하는 메시지 구성
        combined_initial_message = (
            f"{STORY_BRIEFING_PREFIX}【{selected_episode_display_title} 시점 스토리 브리핑】\n{briefing_text}\n\n"
            f"{MY_ROLE_CHOICE_PREFIX}【{selected_episode_display_title}에서 선택 가능한 역할】\n{role_choices_text_for_display}"
        )
        initial_diaglist_for_chatbot.append({"role": "assistant", "content": combined_initial_message})

        new_setup_step = 1.0
        user_box_placeholder_update = gr.update(placeholder=ROLE_CHOICE_USER_BOX_PLACEHOLDER, interactive=True)
        send_btn_text_update = gr.update(value=ROLE_CHOICE_SEND_BUTTON_TEXT, interactive=True)
        confirm_start_episode_btn_interactive_update = gr.update(interactive=False)
    else:
        fallback_text = role_choice_data.get("full_text") if role_choice_data else "역할 선택지 생성에 실패했습니다."
        combined_initial_message = (
            f"{STORY_BRIEFING_PREFIX}【{selected_episode_display_title} 시점 스토리 브리핑】\n{briefing_text}\n\n"
            f"{fallback_text}\n\n{selected_episode_display_title} 시점에서 AI 캐릭터에게 말을 걸어 이야기를 시작하세요."
        )
        initial_diaglist_for_chatbot.append({"role": "assistant", "content": combined_initial_message})

        new_setup_step = 3.0
        user_box_placeholder_update = gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER, interactive=True)
        send_btn_text_update = gr.update(value=DEFAULT_SEND_BUTTON_TEXT, interactive=True)
        req_event_btn_interactive_update = gr.update(interactive=True)
        inject_sit_btn_interactive_update = gr.update(interactive=True)
        confirm_start_episode_btn_interactive_update = gr.update(interactive=False)

    return (
        focused_content, current_timeline_info,
        gr.update(value=initial_diaglist_for_chatbot), initial_diaglist_for_chatbot,
        new_setup_step, role_choices_list_for_state, [],
        user_box_placeholder_update, send_btn_text_update,
        req_event_btn_interactive_update, inject_sit_btn_interactive_update, confirm_start_episode_btn_interactive_update
    )

def generate_my_role_choices_llm(world_context: str, my_profile: str) -> Optional[Dict[str, Any]]:
    if not openai_client: return None
    context_summary = world_context if len(world_context) < 1000 else world_context[:500] + "..." + world_context[-500:]
    prompt_content = (
        "당신은 창의적인 스토리 작가입니다. 제공된 소설 세계관 정보와 참여자('나')의 기본 프로필을 참고하여, '나'가 이 소설 세계관에서 맡을 수 있는 흥미로운 역할 3가지를 제안해주세요.\n"
        "각 역할은 소설의 분위기와 설정, 그리고 현재까지의 줄거리(특히 최근 사건이나 등장인물)와 밀접하게 연관되어야 합니다.\n"
        "단순한 '아군/적군'이 아닌, 구체적인 배경이나 동기를 암시하는 한두 문장의 설명으로 각 역할을 제시해주세요.\n"
        "출력은 다음 형식을 정확히 지켜주세요 (다른 설명 없이 역할 목록만, 각 역할 설명 후에는 빈 줄(\n\n)을 넣어주세요):\n"
        "1. [첫 번째 역할에 대한 구체적이고 흥미로운 설명]\n\n"
        "2. [두 번째 역할에 대한 구체적이고 흥미로운 설명]\n\n"
        "3. [세 번째 역할에 대한 구체적이고 흥미로운 설명]"
    )
    role_prompt_messages = [
        {"role": "system", "content": prompt_content},
        {"role": "user", "content": (
            f"【소설 세계관 정보 및 현재까지의 줄거리】\n{context_summary or '제공되지 않음'}\n\n"
            f"【'나'(참여자)의 기본 프로필】\n{my_profile or DEFAULT_MY_PROFILE_PLACEHOLDER}\n\n"
            "제안할 역할 3가지 (위 형식 엄수):"
        )}
    ]
    try:
        response_text = llm.chat(role_prompt_messages, max_tokens=350, temperature=0.75)
        if response_text:
            roles_temp = {}
            current_role_num = None
            current_role_text = []
            for line in response_text.splitlines():
                match = re.match(r"^\s*([1-9])\.\s*(.*)", line)
                if match:
                    if current_role_num is not None and current_role_text:
                        roles_temp[current_role_num] = "\n".join(current_role_text).strip()
                    current_role_num = int(match.group(1))
                    current_role_text = [match.group(2).strip()]
                elif current_role_num is not None and line.strip():
                    current_role_text.append(line.strip())
            if current_role_num is not None and current_role_text:
                roles_temp[current_role_num] = "\n".join(current_role_text).strip()

            parsed_choices = [roles_temp.get(i, "") for i in range(1, 4) if roles_temp.get(i, "")]
            if len(parsed_choices) >= 2:
                choices_for_display = "\n\n".join([f"{i+1}. {choice}" for i, choice in enumerate(parsed_choices)])
                return {"full_text": choices_for_display, "choices_list": parsed_choices}
        print(f"Failed to parse role choices from LLM: '{response_text}'")
        fallback_choices_text = "역할 선택지 생성에 실패했습니다. AI 캐릭터에게 말을 걸어 이야기를 시작하세요."
        return {"full_text": fallback_choices_text, "choices_list": [], "is_fallback": True}
    except Exception as e: print(f"Error generating role choices: {e}"); return None

def generate_scene_entry_choices_llm(
    full_story_context: str,       # ★ 신규: 원작 전체 내용
    current_timeline_info: str,    # ★ 신규: 예: "N화 시점"
    # world_context: str,
    my_profile: str,
    my_role: str
    ) -> Optional[Dict[str, Any]]:
    if not openai_client: return None


    context_summary = full_story_context[-20000:] # 예시: 최근 2만자 정도 참고
    if len(full_story_context) > 20000:
        context_summary = f"...(이전 내용 생략)...\n{context_summary}"
    my_name = my_profile.splitlines()[0].replace('이름: ', '').strip() if my_profile and '이름:' in my_profile.splitlines()[0] else DEFAULT_MY_PROFILE_NAME
    prompt_content = (
        f"당신은 스토리텔링 AI입니다. 사용자 '{my_name}'은(는) '{my_role}' 역할을 맡아, **'{current_timeline_info}' 시점**에서 이야기에 참여하려고 합니다.\n"
        f"당신은 이 이야기의 전체 원작 내용을 알고 있습니다. (아래 제공되는 '세계관 및 현재까지의 줄거리'는 '{current_timeline_info}'까지의 내용 요약 또는 참고용 최근 내용입니다.)\n"
        f"사용자가 '{current_timeline_info}'에서 시작하기에 적절하고 흥미로운 **세 가지 구체적인 장면 진입 선택지**를 생성해주세요. 이 선택지들은 '{current_timeline_info}' 시점의 상황과 주요 등장인물, 최근 사건과 직접 관련되어야 하며, 사용자 역할 '{my_role}'과도 잘 어울려야 합니다.\n"
        f"또한, 이 선택지들은 당신이 알고 있는 **원작 전체의 설정 및 향후 전개와도 논리적으로 충돌하지 않도록** 고려해주세요. (IF 스토리를 위한 발판이 될 수 있음)\n"
        f"선택지는 다음과 같은 세 가지 유형으로 구성해주세요:\n"
        f"1. **주인공(또는 이야기의 중심인물)과 협력하는 장면**\n"
        f"2. **주인공(또는 이야기의 중심인물)과 대립하거나 긴장 관계에 놓이는 장면**\n"
        f"3. **중립적이지만 호기심을 자극하는 발견 또는 만남의 장면**\n\n"
        f"각 장면 설명은 2-3문장으로, 줄바꿈(\n\n)을 포함하여 가독성을 높여주세요. 원작 등장인물 이름이나 특정 사건을 언급하여 연관성을 높여야 합니다.\n"
        f"출력 형식은 다음과 같습니다 (다른 설명 없이 장면 선택지만):\n"
        f"1. [1번 유형의 장면 설명]\n\n2. [2번 유형의 장면 설명]\n\n3. [3번 유형의 장면 설명]"
    )

    scene_prompt_messages = [
        {"role": "system", "content": prompt_content},
        {"role": "user", "content": (
            f"【세계관 및 현재까지의 줄거리 ({current_timeline_info} 기준 참고용)】\n{context_summary or '제공되지 않음'}\n\n" # 여기서는 focused_content를 전달받는 대신, full_story_context의 일부를 사용
            f"【'나'({my_name})의 프로필】\n{my_profile or DEFAULT_MY_PROFILE_PLACEHOLDER}\n\n"
            f"【'나'({my_name})가 선택한 역할】\n{my_role}\n\n"
            "제안할 세 가지 장면 진입 선택지 (위 형식 엄수, 각 선택지 사이에 빈 줄 포함):"
        )}
    ]

    try:
        response_text = llm.chat(scene_prompt_messages, max_tokens=500, temperature=0.7)
        # ... (파싱 로직) ...
        if response_text: # 임시 파싱 로직, 실제로는 이전과 동일한 견고한 파싱 사용
            scenes_temp = {}
            current_scene_num = None
            current_scene_text = []
            for line in response_text.splitlines():
                match = re.match(r"^\s*([1-9])\.\s*(.*)", line)
                if match:
                    if current_scene_num is not None and current_scene_text: scenes_temp[current_scene_num] = "\n".join(current_scene_text).strip()
                    current_scene_num = int(match.group(1)); current_scene_text = [match.group(2).strip()]
                elif current_scene_num is not None: current_scene_text.append(line)
            if current_scene_num is not None and current_scene_text: scenes_temp[current_scene_num] = "\n".join(current_scene_text).strip()
            parsed_scene_choices = [scenes_temp.get(i, "") for i in range(1, 4) if scenes_temp.get(i, "")]
            if len(parsed_scene_choices) == 3:
                return {"full_text": "\n\n".join([f"{i+1}. {choice}" for i, choice in enumerate(parsed_scene_choices)]), "choices_list": parsed_scene_choices}
    except Exception as e: print(f"Error in generate_scene_entry_choices_llm: {e}")
    return {"full_text": "장면 선택지 생성에 실패했습니다.", "choices_list": [], "is_fallback": True} # Fallback


def generate_ai_reaction_to_scene_choice_llm(
    full_story_context: str,       # ★ 신규: 원작 전체 내용
    current_timeline_info: str,    # ★ 신규: 예: "N화 시점"
    my_profile: str,
    my_role: str,
    chosen_scene_description: str
    ) -> Optional[str]:
    if not openai_client: return None

    context_summary = full_story_context[-15000:] # 예시: 최근 1만 5천자 정도 참고
    if len(full_story_context) > 15000:
        context_summary = f"...(이전 내용 생략)...\n{context_summary}"

    my_name = my_profile.splitlines()[0].replace('이름: ', '').strip() if my_profile and '이름:' in my_profile.splitlines()[0] else DEFAULT_MY_PROFILE_NAME
    prompt_content = (
        f"당신은 웹소설 속 AI 캐릭터 또는 나레이터입니다. 사용자 '{my_name}'(이)가 '{my_role}' 역할을 선택했고, **'{current_timeline_info}' 시점**에서 다음 장면으로 이야기에 참여하기로 결정했습니다:\n"
        f"【사용자 '{my_name}'이(가) 선택한 참여 장면】\n{chosen_scene_description}\n\n"
        f"당신은 이 이야기의 전체 원작 내용을 알고 있습니다. (아래 '세계관 및 현재까지의 줄거리'는 참고용입니다.)\n"
        f"선택된 장면에 맞춰, 다른 등장인물이 사용자 '{my_name}'에게 **먼저 말을 걸거나, 또는 '{my_name}'이 즉시 반응해야 하는 구체적인 사건이나 발견을 제시**하며 장면을 시작해주세요. 이 반응은 '{current_timeline_info}' 시점과 사용자 역할에 부합해야 하며, 당신이 알고 있는 원작 전체의 설정과도 일관성을 유지해야 합니다.\n"
        f"1. **다른 등장인물의 선제적 대사 (70% 등장빈도):** 선택된 장면에 등장하는 다른 주요 캐릭터(예: 소설 속 주요 캐릭터)가 사용자 '{my_name}'에게 먼저 말을 걸도록 하세요. 이 대사는 '{my_name}'의 다음 행동을 유도하거나, 장면의 핵심 갈등/사건을 직접적으로 제시해야 합니다. 예를 들어, 상대방이 '{my_name}'에게 **구체적인 질문을 하거나, 명확한 도움을 요청하거나, 혹은 긴급한 정보를 전달하며 '{my_name}'의 즉각적인 반응이나 결정을 요구**할 수 있습니다. 상대방의 현재 처지, 감정, 생각을 대사에 자연스럽게 포함시키되, **반드시 그 등장인물의 구체적인 대사 전체를 큰따옴표(\" \") 안에 넣어 명확히 제시해야 합니다.** '말을 걸었다' 등으로 상황만 암시하고 대사를 생략해서는 안 됩니다.\n" # 수정: 행동 유도 강화
        f"2. **상황/환경 묘사 또는 '{my_name}'의 행동 묘사 제시 (30% 등장빈도):** 선택된 장면의 주변 환경, 분위기, 또는 다른 캐릭터의 상태를 상세히 묘사하세요. 그리고 사용자 '{my_name}'이(가) 처한 구체적인 상황에서 **다음에 어떤 점에 주목해야 할지, 어떤 행동을 고려해볼 수 있을지에 대한 명확한 단서나 한두 가지 방향성을 3인칭 나레이션으로 제시**해주세요. 예를 들어, '*이로운은 눈앞에 펼쳐진 광경에 잠시 숨을 죽였다. 오래된 제단 위에는 알 수 없는 문자가 새겨진 석판이 놓여 있었고, 희미한 마력의 잔향이 느껴졌다. 석판을 먼저 자세히 조사해볼지, 아니면 주변의 다른 위험 요소를 먼저 경계할지 결정해야 할 순간이었다.*' 와 같이 사용자의 다음 행동을 위한 구체적인 선택지를 암시할 수 있습니다.\n\n" # 수정: 행동 방향 제시 강화
        f"AI의 응답은 1-3 문장으로 간결하되, 사용자의 다음 행동을 명확히 유도해야 합니다. (예: NPC의 질문, '{my_name}' 앞의 새로운 상황 전개 등)\n"
        f"**매우 중요: 어떤 경우에도 사용자 '{my_name}'의 대사나 생각을 1인칭으로 직접 생성하지 마세요.** '{my_name}'의 행동이나 대사는 사용자가 직접 입력할 것입니다. '어떻게 하시겠습니까?' 식의 직접적인 질문은 피해주세요.\n\n"
        f"당신의 응답은 사용자가 다음에 무엇을 해야 할지 명확히 알 수 있도록 구체적인 시작점을 제공해야 하며, 2-4문장으로 간결하게 작성해주세요. 문장 사이에 줄바꿈(\n\n)을 넣어 가독성을 높여주세요. **'어떻게 하시겠습니까?' 또는 이와 유사한 직접적인 질문으로 끝맺지 마세요.**\n\n"
        f"--- 참고 정보 ---\n"
        f"【세계관 및 현재까지의 줄거리 ({current_timeline_info} 기준 참고용)】\n{context_summary or '제공되지 않음'}\n"
        f"【사용자 '{my_name}'의 프로필】\n{my_profile or DEFAULT_MY_PROFILE_PLACEHOLDER}\n"
        f"--- (참고 정보 끝) ---"
    )

    messages = [{"role": "system", "content": prompt_content}]
    try:
        response = llm.chat(messages, max_tokens=300, temperature=0.75) # max_tokens 약간 늘림
        return response if response else f"'{my_name}'님, '{my_role}'으로서 '{chosen_scene_description}' 장면으로 모험을 시작합니다! 이제 당신의 차례입니다."
    except Exception as e:
        print(f"Error in generate_ai_reaction_to_scene_choice_llm: {e}")
        return f"오류로 인해 AI 캐릭터의 첫 반응을 생성하지 못했습니다. '{my_name}'님, 자유롭게 행동을 시작해주세요."

# ... (이하 extract_choices_from_text 부터 handle_request_system_situation 까지의 함수들은 이전과 동일)
def extract_choices_from_text(text_with_choices: str) -> List[str]:
    choices = []
    choice_pattern = re.compile(r"^\s*(?:[①②③④⑤]|[1-9][.\)])\s*(.+)")
    lines = text_with_choices.splitlines()
    in_choices_section = False
    choice_header_keywords = ["선택지:", "행동:", "어떻게 할까?", "다음 중 선택하세요:"]
    for line in lines:
        stripped_line = line.strip()
        if not stripped_line: continue
        is_header_line = any(keyword.lower() in stripped_line.lower() for keyword in choice_header_keywords)
        if is_header_line:
            in_choices_section = True
            potential_choice_in_header = re.sub(r".*?(선택지:|행동:|어떻게 할까?:|다음 중 선택하세요:)\s*", "", stripped_line, flags=re.IGNORECASE).strip()
            if potential_choice_in_header:
                match_in_header = choice_pattern.match(potential_choice_in_header)
                if match_in_header:
                    choice_text = match_in_header.group(1).strip()
                    if choice_text.lower().startswith("선택지:"): choice_text = choice_text[len("선택지:"):].strip()
                    if choice_text : choices.append(choice_text)
            continue
        if in_choices_section:
            match = choice_pattern.match(stripped_line)
            if match:
                choice_text = match.group(1).strip()
                if choice_text.lower().startswith("선택지:"): choice_text = choice_text[len("선택지:"):].strip()
                if choice_text : choices.append(choice_text)
            elif not choice_pattern.match(stripped_line) and stripped_line and choices:
                 if not any(stripped_line.startswith(kw) for kw in ["[", "]", "---", "##", "*"]): pass
        elif not in_choices_section:
            match = choice_pattern.match(stripped_line)
            if match:
                choice_text = match.group(1).strip()
                if choice_text.lower().startswith("선택지:"): choice_text = choice_text[len("선택지:"):].strip()
                if choice_text : choices.append(choice_text)
                in_choices_section = True
    return choices

def generate_system_situation(
    full_story_context: str,       # ★ 전체 원작 내용 (world_context 대신 사용)
    current_timeline_info: str,    # ★ 현재 상호작용 시점 정보 (신규 인자)
    my_profile: str,
    my_role: str,
    diaglist: List[Dict[str, str]] # 현재까지의 대화 목록
) -> Optional[Dict[str, Any]]:
    if not openai_client:
        print("Warning: OpenAI client not available for system situation.")
        return None
    if not full_story_context:
        print("Warning: Full story context is needed for generating a system situation.")
        return None
    if not current_timeline_info:
        print("Warning: Current timeline information is needed for generating a system situation.")
        return None
    profile_for_situation = my_profile
    if my_role.strip(): profile_for_situation += f"\n\n현재 '나'의 역할: {my_role}"
    recent_dialogue_str = "\n".join([f"{msg['role']}: {msg['content']}" for msg in diaglist[-6:]]) if diaglist else "없음"
    context_summary = full_story_context if len(full_story_context) < 800 else full_story_context[:400] + "..." + full_story_context[-400:]
    prompt_content = (
        "당신은 창의적인 웹소설 스토리텔러 AI입니다. "
        "제공된 현재까지의 줄거리, 주인공(사용자)의 프로필 및 역할, 그리고 최근 대화 내용을 바탕으로, "
        "주인공(사용자)에게 다음에 일어날 법한 흥미롭거나 긴장감 넘치는 '돌발 상황'을 생성해주세요. 상황 설명은 2-3문장으로 나누어 줄바꿈(\n\n)을 포함하여 가독성을 높여주세요.\n"
        "이 상황은 현재 줄거리에서 가장 최근에 언급된 주요 등장인물(주인공 제외)이나 사건과 직접적으로 관련되어야 합니다.\n"
        "그리고 그 상황에 대한 주인공(사용자)의 행동 선택지를 2~3가지 함께 제시해주세요. 선택지는 각기 다른 방향성을 가지며, 사용자의 역할에 어울리는 것이 좋습니다.\n"
        "출력 형식은 다음과 같습니다:\n"
        "[상황 문장 (필요시 여러 줄, 문단 사이 \n\n 사용)]\n\n"
        "선택지:\n"
        "1. [선택지 1 내용]\n"
        "2. [선택지 2 내용]\n"
        "3. [선택지 3 내용 (있을 경우)]\n\n"
        "반드시 위의 형식처럼 상황과 선택지만 간결하게 출력해야 합니다. '1. 선택지: 내용' 과 같이 '선택지:'를 반복하지 마세요. 부연 설명이나 인사말은 절대 포함하지 마세요."
    )
    situation_prompt_messages = [
        {"role": "system", "content": prompt_content},
        {"role": "user", "content": (
            f"【참고용 원작 전체 줄거리 (AI의 지식 베이스)】\n{context_summary or '제공되지 않음'}\n\n"
            f"【주인공(사용자) 프로필 및 역할】\n{profile_for_situation or '제공되지 않음'}\n\n"
            f"【최근 대화 내용】\n{recent_dialogue_str}\n\n"
            f"생성할 돌발 상황 및 선택지 (위의 형식 엄수, 현재 '{current_timeline_info}' 시점 및 최근 줄거리/등장인물 연계 필수):"
        )}
    ]
    try:
        response = openai_client.chat.completions.create(
            model=Config.GPT_MODEL, messages=situation_prompt_messages, max_tokens=300,
            temperature=0.75, n=1, stop=None
        )
        generated_text = response.choices[0].message.content.strip()
        situation_part = ""; choices_part_text = ""
        parts = re.split(r"\n\s*선택지:\s*\n", generated_text, 1, re.IGNORECASE)
        if len(parts) == 2: situation_part, choices_part_text = parts[0].strip(), parts[1].strip()
        else:
            lines = generated_text.splitlines()
            if lines:
                situation_part = lines[0].strip()
                if len(lines) > 1: choices_part_text = "\n".join(lines[1:]).strip()
        parsed_choices = extract_choices_from_text(choices_part_text)
        if situation_part and parsed_choices:
            choices_for_display = "\n".join([f"{i+1}. {choice}" for i, choice in enumerate(parsed_choices)])
            full_text_for_display = f"{situation_part}\n\n선택지:\n{choices_for_display}"
            return {"full_text": full_text_for_display, "situation_only": situation_part, "choices_list": parsed_choices}
        elif situation_part:
            return {"full_text": situation_part, "situation_only": situation_part, "choices_list": []}
        else: return None
    except Exception as e: print(f"Error generating system situation: {e}"); return None

def load_file_and_parse_episodes_revised(file_obj: Optional[Any], current_my_profile_in_box: str) -> \
Tuple[
    List[Dict[str,str]], str, gr.update, str, gr.update, float, bool, list, list, list, str,
    int, gr.update, gr.update, gr.update, gr.update, gr.update
]:
    # 초기화 값들
    initial_diaglist = []
    raw_text_content = ""
    parsed_episodes_val = []
    episode_selector_update_val = gr.update(choices=[], value=None, interactive=False)
    focused_content_val = "" # focused_episode_content_state 초기값
    chatbot_display_update_val = gr.update(value=[{"role": "assistant", "content": "파일을 먼저 업로드해주세요."}])
    setup_step_val = 0.0
    system_situation_active_val = False
    last_system_choices_val = []
    role_choices_list_val = []
    scene_choices_list_val = []
    current_timeline_info_val = "" # current_timeline_info_state 초기값
    turns_since_last_event_val = 0
    user_box_update_val = gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER, interactive=False)
    send_btn_update_val = gr.update(value=DEFAULT_SEND_BUTTON_TEXT, interactive=False)
    request_event_btn_update_val = gr.update(interactive=False)
    inject_situation_btn_update_val = gr.update(interactive=False)
    confirm_start_episode_btn_update_val = gr.update(interactive=False)

    if file_obj is None:
        gr.Warning("파일 선택 안됨.")
        return (
            parsed_episodes_val, raw_text_content, episode_selector_update_val,
            focused_content_val, chatbot_display_update_val, setup_step_val,
            system_situation_active_val, last_system_choices_val, role_choices_list_val,
            scene_choices_list_val, current_timeline_info_val, turns_since_last_event_val,
            user_box_update_val, send_btn_update_val, request_event_btn_update_val,
            inject_situation_btn_update_val, confirm_start_episode_btn_update_val
        )

    try:
        raw_text_content = Path(file_obj.name).read_text("utf-8", errors="replace")
        parsed_episodes_val = parse_episodes_from_text(raw_text_content)

        if not parsed_episodes_val:
            gr.Warning("회차 정보 파싱 실패 또는 내용 없음.")
            chatbot_display_update_val = gr.update(value=[{"role": "assistant", "content": "회차 정보 파싱 실패 또는 내용 없음."}])
            return (
                [], raw_text_content, episode_selector_update_val, # 파싱 실패 시 parsed_episodes_val은 빈 리스트
                focused_content_val, chatbot_display_update_val, setup_step_val,
                system_situation_active_val, last_system_choices_val, role_choices_list_val,
                scene_choices_list_val, current_timeline_info_val, turns_since_last_event_val,
                user_box_update_val, send_btn_update_val, request_event_btn_update_val,
                inject_situation_btn_update_val, confirm_start_episode_btn_update_val
            )

        dropdown_choices = [ep["display_title"] for ep in parsed_episodes_val]
        default_selected_display_title = parsed_episodes_val[-1]["display_title"] if dropdown_choices else None

        # 파일 로드 성공 시 UI 업데이트
        initial_diaglist.append({"role": "assistant", "content": f"파일이 로드되었습니다. 시작할 회차를 선택하고 '{CONFIRM_EPISODE_BUTTON_TEXT}' 버튼을 눌러주세요."})
        chatbot_display_update_val = gr.update(value=initial_diaglist)
        setup_step_val = 0.5 # 회차 확정 대기 상태
        user_box_update_val = gr.update(placeholder=EPISODE_CONFIRM_USER_BOX_PLACEHOLDER, interactive=False)
        send_btn_update_val = gr.update(value=DEFAULT_SEND_BUTTON_TEXT, interactive=False)
        confirm_start_episode_btn_update_val = gr.update(interactive=True) # 확정 버튼 활성화
        episode_selector_update_val = gr.update(choices=dropdown_choices, value=default_selected_display_title, interactive=True)
        request_event_btn_update_val = gr.update(interactive=False) # 다른 버튼들은 비활성화
        inject_situation_btn_update_val = gr.update(interactive=False)

        gr.Info(f"총 {len(parsed_episodes_val)}개 회차 로드 완료. 회차 선택 후 확정해주세요.")

        return (
            parsed_episodes_val, raw_text_content, episode_selector_update_val,
            focused_content_val, # 아직 확정 전이므로 빈 값
            chatbot_display_update_val,
            setup_step_val, system_situation_active_val, last_system_choices_val,
            role_choices_list_val, scene_choices_list_val,
            current_timeline_info_val, # 아직 확정 전이므로 빈 값
            turns_since_last_event_val,
            user_box_update_val, send_btn_update_val,
            request_event_btn_update_val, inject_situation_btn_update_val,
            confirm_start_episode_btn_update_val
        )

    except Exception as e:
        gr.Error(f"파일 처리 오류: {e}")
        chatbot_display_update_val = gr.update(value=[{"role": "assistant", "content": f"파일 처리 오류: {e}"}])
        return (
            [], raw_text_content, # 오류 시에도 원본 텍스트는 반환 시도
            gr.update(choices=[], value=None, interactive=False),
            "", chatbot_display_update_val,
            0.0, False, [], [], [], "", 0,
            gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER, interactive=False),
            gr.update(value=DEFAULT_SEND_BUTTON_TEXT, interactive=False),
            gr.update(interactive=False), gr.update(interactive=False),
            gr.update(interactive=False)
        )



def update_context_on_episode_change(selected_episode_display_title: str, parsed_episodes_list: List[Dict[str, str]]) -> str:
    if not selected_episode_display_title: return ""
    new_cumulative_context = get_cumulative_content(selected_episode_display_title, parsed_episodes_list)
    gr.Info(f"컨텍스트가 '{selected_episode_display_title}'로 변경됨."); return new_cumulative_context

def call_gpt(
    diaglist: List[Dict[str, str]],
    full_story_context: str,       # ★ 신규: 원작 전체 내용 (AI의 지식 베이스)
    current_timeline_info: str,    # ★ 신규: 예: "현재 15화 시점에서 이야기 진행 중"
    my_profile: str,
    my_role: str,
    user_selected_action: Optional[str] = None
    ) -> str:
    if not openai_client: return "오류: OpenAI API 클라이언트 없음."
    my_name_from_profile = my_profile.splitlines()[0].replace('이름: ', '').strip() if my_profile and '이름:' in my_profile.splitlines()[0] else DEFAULT_MY_PROFILE_NAME

    full_sys_parts = [
        f"당신은 지금부터 웹소설의 AI 캐릭터 또는 나레이터입니다. 사용자는 '{my_name_from_profile}'(이)라는 이름으로 이 이야기에 참여하며, 그(녀)의 프로필은 다음과 같습니다:",
        f"【'나'({my_name_from_profile})의 프로필】\n{my_profile.strip() or '제공되지 않음. 사용자의 말과 행동으로 유추하세요.'}\n"
    ]
    if my_role.strip():
        full_sys_parts.append(f"또한, '나'({my_name_from_profile})는 이 이야기에서 '{my_role}' 역할을 맡고 있습니다.")
    # AI의 지식 범위와 현재 상호작용 시점에 대한 명확한 지침 추가
    full_sys_parts.append(
        f"\n**매우 중요한 배경 정보:** 당신은 다음 '【참고용 원작 전체 줄거리 (AI의 지식 베이스)】'에 제공될 전체 원작 내용을 모두 알고 있으며, 이것이 이야기의 원래 역사입니다. 이 전체 내용을 바탕으로 세계관의 일관성을 유지해야 합니다."
    )
    full_sys_parts.append(
        f"**현재 상호작용 시점:** 사용자는 현재 '{current_timeline_info}'을 기준으로 이야기를 진행하고 있습니다. 당신의 모든 반응, 묘사, 그리고 다른 등장인물의 행동은 이 특정 시점을 기준으로 이루어져야 합니다."
    )

    full_sys_parts.extend([
        f"\n당신은 '나'(사용자, 이름: {my_name_from_profile})와 대화하고 상호작용하는 소설 속 AI 캐릭터 또는 나레이터입니다. 사용자의 프로필과 역할을 참고하여 자연스럽게 대화하세요.",
        "답변은 너무 길지 않게, 2-4문장 정도로 간결하지만 핵심을 담아 답해주세요.",
        "캐릭터와 세계관의 일관성 있는 말투와 행동을 유지하세요.",

        f"\n**매우 중요 - 사용자 캐릭터 행동 제어 지침:** 당신은 AI 캐릭터 또는 나레이터이며, 사용자 '{my_name_from_profile}'의 대사, 생각, 또는 행동을 1인칭 시점으로 직접 생성해서는 안 됩니다. '{my_name_from_profile}'의 다음 행동이나 말은 반드시 사용자의 실제 입력에 따라야 합니다.",

        f"\n**AI 역할 및 응답 방식 상세 지침:**",
        f"1. 당신의 역할은 현재 상황에 대한 반응, 다른 등장인물의 행동이나 대사 전달, 또는 주변 환경 및 분위기 묘사에 집중하는 것입니다.",
        f"2. 다른 등장인물이 말을 하는 장면을 묘사할 경우, 그 캐릭터의 **구체적인 대사 전체를 큰따옴표(\" \")로 감싸서 명확하게 포함**시켜야 합니다. '말을 걸었다'와 같이 대사를 생략하고 상황만 언급해서는 안 됩니다.",
        f"3. 사용자 '{my_name_from_profile}'의 다음 행동을 유도할 때는, 직접적인 질문('어떻게 하시겠습니까?')보다는 상황 설명을 통해 자연스럽게 사용자가 다음 행동을 떠올리게 하거나, 다른 캐릭터의 말이나 행동을 통해 사용자에게 명확한 과제나 선택지를 제시해야 합니다. 사용자가 이야기에 계속해서 능동적으로 참여하도록 이끌어주세요.",

        f"\n**IF 스토리 및 일관성 유지 지침:**",
        f"1. 사용자의 선택으로 인해 이야기가 원작과 다른 방향(IF 스토리)으로 흘러갈 수 있습니다. 이 경우, 현재 상호작용 시점({current_timeline_info}) 이후의 원작 내용은 '원래 일어났을 수도 있는 역사'로 참고만 하세요.",
        f"2. 하지만, IF 스토리를 전개하더라도 당신이 알고 있는 **원작 전체의 핵심 설정, 세계관의 규칙, 캐릭터의 근본적인 성격 및 주요 동기에는 최대한 충돌하지 않도록 주의**하며 새로운 이야기를 만들어가야 합니다. 이를 통해 이야기의 논리적인 개연성을 확보해주세요.",
        f"3. 원작의 미래 내용을 사용자에게 직접적으로 스포일러하지 마세요. 단, IF 스토리 전개에 따라 기존 설정이 자연스럽게 다르게 활용되거나 그 결과가 암시되는 것은 허용됩니다.",

        "\n가끔 *~~~* 와 같은 나레이션(AI 캐릭터 자신의 행동/묘사 또는 주변 상황 묘사, 또는 사용자 캐릭터의 행동에 대한 3인칭 묘사)을 사용해도 좋습니다. (예: *이로운은 잠시 생각에 잠겼다.*)"
    ])

    # ... (이하 로직은 webnovel_chat_app_v8과 동일) ...
    is_reacting_to_system_situation = False
    if diaglist and diaglist[-1]["role"] == "assistant" and diaglist[-1]["content"].startswith(SYSTEM_SITUATION_PREFIX):
      is_reacting_to_system_situation = True

    if user_selected_action: # 사용자가 시스템 상황에 대한 '선택지'를 골랐을 때
        full_sys_parts.append(
            f"\n**[매우 중요! 사용자의 선택 '{user_selected_action}'에 따른 장면 전개!]**\n" # 사용자 선택 명시
            f"AI(당신)는 이전에 시스템이 생성한 특정 상황과 그에 따른 선택지들을 사용자 '{my_name_from_profile}'에게 제시했습니다. "
            f"사용자는 그 선택지들 중에서 **'{user_selected_action}'** 행동을 선택했습니다. "
            f"이 선택은 이미 채팅 기록에 '{USER_CHOICE_ACTION_PREFIX}{user_selected_action}'과 같이 사용자 메시지로 표시되어 사용자가 인지하고 있습니다.\n"
            f"**당신의 역할은 이제 사용자의 선택 '{user_selected_action}'이 어떤 직접적인 결과로 이어지는지, 그로 인해 발생하는 새로운 상황, 또는 관련된 다른 캐릭터의 반응을 구체적으로 묘사하는 것입니다.** "
            f"당신은 이전 대화의 맥락을 참고할 수 있지만, **절대로 당신이 이전에 제시했던 시스템 상황 설명이나 그 이전의 일반 대화 내용을 그대로 반복해서는 안 됩니다.** "
            f"사용자의 '{user_selected_action}' 선택을 이야기의 새로운 분기점으로 삼아, 다음 장면을 창의적이고 흥미롭게 전개해주십시오. 당신의 이번 응답은 이 선택에 대한 첫 번째 반응이자 새로운 이야기의 시작이 되어야 합니다. "
            f"이전 대화의 주요 등장인물, 장소, 사건 등을 기억하고 있다면, 그것이 사용자의 현재 선택과 어떻게 자연스럽게 이어지는지 보여주는 것이 좋습니다." # 맥락 유지 지침 추가
        )
    elif diaglist and diaglist[-1].get("role") == "user" and diaglist[-1].get("content", "").startswith(USER_SITUATION_PREFIX): # 사용자가 직접 상황을 제시했을 때
        actual_situation_content = diaglist[-1]["content"][len(USER_SITUATION_PREFIX):].strip()
        full_sys_parts.append(f"\n[중요! 새로운 상황 발생!] 사용자가 방금 채팅에 다음과 같은 상황을 제시했습니다:\n'{actual_situation_content}'\n이 상황에 대한 당신(AI 캐릭터/나레이터)의 반응이나 다음 상황을 묘사해주세요. 당신의 다음 발언은 이 상황에 대한 첫 반응이어야 합니다.")
    # 시스템 상황 제시 후 사용자가 자유 텍스트로 응답했을 때의 처리:
    # 이 경우는 user_selected_action이 None이고, diaglist의 마지막이 사용자의 자유 입력이므로,
    # 아래 messages_to_send 구성 시 해당 사용자 입력이 포함되어 LLM이 자연스럽게 반응하게 됩니다.
    # is_reacting_to_system_situation 플래그는 이전에 시스템 상황이 제시되었음을 나타낼 수 있으나,
    # 시스템 프롬프트에 명시적으로 "사용자가 자유 행동을 했다"고 넣는 것보다,
    # 대화 목록에 있는 사용자 자유 행동에 AI가 직접 반응하도록 하는 것이 더 자연스러울 수 있습니다.
    # (만약 필요하다면, 이전에 추가했던 "제시된 상황 및 사용자 행동 참고" 프롬프트를 다시 고려할 수 있습니다.)

    sys_prompt = " ".join(full_sys_parts)

    # AI에게 전달되는 원작 줄거리는 전체 내용을 포함해야 함.
    # 토큰 제한을 고려하여 full_story_context의 일부 또는 요약본을 전달할 수 있음.
    # 현재는 최대 15만자로 제한하는 예시를 사용. (실제 토큰 수와 다를 수 있음)
    context_for_llm_display = ""
    if full_story_context.strip():
        # LLM에 전달할 컨텍스트 길이 제한 (예: 최근 내용 또는 중요도 기반 요약)
        # 여기서는 간단히 최근 내용을 중심으로 전달하거나, 전체를 전달하되 LLM API 자체의 입력 한계를 고려해야 함.
        # 이전 아이디어인 "지능형 요약기"를 통해 생성된 요약본을 full_story_context로 전달받는 것이 이상적.
        # 여기서는 full_story_context가 이미 적절한 길이로 준비되었다고 가정하거나, 일부만 사용.
        max_chars_for_llm_context = 100000 # 예시: 최대 10만자
        context_for_llm_display = full_story_context
        if len(full_story_context) > max_chars_for_llm_context:
            print(f"Warning: full_story_context is very long ({len(full_story_context)} chars). Truncating for call_gpt system prompt.")
            # 단순 뒷부분 자르기보다는, 앞/뒤 또는 핵심 요약 등 전략 필요. 여기서는 단순 자르기 예시.
            context_for_llm_display = full_story_context[-max_chars_for_llm_context:]

        sys_prompt += f"\n\n【참고용 원작 전체 줄거리 (AI의 지식 베이스)】\n{context_for_llm_display}"
        if len(full_story_context) > max_chars_for_llm_context:
             sys_prompt += "\n...(원작 줄거리 일부 생략)..."

    messages_to_send = [{"role": "system", "content": sys_prompt}]
    # API로 보낼 메시지 목록 필터링 (초기 설정 및 시스템 안내 메시지, 사용자 선택 확인 메시지 제외)
    for msg in diaglist:
        content = msg.get("content", "")
        role = msg.get("role", "user")
        # 사용자가 선택한 역할/장면/행동에 대한 확인 메시지는 제외
        is_user_choice_confirmation = role == "user" and \
                                     (content.startswith(USER_CHOICE_ROLE_PREFIX) or \
                                      content.startswith(USER_CHOICE_SCENE_PREFIX) or \
                                      content.startswith(USER_CHOICE_ACTION_PREFIX))

        # AI가 제시한 초기 설정 메시지들도 제외
        is_system_setup_message = role == "assistant" and \
                                  (content.startswith(STORY_BRIEFING_PREFIX) or \
                                   content.startswith(MY_ROLE_CHOICE_PREFIX) or \
                                   content.startswith(SCENE_ENTRY_CHOICE_PREFIX) or \
                                   content.startswith(SYSTEM_SITUATION_PREFIX)) # 시스템 상황 제시는 API에 안 보냄 (프롬프트로 처리)

        if not (is_system_setup_message or is_user_choice_confirmation):
            messages_to_send.append(msg)

    # 만약 messages_to_send에 시스템 프롬프트 외 아무것도 없다면 (모든게 필터링 되었다면)
    # 그리고 user_selected_action도 없다면 (즉, AI가 반응할 사용자 입력이 없다면) 경고
    if len(messages_to_send) == 1 and not user_selected_action:
        # 이 조건은 AI가 스스로 말을 계속 만들어내는 것을 방지하기 위함
        # 단, 시스템 상황 제시 후 사용자가 '선택지'가 아닌 '자유행동'을 했을 경우,
        # 그 자유행동은 messages_to_send에 포함되어야 함. 위 필터링 로직에서 USER_CHOICE_ACTION_PREFIX 등은 제외됨.
        # 사용자의 순수 대화나 USER_SITUATION_PREFIX가 붙은 입력은 messages_to_send에 포함됨.
        pass # 특별히 경고할 필요 없을 수도 있음. 프롬프트가 잘 설계되었다면.

    return llm.chat(messages_to_send, max_tokens=350, temperature=0.72)


# ... (이하 user_turn 부터 handle_request_system_situation 까지의 함수들은 이전과 동일)
def user_turn(user_input: str, diaglist: List[Dict[str, str]]) -> Tuple[str, List[Dict[str, str]]]:
    if user_input.strip(): diaglist.append({"role": "user", "content": user_input})
    return "", diaglist

def assistant_turn(
    diaglist: List[Dict[str, str]],
    full_story_context: str,       # ★ 신규
    current_timeline_info: str,    # ★ 신규
    my_profile: str,
    my_role: str,
    user_selected_action: Optional[str] = None) -> str:
    if not diaglist and not my_role: return "먼저 파일 로드 후 초기 설정을 완료해주세요."
    should_respond = bool(user_selected_action or (diaglist and diaglist[-1]["role"] == "user"))
    if not should_respond: return ""
    return call_gpt(diaglist, full_story_context, current_timeline_info, my_profile, my_role, user_selected_action)


def generate_image_button_callback(diaglist: List[Dict[str, str]], current_my_profile: str) -> Optional[Image.Image]: # img_gen은 전역 객체로 가정
    if not diaglist:
        gr.Warning("대화 내용이 없어 이미지를 생성할 수 없습니다.")
        return None

    scene_dialogue_segment = []
    last_scene_choice_msg_idx = -1
    # 사용자의 마지막 장면 선택 메시지 인덱스 찾기
    for i in range(len(diaglist) - 1, -1, -1):
        msg = diaglist[i]
        if msg.get("role") == "user" and msg.get("content", "").startswith(USER_CHOICE_SCENE_PREFIX):
            last_scene_choice_msg_idx = i
            break

    if last_scene_choice_msg_idx != -1:
        # 장면 선택 메시지 *다음* 메시지부터가 실제 장면의 시작 (AI의 장면 시작 묘사부터 포함)
        if last_scene_choice_msg_idx + 1 < len(diaglist):
            scene_dialogue_segment = diaglist[last_scene_choice_msg_idx + 1:]
            print(f"DEBUG: generate_image_button_callback: Scene dialogue segment identified with {len(scene_dialogue_segment)} messages.")
        else:
            gr.Warning("현재 장면에 아직 내용이 없습니다 (AI의 장면 시작 메시지가 없음).")
            print("DEBUG: generate_image_button_callback: Scene choice confirmed, but no subsequent AI message to start the scene found.")
            return None
    else:
        # 장면 선택이 아직 없으면, 최근 대화 몇 개를 기반으로 생성 시도 (롤백된 로직과 유사하게)
        # 또는 이미지 생성 버튼을 비활성화하는 것이 더 나은 UX일 수 있음
        gr.Warning("현재 진행 중인 장면이 없습니다. 최근 대화를 기반으로 이미지를 생성하거나, 장면 선택 후 다시 시도해주세요.")
        # 이 경우, 최근 N개 메시지를 scene_dialogue_segment로 사용하거나, 이전 로직대로 마지막 사용자/AI 메시지 추출
        # 여기서는 요청에 따라 "장면 선택 이후"를 강조하므로, 장면이 없으면 생성하지 않도록 함.
        return None

    if not scene_dialogue_segment:
        gr.Warning("현재 장면에 분석할 대화 내용이 없습니다.")
        print("DEBUG: generate_image_button_callback: Scene dialogue segment is empty after identification attempt.")
        return None

    # 전체 장면 대화 세그먼트를 프롬프트 생성 함수에 전달
    image_prompt = call_minimax_for_image_prompt(scene_dialogue_segment, current_my_profile)

    if not image_prompt or "오류:" in image_prompt:
        gr.Error(f"이미지 프롬프트 생성 실패: {image_prompt}")
        return None

    gr.Info(f"생성된 이미지 프롬프트: {image_prompt}")
    return img_gen.generate(image_prompt) # img_gen은 전역에 선언된 ImageGenerator 인스턴스


def call_minimax_for_image_prompt(dialogue_segment: List[Dict[str, str]], current_my_profile: str) -> str:
    print(f"DEBUG: call_minimax_for_image_prompt received dialogue_segment with {len(dialogue_segment)} messages.")

    my_name = DEFAULT_MY_PROFILE_NAME
    if current_my_profile:
        try:
            # 프로필에서 "이름: " 형식으로 이름 추출 시도
            name_lines = [line for line in current_my_profile.splitlines() if line.startswith("이름:")]
            if name_lines:
                my_name = name_lines[0].replace("이름:", "").strip()
        except Exception:
            pass # 이름 추출 실패 시 기본값 사용

    descriptive_parts = []

    if not dialogue_segment:
        return f"Illustration of a character named {my_name} in a webnovel scene. Detailed, vivid colors, cinematic lighting, digital art."

    # 1. 장면 시작 묘사 (세그먼트의 첫 번째 AI 메시지)
    if dialogue_segment[0].get("role") == "assistant":
        content = dialogue_segment[0].get("content", "")
        # 알려진 시스템/UI용 접두어들 (이미지 프롬프트에는 불필요)
        # SCENE_START_PREFIX는 이미 제거되었지만, 혹시 유사한 패턴이 있다면 여기서 처리
        prefixes_to_clean = [SCENE_ENTRY_CHOICE_PREFIX, MY_ROLE_CHOICE_PREFIX, STORY_BRIEFING_PREFIX, SYSTEM_SITUATION_PREFIX]
        cleaned_content = content
        for prefix in prefixes_to_clean:
            if cleaned_content.startswith(prefix):
                cleaned_content = cleaned_content[len(prefix):].strip()

        narration_match = re.search(r"\*(.*?)\*", cleaned_content) # 나레이션 우선
        if narration_match:
            descriptive_parts.append(narration_match.group(1).strip()[:200])
        else:
            # 직접적인 대화 따옴표 제거 시도 (묘사 위주로)
            text_without_direct_speech = re.sub(r"“.*?”", "", cleaned_content).strip()
            text_without_direct_speech = re.sub(r'".*?"', "", text_without_direct_speech).strip()
            if text_without_direct_speech.strip(): # 묘사 부분이 있다면 사용
                descriptive_parts.append(text_without_direct_speech[:200])
            else: # 묘사 부분이 없다면 (대화 위주일 경우) 전체 내용 일부 사용
                descriptive_parts.append(cleaned_content.strip()[:200])

    # 2. 최근 상호작용 (세그먼트의 마지막 1~2개 메시지, 단, 첫 메시지와 중복되지 않도록)
    # (더 정교한 요약을 위해서는 실제 LLM 호출 필요)
    if len(dialogue_segment) > 1:
        # 마지막 2개 메시지 (최대)
        recent_messages = dialogue_segment[-2:] if len(dialogue_segment) > 2 else dialogue_segment[-1:]

        for msg in recent_messages:
            # 첫 번째 메시지와 동일하다면 건너뛰기 (중복 방지)
            if msg == dialogue_segment[0] and len(dialogue_segment) > 1 : # 첫 메시지이면서, 메시지가 여러개일때만 스킵
                continue

            content = msg.get("content", "")
            role = msg.get("role")
            cleaned_content = content

            # 사용자 선택지 확인용 접두어 등 제거
            choice_prefixes = [USER_CHOICE_ROLE_PREFIX, USER_CHOICE_SCENE_PREFIX, USER_CHOICE_ACTION_PREFIX, USER_SITUATION_PREFIX]
            for prefix in choice_prefixes:
                if cleaned_content.startswith(prefix):
                    cleaned_content = cleaned_content[len(prefix):].strip()

            if not cleaned_content.strip():
                continue

            text_to_add = ""
            if role == "user":
                text_to_add = f"{my_name}'s action or dialogue: {cleaned_content[:80]}"
            elif role == "assistant":
                narration_match = re.search(r"\*(.*?)\*", cleaned_content)
                if narration_match:
                    text_to_add = f"Narrative continuation: {narration_match.group(1).strip()[:120]}"
                else:
                    text_to_add = f"Further dialogue or events: {cleaned_content.strip()[:120]}"

            if text_to_add and not any(text_to_add in part for part in descriptive_parts): # 중복 내용 방지 (단순 체크)
                 descriptive_parts.append(text_to_add)

    scene_summary_for_prompt = ". ".join(filter(None, descriptive_parts))

    if not scene_summary_for_prompt:
        scene_summary_for_prompt = f"A scene in a webnovel involving character {my_name}."

    final_prompt = f"Illustrate a webnovel scene: {scene_summary_for_prompt}. Style: detailed digital art, cinematic lighting, vivid colors, (fantasy or modern setting depending on context)."

    max_prompt_length = 400
    if len(final_prompt) > max_prompt_length:
        # 뒤에서부터 단어 단위로 자르기 시도
        trimmed_prompt = final_prompt[:max_prompt_length]
        last_space = trimmed_prompt.rfind(' ')
        if last_space != -1:
            final_prompt = trimmed_prompt[:last_space]
        else:
            final_prompt = trimmed_prompt

    print(f"Generated Image Prompt (Summarized Scene Segment): {final_prompt}")
    return final_prompt.strip()

def generate_context_aware_world_summary_with_claude(
    full_world_context: str,
    current_dialogue_str: str, # 현재 대화 흐름 (문자열)
    my_profile_str: str,
    my_role_str: str,
    target_summary_max_output_tokens: int = 4000 # Claude가 생성할 요약문의 최대 토큰
) -> str:
    if not Config.ANTHROPIC_API_KEY:
        print("Error: Anthropic API key not set for summarization. Returning a slice of world_context.")
        # API 키가 없을 경우, 원본 컨텍스트의 일부를 반환하거나 간단한 메시지 반환
        return full_world_context[-(target_summary_max_output_tokens * 3):] if full_world_context else "원작 요약 정보를 생성하지 못했습니다 (API 키 없음)."

    anthropic_client = anthropic.Anthropic(api_key=Config.ANTHROPIC_API_KEY)

    # Claude에 전달할 원작 컨텍스트의 양 조절 (Claude의 입력 토큰 한계 고려)
    # 예: Claude 3 Sonnet은 200k 토큰 입력 가능. 프롬프트의 다른 부분도 고려해야 함.
    # 여기서는 full_world_context가 매우 길 경우를 대비해 일부만 사용 (예: 최근 10만자)
    # 실제로는 더 정교한 청킹 또는 사전 요약 전략이 필요할 수 있음.
    chars_limit_for_claude_input_context = 100000
    context_to_summarize_for_claude = full_world_context
    if len(full_world_context) > chars_limit_for_claude_input_context:
        print(f"Warning: full_world_context for summarizer is very long ({len(full_world_context)} chars). Truncating to last {chars_limit_for_claude_input_context} chars for summarizer input to Claude.")
        context_to_summarize_for_claude = full_world_context[-chars_limit_for_claude_input_context:]

    user_char_name = my_profile_str.splitlines()[0].replace('이름: ', '').strip() if my_profile_str and '이름:' in my_profile_str.splitlines()[0] else DEFAULT_MY_PROFILE_NAME

    system_prompt_for_summarizer = f"""
당신은 고도로 숙련된 스토리 분석가이자 요약 전문가입니다. 당신의 임무는 제공된 '원작 소설 내용' 중에서, 현재 진행 중인 '사용자와 AI 간의 대화 내용' 및 '사용자 캐릭터 정보'를 바탕으로 다음 이야기를 창작(예: 소설의 다음 편 또는 팬픽)하는 데 직접적으로 필요하고 가장 관련성이 높은 핵심 정보만을 추출하여 요약하는 것입니다.
요약은 매우 간결해야 하며, 생성될 요약문의 최대 토큰 수({target_summary_max_output_tokens}) 제한을 고려하여 핵심 내용 위주로 작성해야 합니다.
불필요한 세부 사항이나 현재 대화와 동떨어진 과거 내용은 과감히 생략하고, 핵심적인 맥락과 캐릭터 동기, 주요 사건 위주로 정리해주세요.
요약은 한국어로 작성해주세요.
"""
    user_message_for_summarizer = f"""
[사용자 캐릭터 정보 ('나')]
이름: {user_char_name}
{my_profile_str}
역할: {my_role_str}

[현재까지의 대화 내용 요약 (이 대화의 다음 장면을 만드는데 참고)]
{current_dialogue_str[:3000]}... (최근 대화 일부만 제공하여 요약 LLM의 입력 토큰 관리)

[요약 대상 원작 소설 내용]
{context_to_summarize_for_claude}

[요약 요청 지침]
1. 현재 대화의 직접적인 연속성을 위해 필수적인 배경 정보 (세계관의 중요한 규칙, 현재 장소의 특징 등)를 포함해주세요.
2. 현재 대화에 참여 중이거나, 앞으로의 전개에 중요하게 작용할 것으로 예상되는 주요 등장인물들의 현재 상태, 심리, 서로 간의 관계, 최근의 중요한 행동을 요약해주세요. (특히 사용자 캐릭터 '{user_char_name}'와 관련된 인물 중심)
3. 현재 대화의 맥락으로 직접 이어지는 원작 소설의 최근 주요 사건 전개를 중심으로 요약해주세요.
4. 다음 이야기 전개에 영향을 줄 수 있는 미해결 복선, 중요한 아이템, 능력, 또는 숨겨진 비밀이 원작에 있다면 간략히 언급해주세요.
5. 전체 요약 결과는 다음 이야기 생성에 바로 사용될 것이므로, 서술형으로 자연스럽게 작성해주세요.

위 지침에 따라, 다음 이야기 창작에 필요한 핵심 원작 컨텍스트를 요약해주세요 (최대 {target_summary_max_output_tokens} 토큰 분량으로):
"""
    try:
        response = anthropic_client.messages.create(
            model="claude-sonnet-4-20250514", # 또는 Haiku (더 빠르고 저렴), Opus (더 고성능)
            max_tokens=target_summary_max_output_tokens,
            system=system_prompt_for_summarizer,
            messages=[{"role": "user", "content": user_message_for_summarizer}],
            temperature=0.3
        )
        summary = response.content[0].text.strip()
        if summary:
            print(f"DEBUG: Claude context-aware summary generated (length {len(summary)} chars):\n{summary[:300]}...")
            return summary
        else:
            print("DEBUG: Claude context-aware summary generation failed or returned empty. Falling back.")
            return full_world_context[-(target_summary_max_output_tokens * 3):] if full_world_context else "원작 요약 정보를 생성하지 못했습니다."
    except Exception as e:
        print(f"Error in Claude generate_context_aware_world_summary: {e}")
        if hasattr(e, 'response') and hasattr(e.response, 'text'): print(f"Claude API 상세 오류: {e.response.text}")
        return full_world_context[-(target_summary_max_output_tokens * 3):] if full_world_context else "원작 요약 중 오류 발생."


def convert_chat_to_novel_text(
    diaglist: List[Dict[str, str]],
    current_my_profile: str,
    my_role: str,
    style_content: str,
    world_context: str # 전체 원작 컨텍스트
    # summarizer_llm_agent 인자는 Claude를 직접 사용하므로 제거됨
) -> str:
    if not diaglist: return "변환할 대화 없음."

    # 1. 현재 대화 내용 등을 문자열로 변환 (요약 LLM에 전달하기 위해)
    cleaned_diaglist = []
    for t in diaglist: # cleaned_diaglist 만드는 로직
        content, role = t.get("content",""), t.get("role", "user")
        # 초기 설정 및 사용자 선택 관련 메시지는 소설 변환에서 제외
        if content.startswith(STORY_BRIEFING_PREFIX) or \
           content.startswith(MY_ROLE_CHOICE_PREFIX) or \
           content.startswith(SCENE_ENTRY_CHOICE_PREFIX) or \
           content.startswith(USER_CHOICE_ROLE_PREFIX) or \
           content.startswith(USER_CHOICE_SCENE_PREFIX) or \
           content.startswith(USER_CHOICE_ACTION_PREFIX):
            continue

        if role == "user" and content.startswith(USER_SITUATION_PREFIX):
            cleaned_diaglist.append({"role": "system", "content": f"('나'(사용자)가 다음 상황을 제시함: {content[len(USER_SITUATION_PREFIX):]})"})
        elif role == "assistant" and content.startswith(SYSTEM_SITUATION_PREFIX):
            cleaned_diaglist.append({"role": "system", "content": f"(시스템이 다음 상황과 선택지를 제시함: {content[len(SYSTEM_SITUATION_PREFIX):]})"})
        else:
            cleaned_diaglist.append(t)

    if not cleaned_diaglist: return "실질적 대화 없어 변환 불가."
    current_dialogue_str_for_summary = "\n".join([f"{t.get('role')}: {t.get('content')}" for t in cleaned_diaglist[-10:]]) # 최근 N개 대화만 요약기에 전달


    # 2. Claude를 사용하여 지능형 원작 컨텍스트 요약 생성
    target_summary_tokens_for_anthropic_input = 8000

    print("DEBUG: Generating context-aware summary for novel conversion using Claude...")
    # generate_context_aware_world_summary_with_claude 함수는 이 함수 외부에 정의되어 있다고 가정
    summarized_world_context = generate_context_aware_world_summary_with_claude(
        world_context,
        current_dialogue_str_for_summary,
        current_my_profile,
        my_role,
        target_summary_tokens_for_anthropic_input
    )

    # 3. Anthropic API(소설 변환용)에 전달할 최종 프롬프트 구성
    transcript_parts = []
    my_name = current_my_profile.splitlines()[0].replace('이름: ', '').strip() if current_my_profile and '이름:' in current_my_profile.splitlines()[0] else DEFAULT_MY_PROFILE_NAME
    for t in cleaned_diaglist:
        role_map = {"user": f"'{my_name}'(나)", "assistant": "AI 캐릭터", "system": "시스템 서술"}
        prefix = role_map.get(t['role'], "")
        current_content = t['content']
        transcript_parts.append(f"{prefix}: {current_content}" if prefix else current_content)
    transcript = "\n".join(transcript_parts)

    sys_prompt_parts = [
        f"당신은 뛰어난 웹소설 작가입니다. 당신의 **주요 임무**는 제공된 '【소설로 변환할 최근 대화 기록】'을 바탕으로, '나({my_name})'를 중심으로 한 몰입감 있는 소설 장면을 창조하는 것입니다. 함께 제공되는 '【참고용 배경 세계관 및 이전 스토리 요약】'은 이 장면에 대한 배경 이해와 세계관 일관성 유지를 위한 **참고 자료**로만 활용해주십시오.",

        "**목표:** '최근 대화 기록'에 나타난 각 인물의 대사, 행동, 감정, 그리고 주변 상황을 소설적인 문체로 풍부하게 풀어내어, '나'의 시점이나 '나'를 중심으로 한 3인칭 관찰자 시점으로 생생하게 재구성해야 합니다.",

        "**세부 지시사항:**",
        "1.  **주요 작업 - 대화의 소설화:** 제공된 '【소설로 변환할 최근 대화 기록】'의 내용을 시작부터 끝까지 충실히 반영하여 하나의 완성된 소설 장면으로 변환해주세요. 대화 내용을 단순히 나열하는 것이 아니라, 각 대사가 나오게 된 상황, 인물의 표정, 몸짓, 내면 심리, 그리고 주변 환경 묘사를 풍부하게 추가해야 합니다.",
        "2.  **원작 컨텍스트의 올바른 활용:** '【참고용 배경 세계관 및 이전 스토리 요약】'의 내용은 현재 작성 중인 장면에 깊이를 더하거나, 캐릭터의 행동/동기, 세계관 설정을 일관되게 유지하는 데 필요한 경우에만 참고하여 자연스럽게 녹여내세요. **원작 요약본의 내용이 '최근 대화 기록'의 흐름을 방해하거나, 특히 주인공 '{my_name}'의 이름을 포함한 등장인물의 이름을 잘못 사용하게 만드는 일이 없도록 매우 주의해야 합니다.**",
        f"3.  **주인공 '{my_name}' 중심 서사 및 이름 절대 정확성:** 이야기는 항상 '나({my_name})'를 중심으로 전개되어야 하며, **주인공의 이름은 반드시 프로필에 명시된 '{my_name}'(으)로 일관되게 사용해야 합니다. 다른 어떤 이름으로도 절대 변경하거나 혼동해서는 안 됩니다.**",
        "4.  **캐릭터 일관성:** '【'나'({my_name}) 프로필】'과 '【'나'({my_name})의 역할】'에 명시된 주인공의 성격, 말투, 능력, 배경 등을 충실히 반영하여 캐릭터의 일관성을 유지해주세요.",
        "5.  **문체 참고 (선택 사항):** '【문체 예시】'가 있다면 해당 스타일(리듬, 어휘, 묘사)을 분석하여 유사하게 작성하고, 없다면 현대적이고 흡입력 있는 웹소설 스타일로 작성해주세요.",
        "6.  **분량:** 생성되는 소설 장면은 '최근 대화 기록'의 내용을 충분히 담아내되, 너무 길어지지 않도록 핵심 내용 중심으로 구성해주세요. (약 500-1500자 사이를 권장합니다.)",
        "7.  **장면 마무리 (선택 사항):** '최근 대화 기록'을 소설 장면으로 모두 변환한 후, 그 장면의 분위기를 정리하는 짧은 묘사나 등장인물의 다음 행동을 암시하는 한두 문장으로 자연스럽게 마무리할 수 있습니다. 이는 필수 사항이 아니며, 주된 목표는 대화 기록의 충실한 소설화입니다.",
        "8.  **형식:** 완성된 소설 텍스트만 반환해야 하며, 서론이나 부연 설명, 또는 '소설 장면:'과 같은 머리말은 제외해주세요.",

        f"\n【'나'({my_name}) 프로필】\n{current_my_profile.strip() or DEFAULT_MY_PROFILE_PLACEHOLDER}\n",
        f"\n【'나'({my_name})의 역할】\n{my_role.strip() or '정해지지 않음'}\n",
        f"【참고용 배경 세계관 및 이전 스토리 요약 (원작 줄거리 핵심 요약본)】\n{summarized_world_context.strip() or '제공되지 않음'}\n", # 역할 명시
        f"【소설화 작업의 주 대상이 되는 대화 내용 (최근 대화 기록)】\n{transcript.strip()}" # 역할 명시
    ]
    if style_content.strip():
        sys_prompt_parts.append(f"\n【문체 예시】\n{style_content.strip()}\n")

    system_prompt_for_anthropic_novel = "\n".join(sys_prompt_parts)

    # 4. Anthropic API 호출 (소설 변환)
    if not Config.ANTHROPIC_API_KEY: return "오류: Anthropic API 키 없음."
    try:
        anthropic_client_novel = anthropic.Anthropic(api_key=Config.ANTHROPIC_API_KEY) # 새 클라이언트 또는 기존 클라이언트 재사용
        response = anthropic_client_novel.messages.create(
            model="claude-sonnet-4-20250514", # 또는 Opus (더 긴 내용 생성에 유리할 수 있음)
            max_tokens=3000, # 소설 결과물의 최대 토큰 (필요에 따라 조절)
            temperature=0.3,
            messages=[{"role": "user", "content": "위 요청대로 소설 장면 작성."}],
            system=system_prompt_for_anthropic_novel
        )
        if not response.content or not response.content[0].text: return "Anthropic API 응답 없음."
        return response.content[0].text.strip()
    except Exception as e:
        print(f"Anthropic API (novel generation) 오류: {e}")
        if hasattr(e, 'response') and hasattr(e.response, 'text'): print(f"Anthropic API 상세 오류: {e.response.text}")
        return f"Anthropic API (소설 변환) 오류: {e}"

def load_style_text(input_text: str) -> str:
    if not input_text.strip(): gr.Warning("문체 예시 비어 있음."); return ""
    gr.Info("문체 예시 적용됨!"); return input_text

def toggle_profile_lock_and_save(current_profile_text_in_box: str, current_my_profile_state: str) -> Tuple[gr.update, str, str]:
    if current_my_profile_state == current_profile_text_in_box and current_my_profile_state.strip() != "":
        gr.Info("'나의 프로필'을 수정합니다. 변경 후 다시 버튼을 눌러 확정해주세요."); return gr.update(interactive=True), current_my_profile_state, "✅ 변경 내용 확정"
    else:
        if not current_profile_text_in_box.strip(): gr.Warning("'나의 프로필' 내용이 비어있습니다."); return gr.update(interactive=True, placeholder="'나의 프로필'을 상세히 입력..."), current_my_profile_state, "✅ 프로필 확정/수정"
        gr.Info("새로운 '나의 프로필'이 적용되었습니다!"); return gr.update(value=current_profile_text_in_box, interactive=False), current_profile_text_in_box, "🔄 '나의 프로필' 수정"

def clear_chat_interface(
    current_my_profile_state: str,
    current_profile_box_content: str,
    # current_ctx_state는 이제 focused_episode_content_state로 대체되거나,
    # 여기서는 파일 로드 여부 판단을 위해 parsed_episodes_state_val을 사용
    parsed_episodes_state_val: list, # 파일이 로드되었는지 (parsed_episodes_state의 현재 값)
    parsed_episodes_full_text_state_val: str # 이 값은 초기화하지 않고 유지
) -> Tuple[ # 반환 값 24개로 가정 (UI 요소 개수에 맞춰야 함)
    gr.update, gr.update, List[Dict[str,str]], str, gr.update, Optional[Image.Image],
    Any, str, str, gr.update, List[Dict[str,str]], gr.update, str, str, bool, # focused_episode_content_state, current_timeline_info_state 추가
    gr.update, bool, list, list, list, int, float, str, gr.update, gr.update, gr.update
]:
    effective_my_profile = current_my_profile_state
    if not effective_my_profile.strip() and current_profile_box_content.strip(): effective_my_profile = current_profile_box_content
    elif not effective_my_profile.strip() and not current_profile_box_content.strip(): effective_my_profile = DEFAULT_MY_PROFILE_PLACEHOLDER
    profile_box_val_on_clear = effective_my_profile
    is_profile_locked = bool(current_my_profile_state.strip() and current_my_profile_state == profile_box_val_on_clear)

    initial_diaglist = []
    initial_setup_step = 0.0
    user_box_placeholder_update = gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER, interactive=False)
    send_btn_text_update = gr.update(value=DEFAULT_SEND_BUTTON_TEXT, interactive=False)
    req_event_btn_interactive_update = gr.update(interactive=False)
    inject_sit_btn_interactive_update = gr.update(interactive=False)
    confirm_start_episode_btn_interactive_update = gr.update(interactive=False) # 기본적으로 비활성화

    initial_focused_episode_content = ""
    initial_current_timeline_info = ""
    initial_my_role = ""
    initial_focused_episode_content
    initial_current_timeline_info
    initial_role_choices_list = []
    initial_scene_choices_list = []
    initial_last_system_choices = []
    initial_turns_count = 0
    initial_system_sit_active = False
    initial_sit_injection_mode = False

    # episode_selector_ui의 상태는 파일 로드 여부에 따라 결정
    episode_selector_update = gr.update(interactive=bool(parsed_episodes_state_val))
    if not parsed_episodes_state_val: # 파일 로드 안된 상태면 드롭다운 비활성화 및 선택 없음
        episode_selector_update = gr.update(choices=[], value=None, interactive=False)


    if parsed_episodes_state_val: # 파일이 로드된 적이 있다면 (즉, parsed_episodes_state가 비어있지 않다면)
        initial_diaglist.append({"role": "assistant", "content": f"대화가 초기화되었습니다. 시작할 회차를 선택하고 '{CONFIRM_EPISODE_BUTTON_TEXT}' 버튼을 눌러주세요."})
        initial_setup_step = 0.5 # 회차 확정 대기 상태로
        user_box_placeholder_update = gr.update(placeholder=EPISODE_CONFIRM_USER_BOX_PLACEHOLDER, interactive=False) # 입력창은 비활성화
        send_btn_text_update = gr.update(interactive=False) # 전송 버튼 비활성화
        confirm_start_episode_btn_interactive_update = gr.update(interactive=True) # 확정 버튼은 활성화
    else: # 파일 로드된 적 없으면 완전 초기 상태
        initial_diaglist.append({"role": "assistant", "content": "먼저 TXT 파일을 업로드해주세요."})
        # 모든 버튼 비활성화, 플레이스홀더 기본값
        user_box_placeholder_update = gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER, interactive=False)
        send_btn_text_update = gr.update(interactive=False)
        req_event_btn_interactive_update = gr.update(interactive=False)
        inject_sit_btn_interactive_update = gr.update(interactive=False)
        confirm_start_episode_btn_interactive_update = gr.update(interactive=False)


    return (
        user_box_placeholder_update,                # 1. user_box
        gr.update(value=initial_diaglist),          # 2. chatbot_display
        initial_diaglist,                           # 3. diaglist_state
        current_my_profile_state,                   # 4. my_profile_state (유지)
        gr.update(value=profile_box_val_on_clear, interactive=not is_profile_locked), # 5. profile_box
        None,                                       # 6. gen_image_display (초기화)
        gr.update(value=None) if not parsed_episodes_state_val else file_input, # 7. file_input (파일 없으면 초기화)
        "",                                         # 8. novel_text_display
        "",                                         # 9. style_content_state
        gr.update(value=""),                        # 10. style_box
        parsed_episodes_state_val if parsed_episodes_state_val else [], # 11. parsed_episodes_state (유지 또는 초기화)
        episode_selector_update,                    # 12. episode_selector_ui
        initial_focused_episode_content,            # 13. ★ focused_episode_content_state (초기화)
        initial_current_timeline_info,              # 14. ★ current_timeline_info_state (초기화)
        initial_sit_injection_mode,                 # 15. situation_injection_mode
        send_btn_text_update,                       # 16. send_btn
        initial_system_sit_active,                  # 17. system_situation_active
        initial_last_system_choices,                # 18. last_system_choices
        initial_role_choices_list,                  # 19. role_choices_list_state
        initial_scene_choices_list,                 # 20. scene_choices_list_state
        initial_turns_count,                        # 21. turns_since_last_event
        initial_setup_step,                         # 22. initial_setup_step
        initial_my_role,                            # 23. my_role_in_story
        req_event_btn_interactive_update,           # 24. request_event_btn
        inject_sit_btn_interactive_update,          # 25. inject_situation_btn
        confirm_start_episode_btn_interactive_update # 26. ★ confirm_start_episode_btn (추가됨, 총 26개)
    )


def activate_situation_mode() -> Tuple[bool, bool, list, gr.update, gr.update]:
    gr.Info("상황 제시 모드 활성화. 상황 입력 후 '상황 전송' 클릭.");
    return True, False, [], gr.update(placeholder=SITUATION_USER_BOX_PLACEHOLDER), gr.update(value=SITUATION_SEND_BUTTON_TEXT)

def handle_request_system_situation(
    diag_list: List[Dict[str,str]],
    full_story_context_from_state: str,       # ★ 신규: 원작 전체 내용
    current_timeline_info_from_state: str,    # ★ 신규: 현재 상호작용 시점 정보
    current_my_profile_state: str,
    profile_box_content: str,
    parsed_eps: list, # 파일 로드 여부 판단용
    current_turns_count: int,
    current_my_role: str,
    current_setup_step: float # float으로 변경
) -> Tuple[gr.update, List[Dict[str,str]], bool, list, gr.update, gr.update, int]:
    final_diag_list = list(diag_list)
    new_last_choices = []; new_system_sit_active = False
    user_box_placeholder_update = gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER)
    send_btn_text_update = gr.update(value=DEFAULT_SEND_BUTTON_TEXT)
    new_turns_counter = current_turns_count

    if current_setup_step < 3: # 일반 대화 모드(3.0)가 아니면 시스템 상황 요청 불가
        gr.Warning("초기 설정(역할/장면 선택)을 먼저 완료해주세요.")
        return gr.update(value=final_diag_list), final_diag_list, new_system_sit_active, new_last_choices, user_box_placeholder_update, send_btn_text_update, new_turns_counter

    if not full_story_context_from_state or not parsed_eps: # 원작 내용이 없으면 (파일 로드 안됐으면)
        gr.Warning("먼저 원작을 로드하고 시작 회차를 확정해주세요.")
        return gr.update(value=final_diag_list), final_diag_list, new_system_sit_active, new_last_choices, user_box_placeholder_update, send_btn_text_update, new_turns_counter

    if not current_my_role:
        gr.Warning("역할이 선택되지 않았습니다. 시스템 상황을 생성하기 전에 역할을 먼저 설정해주세요.")
        return gr.update(value=final_diag_list), final_diag_list, new_system_sit_active, new_last_choices, user_box_placeholder_update, send_btn_text_update, new_turns_counter

    if not current_timeline_info_from_state:
        gr.Warning("현재 상호작용 시점이 설정되지 않았습니다. 시작 회차를 확정해주세요.")
        return gr.update(value=final_diag_list), final_diag_list, new_system_sit_active, new_last_choices, user_box_placeholder_update, send_btn_text_update, new_turns_counter


    effective_my_profile = current_my_profile_state
    if not effective_my_profile.strip() and profile_box_content.strip(): effective_my_profile = profile_box_content
    elif not effective_my_profile.strip() and not profile_box_content.strip():
        effective_my_profile = DEFAULT_MY_PROFILE_PLACEHOLDER
        gr.Info("'나의 프로필'이 없어 기본 프로필('이로운')으로 상황을 생성합니다.")

    situation_data = generate_system_situation(
        full_story_context_from_state,    # ★ 전체 원작 내용 전달
        current_timeline_info_from_state, # ★ 현재 시점 정보 전달
        effective_my_profile,
        current_my_role,
        final_diag_list
    )
    if situation_data and situation_data.get("full_text"):
        gr.Info(f"사용자 요청 시스템 상황 제시:\n{situation_data['full_text']}")
        final_diag_list.append({"role": "assistant", "content": f"{SYSTEM_SITUATION_PREFIX}{situation_data['full_text']}"})
        new_last_choices = situation_data.get("choices_list", [])
        new_system_sit_active = True
        user_box_placeholder_update = gr.update(placeholder=CHOICE_USER_BOX_PLACEHOLDER)
        send_btn_text_update = gr.update(value=CHOICE_SEND_BUTTON_TEXT)
        new_turns_counter = 0
    else:
        gr.Warning("새로운 상황 생성에 실패했습니다. 잠시 후 다시 시도해주세요.")

    return gr.update(value=final_diag_list), final_diag_list, new_system_sit_active, new_last_choices, user_box_placeholder_update, send_btn_text_update, new_turns_counter

def full_reset_interface() -> Tuple[
    gr.update, gr.update, List[Dict[str,str]], str, gr.update, Optional[Image.Image],
    gr.update, str, str, gr.update, List[Dict[str,str]], gr.update, str, str, bool,
    gr.update, bool, list, list, list, int, float, str, gr.update, gr.update, gr.update
]:
    """
    모든 상태와 UI를 완전히 초기화하는 함수
    """
    # 초기 UI 상태 설정
    user_box_update = gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER, interactive=False)
    chatbot_display_update = gr.update(value=[{"role": "assistant", "content": "먼저 TXT 파일을 업로드해주세요."}])
    initial_diaglist = [{"role": "assistant", "content": "먼저 TXT 파일을 업로드해주세요."}]
    profile_box_value = DEFAULT_MY_PROFILE_PLACEHOLDER
    profile_box_update = gr.update(value=profile_box_value, interactive=True)

    # 파일 관련 상태 초기화
    file_input_update = gr.update(value=None)
    parsed_episodes_state = []
    parsed_episodes_full_text = ""
    episode_selector_update = gr.update(choices=[], value=None, interactive=False)

    # 기타 상태 초기화
    my_profile_state = ""
    novel_text_display = ""
    style_content_state = ""
    style_box_update = gr.update(value="")
    focused_episode_content_state = ""
    current_timeline_info_state = ""
    situation_injection_mode = False
    send_btn_update = gr.update(value=DEFAULT_SEND_BUTTON_TEXT, interactive=False)
    system_situation_active = False
    last_system_choices = []
    role_choices_list_state = []
    scene_choices_list_state = []
    turns_since_last_event = 0
    initial_setup_step = 0.0  # 완전 초기 상태
    my_role_in_story = ""

    # 버튼 상태 초기화
    request_event_btn_update = gr.update(interactive=False)
    inject_situation_btn_update = gr.update(interactive=False)
    confirm_start_episode_btn_update = gr.update(interactive=False)

    # 이미지 초기화
    gen_image_display = None

    gr.Info("모든 상태가 완전히 초기화되었습니다. 처음부터 다시 시작해주세요.")

    return (
        user_box_update,
        chatbot_display_update,
        initial_diaglist,
        my_profile_state,
        profile_box_update,
        gen_image_display,
        file_input_update,
        novel_text_display,
        style_content_state,
        style_box_update,
        parsed_episodes_state,
        episode_selector_update,
        focused_episode_content_state,
        current_timeline_info_state,
        situation_injection_mode,
        send_btn_update,
        system_situation_active,
        last_system_choices,
        role_choices_list_state,
        scene_choices_list_state,
        turns_since_last_event,
        initial_setup_step,
        my_role_in_story,
        request_event_btn_update,
        inject_situation_btn_update,
        confirm_start_episode_btn_update
    )


def get_clear_chat_outputs():
    return [
        user_box,
        chatbot_display,
        diaglist_state,
        my_profile_state,
        profile_box,
        gen_image_display,
        file_input,
        novel_text_display,
        style_content_state,
        style_box,
        parsed_episodes_state,
        episode_selector_ui,
        focused_episode_content_state,
        current_timeline_info_state,
        situation_injection_mode,
        send_btn,
        system_situation_active,
        last_system_choices,
        role_choices_list_state,
        scene_choices_list_state,
        turns_since_last_event,
        initial_setup_step,
        my_role_in_story,
        request_event_btn,
        inject_situation_btn,
        confirm_start_episode_btn
    ]


###################################
# Gradio UI 구간
###################################
with gr.Blocks(theme=gr.themes.Soft(primary_hue=gr.themes.colors.sky, secondary_hue=gr.themes.colors.blue)) as demo:
    gr.Markdown("<h1 align='center'>📝AI 스토리다이빙</h1><p align='center'>'직접 원작의 캐릭터가 되어, 세계관 속에 잠수해보세요!</p>")

    # 사용 방법 안내 추가
    with gr.Accordion("📖 사용 방법 안내", open=False): # 기본적으로 닫혀있도록 open=False 설정 가능
        gr.Markdown(
            """
            **📝 웹소설 AI 창작 도우미에 오신 것을 환영합니다!** AI와 함께 나만의 웹소설 이야기를 만들어보세요.

            **1. 원작 파일 업로드 (선택 사항):**
            - 왼쪽 상단의 "원작 TXT 파일 (.txt)" 버튼을 클릭하여 참고할 웹소설 텍스트 파일을 업로드합니다. (UTF-8 인코딩 권장)
            - 파일이 업로드되면 회차 목록이 자동으로 생성됩니다.

            **2. '나의 프로필' 설정:**
            - "원작 & '나의' 프로필" 섹션에서 이야기의 주인공인 '나'의 이름, 성별, 외모, 성격 등을 자유롭게 설정합니다.
            - 설정 후에는 반드시 "**✅ '나의 프로필' 확정/수정**" 버튼을 눌러 적용해주세요. (기본 프로필 사용 가능)

            **3. 회차 선택 (파일 업로드 시):**
            - "컨텍스트 회차 선택" 드롭다운 메뉴에서 AI가 참고할 원작 내용의 범위를 선택합니다.
            - 기본적으로 파일의 마지막 회차까지의 내용이 AI의 전체 지식으로 사용되며, 드롭다운에서 선택한 회차는 현재 상호작용을 시작하거나 집중할 시점을 의미합니다.
            - 회차 변경 후 "**🔄 대화 초기화**" 버튼을 누르면, 변경된 시점을 기준으로 브리핑 및 역할 선택부터 다시 시작할 수 있습니다. (AI는 여전히 전체 내용을 기억합니다.)

            **4. 초기 설정 진행 (AI와의 첫 상호작용):**
            - 파일 업로드 (또는 초기화) 시 채팅창에 현재까지의 **[스토리 브리핑]**과 사용자('나')가 맡을 수 있는 **[나의 역할 선택지 제시]**가 나타납니다.
            - 제시된 역할 번호를 입력창에 입력하고 "전송" 버튼(또는 Enter)을 누르면, 해당 역할이 '나'의 역할로 채팅창에 표시됩니다.
            - 이후 AI는 선택된 역할에 맞춰 참여할 수 있는 **[참여 장면 선택지 제시]**를 보여줍니다.
            - 다시 장면 번호를 입력하여 전송하면, 해당 장면이 '나'의 선택으로 채팅창에 표시되고, AI가 그 장면에 대한 첫 반응(다른 캐릭터의 대사, 상황 묘사 등)을 보여주며 본격적인 이야기가 시작됩니다.

            **5. AI와 대화하며 이야기 만들기:**
            - 장면이 시작된 후에는 자유롭게 '나'의 대사, 행동, 생각을 입력하여 AI와 함께 스토리를 만들어갑니다.
            - AI는 사용자의 입력에 반응하며 이야기를 이어갑니다.

            **6. 주요 기능 활용:**
            - **✨ 다음 사건은?:** AI에게 새로운 사건이나 돌발 상황을 요청하여 이야기의 전환점을 만들 수 있습니다. (초기 설정 완료 후 활성화)
            - **⚡ 상황 제시:** 사용자가 직접 특정 상황을 설정하여 AI에게 전달하고 그에 대한 반응을 유도할 수 있습니다. (초기 설정 완료 후 활성화)
            - **🖼️ 현재 대화 장면 이미지 생성:** 최근 대화 내용을 바탕으로 이미지를 생성합니다. (이미지 생성 백엔드 설정 필요)
            - **📚 대화를 소설로 변환:** 현재까지의 대화 흐름을 바탕으로 소설 형식의 글을 생성합니다. (Anthropic API 키 필요)
            - **🔄 대화 초기화:** 현재의 원작 컨텍스트 및 프로필 설정을 유지한 채, 대화 내용만 초기화하고 브리핑 단계부터 다시 시작합니다.
            """
        )

    diaglist_state = gr.State([])
    my_profile_state = gr.State("")
    style_content_state = gr.State("")
    parsed_episodes_state = gr.State([])
    parsed_episodes_full_text_state = gr.State("") # ★ 신규: 원작 전체 텍스트

    focused_episode_content_state = gr.State("")   # ★ 신규: 확정된 N화까지의 내용
    current_timeline_info_state = gr.State("")     # ★ 신규: 현재 상호작용 시점 정보 문자열

    current_cumulative_context_state = gr.State("")

    situation_injection_mode = gr.State(False)
    system_situation_active = gr.State(False)
    last_system_choices = gr.State([])
    turns_since_last_event = gr.State(0)
    initial_setup_step = gr.State(0)
    my_role_in_story = gr.State("")
    role_choices_list_state = gr.State([])
    scene_choices_list_state = gr.State([])







    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### 📚 1. 기본 설정");
            with gr.Accordion("원작 & '나의' 프로필", open=True):
                gr.Markdown("#### 원작 텍스트 (선택)"); file_input = gr.File(label="원작 TXT 파일 (.txt)", file_types=[".txt"])
                gr.Markdown("#### <span style='color: steelblue;'>✨ '나'의 프로필</span>")
                profile_box = gr.Textbox(label="이야기 속 '나'는 어떤 인물인가요?", lines=10, interactive=True, placeholder="예시:\n이름: 이로운...", value=DEFAULT_MY_PROFILE_PLACEHOLDER)
                confirm_profile_btn = gr.Button("✅ '나의 프로필' 확정/수정", variant="primary")

            # "이야기 시작 시점 선택" 섹션을 아코디언 바깥으로 빼거나, 아코디언 내에 둔다면 이전 중복 정의 삭제
            gr.Markdown("#### 📖 이야기 시작 시점 선택")
            episode_selector_ui = gr.Dropdown(
                label="시작할 회차 선택",
                choices=[],
                interactive=False,
                info="파일 업로드 후 목록이 생성되며, 여기서 선택 후 아래 '확정' 버튼을 눌러주세요."
            )
            confirm_start_episode_btn = gr.Button(
                CONFIRM_EPISODE_BUTTON_TEXT, # 예: "🚀 시작 회차 확정"
                variant="primary",
                interactive=False
            )

            # gr.Markdown("#### 📖 회차 선택 (최대 50화)"); episode_selector_ui = gr.Dropdown(label="컨텍스트 회차 선택", choices=[], interactive=False, info="파일 업로드 시 목록 생성.")
            request_event_btn = gr.Button(USER_REQUEST_EVENT_BUTTON_TEXT, variant="secondary", interactive=False)
            with gr.Row():
                clear_chat_btn = gr.Button("🔄 대화 초기화", variant="stop", size="sm")
                full_reset_btn = gr.Button("🗑️ 전체 초기화", variant="stop", size="sm")

            # outputs_for_clear_chat_full은 기존 clear_chat_btn.click()의 outputs 리스트

            gr.Markdown("### 🎨 3. 장면 이미지화"); gen_image_display = gr.Image(label="생성된 장면 이미지", type="pil", height=320, interactive=False, show_download_button=True)
            gen_image_btn = gr.Button("🖼️ 현재 대화 장면 이미지 생성")
        with gr.Column(scale=2):
            gr.Markdown("### 💬 2. AI 캐릭터와 대화"); chatbot_display = gr.Chatbot(label="'나'와 AI 캐릭터의 대화", height=680, avatar_images=("https://img.icons8.com/officel/80/person-male.png", "https://img.icons8.com/arcade/64/bot.png"), show_copy_button=True, type="messages")
            with gr.Row():
                user_box = gr.Textbox(placeholder=DEFAULT_USER_BOX_PLACEHOLDER, lines=3, show_label=False, scale=3)
                inject_situation_btn = gr.Button("⚡ 상황 제시", scale=1, interactive=False)
                send_btn = gr.Button(DEFAULT_SEND_BUTTON_TEXT, scale=1, variant="primary")
            clear_chat_btn = gr.Button("🔄 대화 초기화", variant="stop", size="sm")
        with gr.Column(scale=2):
            gr.Markdown("### ✍️ 4. AI와 채팅한 대화를 소설로 변환");
            with gr.Accordion("참고 문체 입력 (선택)", open=False):
                style_box = gr.Textbox(label="글쓰기 스타일 참고", lines=10, interactive=True, placeholder="참고 문체 붙여넣기...")
                load_style_btn = gr.Button("🎨 문체 예시 적용")
            novel_text_display = gr.Textbox(label="변환된 소설 내용", lines=32, interactive=False, show_copy_button=True)
            convert_to_novel_btn = gr.Button("📚 AI와 채팅한 스토리를 소설로 변환", variant="primary")

    outputs_for_file_load = [
        parsed_episodes_state,              # 1. 파싱된 에피소드 객체 리스트
        parsed_episodes_full_text_state,    # 2. ★ 원작 전체 텍스트 (신규 상태)
        episode_selector_ui,                # 3. 드롭다운 UI 업데이트
        focused_episode_content_state,      # 4. ★ N화까지 내용 (초기엔 빈 값)
        chatbot_display,                    # 5. 챗봇 UI 업데이트 (안내 메시지)
        initial_setup_step,                 # 6. 설정 단계 (0.5로)
        system_situation_active,            # 7
        last_system_choices,                # 8
        role_choices_list_state,            # 9
        scene_choices_list_state,           # 10
        current_timeline_info_state,        # 11. ★ 현재 시점 정보 (초기엔 빈 값)
        turns_since_last_event,             # 12
        user_box,                           # 13
        send_btn,                           # 14
        request_event_btn,                  # 15
        inject_situation_btn,               # 16
        confirm_start_episode_btn           # 17. ★ 확정 버튼 상태 업데이트
    ]




    file_input.upload(fn=load_file_and_parse_episodes_revised, inputs=[file_input, profile_box], outputs=outputs_for_file_load) \
        .then(lambda chatbot_value: chatbot_value, inputs=[chatbot_display], outputs=[diaglist_state])

    episode_selector_ui.change(fn=update_context_on_episode_change, inputs=[episode_selector_ui, parsed_episodes_state], outputs=[current_cumulative_context_state])
    confirm_profile_btn.click(fn=toggle_profile_lock_and_save, inputs=[profile_box, my_profile_state], outputs=[profile_box, my_profile_state, confirm_profile_btn])

    outputs_for_activate_sit_mode = [situation_injection_mode, system_situation_active, last_system_choices, user_box, send_btn]
    inject_situation_btn.click(fn=activate_situation_mode, inputs=None, outputs=outputs_for_activate_sit_mode)

    outputs_for_req_sys_sit = [chatbot_display, diaglist_state, system_situation_active, last_system_choices, user_box, send_btn, turns_since_last_event]
    request_event_btn.click(fn=handle_request_system_situation,
                            inputs=[diaglist_state,
                                current_cumulative_context_state,
                                current_timeline_info_state,  # 위치 변경 (함수 정의 순서에 맞게)
                                my_profile_state,
                                profile_box,
                                parsed_episodes_state,
                                turns_since_last_event,
                                my_role_in_story,
                                initial_setup_step],
                            outputs=outputs_for_req_sys_sit)

    outputs_for_handle_send = [
        user_box, chatbot_display, diaglist_state,
        situation_injection_mode, system_situation_active, last_system_choices,
        role_choices_list_state, scene_choices_list_state,
        send_btn, turns_since_last_event, initial_setup_step, my_role_in_story,
        request_event_btn, inject_situation_btn,confirm_start_episode_btn
    ]
    def handle_send_click_wrapper(user_input: str,
                                  diag_list: List[Dict[str,str]],
                                  full_story_context_from_state: str,       # 'parsed_episodes_full_text_state' 값을 받음
                                  current_timeline_info_from_state: str,    # 'current_timeline_info_state' 값을 받음
                                  # focused_episode_content_from_state: str, # 필요시 N화까지 내용도 전달 가능 (현재는 full_story와 timeline_info로 대부분 커버)
                                  # ctx_state: str,
                                  current_my_profile_from_state: str,
                                  current_my_profile_from_box: str,
                                  user_sit_mode: bool,
                                  system_sit_active_mode: bool,
                                  current_last_choices: list,
                                  current_role_choices_from_state: list,
                                  current_scene_choices_from_state: list,
                                  current_parsed_eps: list,
                                  turns_counter: int,
                                  setup_step: float,
                                  current_my_role: str
                                 ) -> \
    Tuple[ # 반환 값 튜플 (총 15개 항목, confirm_start_episode_btn 상태 포함)
    gr.update, gr.update, List[Dict[str,str]], bool, bool, list, list, list,
    gr.update, int, float, str, gr.update, gr.update, gr.update
]:
        print(f"DEBUG: handle_send_click_wrapper called. setup_step={setup_step}, user_input='{user_input}'")
        final_diag_list = list(diag_list)
        effective_my_profile = current_my_profile_from_state or current_my_profile_from_box or DEFAULT_MY_PROFILE_PLACEHOLDER

        new_user_sit_mode = user_sit_mode
        new_system_sit_active_mode = system_sit_active_mode
        final_user_box_placeholder_update = gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER)
        final_send_btn_text_update = gr.update(value=DEFAULT_SEND_BUTTON_TEXT)
        final_user_box_value_update = gr.update(value="")

        new_last_choices_list = list(current_last_choices)
        new_role_choices_list_state = list(current_role_choices_from_state)
        new_scene_choices_list_state = list(current_scene_choices_from_state)
        new_turns_counter = turns_counter
        new_setup_step = setup_step
        new_my_role = current_my_role
        req_event_btn_interactive_update = gr.update(interactive=False)
        inject_sit_btn_interactive_update = gr.update(interactive=False)
        confirm_start_episode_btn_interactive_update = gr.update(interactive=False) # 기본적으로 비활성
        user_input_processed_this_turn = False

        if not user_input.strip():
            gr.Warning("메시지나 선택할 번호를 입력해주세요.");
            if setup_step == 0.5: final_user_box_placeholder_update = gr.update(placeholder=EPISODE_CONFIRM_USER_BOX_PLACEHOLDER, interactive=False); confirm_start_episode_btn_interactive_update = gr.update(interactive=True); send_btn_text_update = gr.update(interactive=False)
            elif setup_step == 1: final_user_box_placeholder_update = gr.update(placeholder=ROLE_CHOICE_USER_BOX_PLACEHOLDER); final_send_btn_text_update = gr.update(value=ROLE_CHOICE_SEND_BUTTON_TEXT);
            elif setup_step == 2: final_user_box_placeholder_update = gr.update(placeholder=SCENE_CHOICE_USER_BOX_PLACEHOLDER); final_send_btn_text_update = gr.update(value=SCENE_CHOICE_SEND_BUTTON_TEXT);
            elif system_sit_active_mode: final_user_box_placeholder_update = gr.update(placeholder=CHOICE_USER_BOX_PLACEHOLDER); final_send_btn_text_update = gr.update(value=CHOICE_SEND_BUTTON_TEXT);
            elif user_sit_mode: final_user_box_placeholder_update = gr.update(placeholder=SITUATION_USER_BOX_PLACEHOLDER); final_send_btn_text_update = gr.update(value=SITUATION_SEND_BUTTON_TEXT);
            else: # setup_step == 3 또는 0
                if setup_step >=3 : req_event_btn_interactive_update = gr.update(interactive=True); inject_sit_btn_interactive_update = gr.update(interactive=True)
                if setup_step == 0: final_user_box_placeholder_update = gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER, interactive=False); send_btn_text_update = gr.update(interactive=False)

        elif new_setup_step == 1: # 역할 선택 (사용자 입력은 역할 번호 또는 직접 입력한 역할)
            user_input_processed_this_turn = True
            choice_match = re.match(r"^\s*(\d+)\s*(?:번)?\s*$", user_input.strip())
            selected_role_text_for_display = ""
            if choice_match and new_role_choices_list_state:
                choice_num = int(choice_match.group(1))
                if 1 <= choice_num <= len(new_role_choices_list_state):
                    new_my_role = new_role_choices_list_state[choice_num - 1]
                    selected_role_text_for_display = new_my_role
                    gr.Info(f"'나의 역할'로 '{new_my_role.splitlines()[0][:30]}...'을(를) 선택했습니다.")
                else:
                    new_my_role = user_input.strip()
                    selected_role_text_for_display = new_my_role
                    gr.Warning("유효하지 않은 역할 번호. 직접 입력한 것으로 간주합니다.")
            else:
                new_my_role = user_input.strip()
                selected_role_text_for_display = new_my_role
                gr.Info(f"'나의 역할'로 '{new_my_role}'을(를) 직접 설정합니다.")

            final_diag_list.append({"role": "user", "content": f"{USER_CHOICE_ROLE_PREFIX}{selected_role_text_for_display}"})

            scene_choice_data = generate_scene_entry_choices_llm(
                full_story_context_from_state,  # ★ 전체 원작 내용
                current_timeline_info_from_state, # ★ 현재 N화 시점 정보
                effective_my_profile,
                new_my_role # 사용자가 선택한 역할
              )
            if scene_choice_data and scene_choice_data.get("full_text") and not scene_choice_data.get("is_fallback"):
                scene_choices_text_for_display = scene_choice_data['full_text']
                new_scene_choices_list_state = scene_choice_data.get("choices_list", [])
                final_diag_list.append({"role": "assistant", "content": f"{SCENE_ENTRY_CHOICE_PREFIX}{scene_choices_text_for_display}"})
                new_setup_step = 2.0
                final_user_box_placeholder_update = gr.update(placeholder=SCENE_CHOICE_USER_BOX_PLACEHOLDER)
                final_send_btn_text_update = gr.update(value=SCENE_CHOICE_SEND_BUTTON_TEXT)
            else:
                fallback_scene_text = scene_choice_data.get("full_text") if scene_choice_data else "장면 선택지 생성에 실패했습니다."
                final_diag_list.append({"role": "assistant", "content": f"{fallback_scene_text}\nAI 캐릭터와 바로 대화를 시작합니다."})
                # ★ AI 응답 생성 시에도 컨텍스트 전달
                ai_fallback_response = assistant_turn(final_diag_list, full_story_context_from_state, current_timeline_info_from_state, effective_my_profile, new_my_role)
                if ai_fallback_response: final_diag_list.append({"role": "assistant", "content": ai_fallback_response})
                else: final_diag_list.append({"role": "assistant", "content": f"'{new_my_role}' 역할로 모험을 시작합니다! 무엇을 하시겠습니까?"})
                new_setup_step = 3.0;
                final_user_box_placeholder_update = gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER, interactive=True)
                final_send_btn_text_update = gr.update(value=DEFAULT_SEND_BUTTON_TEXT, interactive=True)
                req_event_btn_interactive_update = gr.update(interactive=True); inject_sit_btn_interactive_update = gr.update(interactive=True)
            new_role_choices_list_state = []

        elif new_setup_step == 2: # 장면 선택
            user_input_processed_this_turn = True
            choice_match = re.match(r"^\s*(\d+)\s*(?:번)?\s*$", user_input.strip())
            chosen_scene_description = ""
            if choice_match and new_scene_choices_list_state:
                choice_num = int(choice_match.group(1))
                if 1 <= choice_num <= len(new_scene_choices_list_state):
                    chosen_scene_description = new_scene_choices_list_state[choice_num - 1]
                    gr.Info(f"장면 '{chosen_scene_description.splitlines()[0][:30]}...'을(를) 선택했습니다.")
                else:
                    chosen_scene_description = new_scene_choices_list_state[0] if new_scene_choices_list_state else "알 수 없는 장면"
                    gr.Warning("유효하지 않은 장면 번호. 첫 번째 장면으로 진행합니다.")
            else:
                chosen_scene_description = new_scene_choices_list_state[0] if new_scene_choices_list_state else "알 수 없는 장면"
                gr.Warning("장면 번호를 입력해주세요. 첫 번째 장면으로 진행합니다.")

            final_diag_list.append({"role": "user", "content": f"{USER_CHOICE_SCENE_PREFIX}{chosen_scene_description.splitlines()[0][:40]}..."})

            ai_first_reaction = generate_ai_reaction_to_scene_choice_llm(
                full_story_context_from_state,  # ★ 전체 원작 내용
                current_timeline_info_from_state, # ★ 현재 N화 시점 정보
                effective_my_profile,
                new_my_role,
                chosen_scene_description # 사용자가 선택한 장면 설명
            )
            # SCENE_START_PREFIX 제거, AI 응답 자체가 장면 시작이 되도록 함. 개행은 AI가 생성하도록 유도.
            ai_first_reaction_formatted = ai_first_reaction if ai_first_reaction else f"선택하신 장면으로 이야기를 시작합니다. '{new_my_role}'으로서 이제 당신의 차례입니다."

            final_diag_list.append({"role": "assistant", "content": ai_first_reaction_formatted})

            new_setup_step = 3; final_user_box_placeholder_update = gr.update(placeholder=DEFAULT_USER_BOX_PLACEHOLDER); final_send_btn_text_update = gr.update(value=DEFAULT_SEND_BUTTON_TEXT)
            req_event_btn_interactive_update = gr.update(interactive=True); inject_sit_btn_interactive_update = gr.update(interactive=True)
            new_scene_choices_list_state = []; new_turns_counter = 0

        elif new_setup_step >= 3: # 일반 상호작용 또는 시스템 상황/사용자 상황 제시
            if system_sit_active_mode:
                user_input_processed_this_turn = True
                choice_match = re.match(r"^\s*(\d+)\s*(?:번)?\s*$", user_input.strip())
                chosen_action_for_llm = ""
                is_free_action = False
                if choice_match and new_last_choices_list:
                    choice_num = int(choice_match.group(1))
                    if 1 <= choice_num <= len(new_last_choices_list):
                        chosen_action_for_llm = new_last_choices_list[choice_num - 1]
                        gr.Info(f"선택지 {choice_num}번 ('{chosen_action_for_llm}')을 선택했습니다.")
                        final_diag_list.append({"role": "user", "content": f"{USER_CHOICE_ACTION_PREFIX}{chosen_action_for_llm}"})
                    else:
                        chosen_action_for_llm = user_input; is_free_action = True; gr.Warning("유효하지 않은 선택지 번호. 일반 텍스트로 처리.")
                else:
                    chosen_action_for_llm = user_input; is_free_action = True; gr.Info("자유 행동으로 입력합니다.")

                if is_free_action:
                    final_diag_list.append({"role": "user", "content": user_input})
                    ai_response = assistant_turn(
                        final_diag_list,
                        full_story_context_from_state,  # ★ 전체 원작 내용
                        current_timeline_info_from_state, # ★ 현재 N화 시점 정보
                        effective_my_profile,
                        new_my_role,
                        # user_selected_action=chosen_action_for_llm # 여기서 chosen_action_for_llm은 사용자가 고른 선택지 또는 자유 입력
                    )

                else:
                    ai_response = assistant_turn(
                        final_diag_list,
                        full_story_context_from_state,  # ★ 전체 원작 내용
                        current_timeline_info_from_state, # ★ 현재 N화 시점 정보
                        effective_my_profile,
                        new_my_role,
                        user_selected_action=chosen_action_for_llm # 여기서 chosen_action_for_llm은 사용자가 고른 선택지 또는 자유 입력
                    )

                if ai_response: final_diag_list.append({"role": "assistant", "content": ai_response})
                new_system_sit_active_mode = False; new_last_choices_list = []; new_turns_counter = 0

            elif user_sit_mode:
                user_input_processed_this_turn = True
                final_diag_list.append({"role": "user", "content": f"{USER_SITUATION_PREFIX}{user_input}"})
                ai_response = assistant_turn(
                    final_diag_list,
                    full_story_context_from_state,  # ★ 전체 원작 내용
                    current_timeline_info_from_state, # ★ 현재 N화 시점 정보
                    effective_my_profile,
                    new_my_role
                )
                if ai_response: final_diag_list.append({"role": "assistant", "content": ai_response})
                new_user_sit_mode = False; new_turns_counter = 0

            if not user_input_processed_this_turn and user_input.strip():
                user_input_processed_this_turn = True
                final_diag_list.append({"role": "user", "content": user_input})
                ai_response = assistant_turn(
                    final_diag_list,
                    full_story_context_from_state,  # ★ 전체 원작 내용
                    current_timeline_info_from_state, # ★ 현재 N화 시점 정보
                    effective_my_profile,
                    new_my_role
                )
                if ai_response: final_diag_list.append({"role": "assistant", "content": ai_response})
                new_turns_counter = 0
            elif not user_input.strip() and not user_input_processed_this_turn:
                new_turns_counter = turns_counter + 1

            # 랜덤 시스템 상황 발생 로직
            # 조건: 사용자 입력이 이번 턴에 처리되지 않았고, 빈 입력이었으며,
            #       시스템 상황이나 사용자 상황 제시 모드가 아니고,
            #       일정 턴 이상 이벤트가 없었고,
            #       원작 파일이 로드되었고 (current_parsed_eps로 판단),
            #       역할이 설정되어 있고, 랜덤 확률 조건 만족 시
            if not user_input_processed_this_turn and not user_input.strip() and \
               not new_system_sit_active_mode and not new_user_sit_mode and \
               new_turns_counter >= SYSTEM_NUDGE_THRESHOLD and \
               full_story_context_from_state and current_parsed_eps and new_my_role and \
               random.random() < RANDOM_SITUATION_PROBABILITY:

                gr.Info(f"{new_turns_counter}턴 동안 특별한 이벤트 없어 시스템 랜덤 상황 제시 시도...");

                # generate_system_situation 함수에 새로운 컨텍스트 정보 전달
                situation_data = generate_system_situation(
                    full_story_context_from_state,    # ★ 전체 원작 내용
                    current_timeline_info_from_state, # ★ 현재 N화 시점 정보
                    effective_my_profile,
                    new_my_role,
                    final_diag_list # 현재까지의 대화 목록
                )

                if situation_data and situation_data.get("full_text"):
                    final_diag_list.append({"role": "assistant", "content": f"{SYSTEM_SITUATION_PREFIX}{situation_data['full_text']}"})
                    new_last_choices_list = situation_data.get("choices_list", [])
                    new_system_sit_active_mode = True
                    final_user_box_placeholder_update = gr.update(placeholder=CHOICE_USER_BOX_PLACEHOLDER)
                    final_send_btn_text_update = gr.update(value=CHOICE_SEND_BUTTON_TEXT)
                    new_turns_counter = 0 # 랜덤 상황 발생 후 턴 카운터 리셋

            if not new_system_sit_active_mode and not new_user_sit_mode and new_setup_step >=3 :
                req_event_btn_interactive_update = gr.update(interactive=True); inject_sit_btn_interactive_update = gr.update(interactive=True)
                confirm_start_episode_btn_interactive_update = gr.update(interactive=True) # 일반 대화 중에는 회차 재확정 가능


        print(f"DEBUG: handle_send_click_wrapper returning. setup_step={new_setup_step}, num_diag_entries={len(final_diag_list)}")
        if final_diag_list:
            for i, msg_item in enumerate(final_diag_list):
                 print(f"    Msg {i}: type={type(msg_item)}, role='{msg_item.get('role')}', content_type={type(msg_item.get('content'))}, content='{str(msg_item.get('content'))[:70]}...'")
        else: print("  final_diag_list is empty.")

        return (
            final_user_box_value_update,
            gr.update(value=list(final_diag_list)),
            list(final_diag_list),
            new_user_sit_mode,
            new_system_sit_active_mode,
            new_last_choices_list,
            new_role_choices_list_state,
            new_scene_choices_list_state,
            final_send_btn_text_update,
            new_turns_counter,
            new_setup_step,
            new_my_role,
            req_event_btn_interactive_update,
            inject_sit_btn_interactive_update,
            confirm_start_episode_btn_interactive_update # ★ 반환 튜플에 추가 (15번째 항목)
        )

    # confirm_start_episode_and_setup 함수의 outputs 개수: 12개
    outputs_for_confirm_start = [
        focused_episode_content_state,      # 1. 확정된 N화까지의 내용
        current_timeline_info_state,        # 2. 현재 시점 정보 문자열
        chatbot_display,                    # 3. 챗봇 UI (브리핑+역할선택지 표시)
        diaglist_state,                     # 4. 챗봇 대화 목록 상태
        initial_setup_step,                 # 5. 설정 단계 (1.0으로)
        role_choices_list_state,            # 6. 역할 선택지 목록 상태
        scene_choices_list_state,           # 7. 장면 선택지 목록 상태 (초기화)
        user_box,                           # 8. 사용자 입력창 UI
        send_btn,                           # 9. 전송 버튼 UI
        request_event_btn,                  # 10. 다음 사건 버튼 UI
        inject_situation_btn,               # 11. 상황 제시 버튼 UI
        confirm_start_episode_btn           # 12. 시작 회차 확정 버튼 UI (비활성화)
    ]
    confirm_start_episode_btn.click(
        fn=confirm_start_episode_and_setup,
        inputs=[
            episode_selector_ui,        # 선택된 회차 표시 이름
            parsed_episodes_state,      # 전체 파싱된 에피소드 객체 리스트
            profile_box                 # 현재 프로필 입력창 내용
            # full_story_context는 이 함수에서 직접 받지 않고,
            # 필요하다면 전역 상태 변수인 parsed_episodes_full_text_state를 다른 함수(예: call_gpt)가 참조
        ],
        outputs=outputs_for_confirm_start
    )
    # .then()을 사용하여 chatbot_display의 값을 diaglist_state로 다시 동기화할 수 있으나,
    # confirm_start_episode_and_setup 함수가 diaglist_state용 값을 직접 반환하므로 불필요할 수 있음.
    # 위 함수 반환값에 diaglist_state가 포함되어 있으므로 .then은 생략 가능.

    # handle_send_click_wrapper에 전달될 inputs 리스트 수정
    inputs_for_handle_send = [
        user_box,
        diaglist_state,
        # current_cumulative_context_state, # 이전 ctx_state 대신 새로운 상태 변수들 사용
        parsed_episodes_full_text_state,    # ★ 신규 추가: 원작 전체 내용
        current_timeline_info_state,        # ★ 신규 추가: 현재 상호작용 시점 정보
        # focused_episode_content_state,    # 필요에 따라 N화까지의 내용도 전달 가능
        my_profile_state,
        profile_box,
        situation_injection_mode,
        system_situation_active,
        last_system_choices,
        role_choices_list_state,
        scene_choices_list_state,
        parsed_episodes_state, # 전체 파싱된 에피소드 객체 리스트 (N화 내용 계산 등에 사용될 수 있음)
        turns_since_last_event,
        initial_setup_step,
        my_role_in_story
    ]

    send_btn.click(fn=handle_send_click_wrapper,
                   inputs=inputs_for_handle_send,
                   outputs=outputs_for_handle_send, queue=True)
    user_box.submit(fn=handle_send_click_wrapper,
                    inputs=inputs_for_handle_send,
                    outputs=outputs_for_handle_send, queue=True)

    gen_image_btn.click(fn=generate_image_button_callback, inputs=[diaglist_state, my_profile_state], outputs=[gen_image_display], show_progress="minimal", queue=True)
    load_style_btn.click(load_style_text, inputs=[style_box], outputs=[style_content_state])
    convert_to_novel_btn.click(fn=convert_chat_to_novel_text, inputs=[diaglist_state, my_profile_state, my_role_in_story, style_content_state, parsed_episodes_full_text_state], outputs=[novel_text_display], show_progress="full", queue=True)

    clear_chat_btn.click(fn=clear_chat_interface,
                        inputs=[my_profile_state, profile_box, parsed_episodes_state, parsed_episodes_full_text_state],
                        outputs=get_clear_chat_outputs(),
                        queue=True)

    # full_reset_btn에 full_reset_interface 함수 연결
    full_reset_btn.click(fn=full_reset_interface,
                        inputs=None,
                        outputs=get_clear_chat_outputs(), # 동일한 outputs 리스트 사용
                        queue=True)
if __name__ == '__main__':
    demo.queue().launch(debug=True, share=True)

